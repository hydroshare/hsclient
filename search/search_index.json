{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"hsclient A python client for interacting with HydroShare in an object oriented way. Jupyter Notebooks HydroShare has a resource with example notebooks. Click here then click the blue Open with... dropdown and select Cuahsi Jupyterhub to launch the notebooks into a Jupyter Environment to start using this project. Install the HydroShare Python Client The HydroShare Python Client for HydroShare won't be installed by default, so it has to be installed first before you can work with it. Use the following command to install the Python Client from the GitHub repository. Eventually we will distribute this package via the Python Package Index (PyPi) so that it can be installed via pip from PyPi. pip install hsclient","title":"hsclient"},{"location":"#hsclient","text":"A python client for interacting with HydroShare in an object oriented way.","title":"hsclient"},{"location":"#jupyter-notebooks","text":"HydroShare has a resource with example notebooks. Click here then click the blue Open with... dropdown and select Cuahsi Jupyterhub to launch the notebooks into a Jupyter Environment to start using this project.","title":"Jupyter Notebooks"},{"location":"#install-the-hydroshare-python-client","text":"The HydroShare Python Client for HydroShare won't be installed by default, so it has to be installed first before you can work with it. Use the following command to install the Python Client from the GitHub repository. Eventually we will distribute this package via the Python Package Index (PyPi) so that it can be installed via pip from PyPi. pip install hsclient","title":"Install the HydroShare Python Client"},{"location":"api/aggregation/","text":"Represents an Aggregation in HydroShare Source code in hsclient\\hydroshare.py class Aggregation : \"\"\"Represents an Aggregation in HydroShare\"\"\" def __init__ ( self , map_path , hs_session , checksums = None ): self . _map_path = map_path self . _hs_session = hs_session self . _retrieved_map = None self . _retrieved_metadata = None self . _parsed_files = None self . _parsed_aggregations = None self . _parsed_checksums = checksums self . _main_file_path = None def __str__ ( self ): return self . _map_path @property def _map ( self ): if not self . _retrieved_map : self . _retrieved_map = self . _retrieve_and_parse ( self . _map_path ) return self . _retrieved_map @property def _metadata ( self ): if not self . _retrieved_metadata : self . _retrieved_metadata = self . _retrieve_and_parse ( self . metadata_path ) return self . _retrieved_metadata @property def _checksums ( self ): if not self . _parsed_checksums : self . _parsed_checksums = self . _retrieve_checksums ( self . _checksums_path ) return self . _parsed_checksums @property def _files ( self ): if not self . _parsed_files : self . _parsed_files = [] for file in self . _map . describes . files : if not is_aggregation ( str ( file )): if not file . path == self . metadata_path : if not str ( file . path ) . endswith ( '/' ): # checking for folders, shouldn't have to do this file_checksum_path = file . path . split ( self . _resource_path , 1 )[ 1 ] . strip ( \"/\" ) file_path = unquote ( file_checksum_path . split ( \"data/contents/\" , )[ 1 ] ) f = File ( file_path , unquote ( file . path ), self . _checksums [ file_checksum_path ]) self . _parsed_files . append ( f ) return self . _parsed_files @property def _aggregations ( self ): def populate_metadata ( _aggr ): _aggr . _metadata if not self . _parsed_aggregations : self . _parsed_aggregations = [] for file in self . _map . describes . files : if is_aggregation ( str ( file )): self . _parsed_aggregations . append ( Aggregation ( unquote ( file . path ), self . _hs_session , self . _checksums )) # load metadata for all aggregations (metadata is needed to create any typed aggregation) with ThreadPoolExecutor () as executor : executor . map ( populate_metadata , self . _parsed_aggregations ) # convert aggregations to aggregation type supporting data object aggregations_copy = self . _parsed_aggregations [:] typed_aggregation_classes = { AggregationType . MultidimensionalAggregation : NetCDFAggregation , AggregationType . TimeSeriesAggregation : TimeseriesAggregation , AggregationType . GeographicRasterAggregation : GeoRasterAggregation , AggregationType . GeographicFeatureAggregation : GeoFeatureAggregation , AggregationType . CSVFileAggregation : CSVAggregation } for aggr in aggregations_copy : typed_aggr_cls = typed_aggregation_classes . get ( aggr . metadata . type , None ) if typed_aggr_cls : typed_aggr = typed_aggr_cls . create ( base_aggr = aggr ) # swapping the generic aggregation with the typed aggregation in the aggregation list self . _parsed_aggregations . remove ( aggr ) self . _parsed_aggregations . append ( typed_aggr ) return self . _parsed_aggregations @property def _checksums_path ( self ): path = self . metadata_path . split ( \"/data/\" , 1 )[ 0 ] path = urljoin ( path , \"manifest-md5.txt\" ) return path @property def _hsapi_path ( self ): resource_path = self . _resource_path hsapi_path = urljoin ( \"hsapi\" , resource_path ) return hsapi_path @property def _resource_path ( self ): resource_path = self . metadata_path [: len ( \"/resource/b4ce17c17c654a5c8004af73f2df87ab/\" )] . strip ( \"/\" ) return resource_path def _retrieve_and_parse ( self , path ): file_str = self . _hs_session . retrieve_string ( path ) instance = load_rdf ( file_str ) return instance def _retrieve_checksums ( self , path ): file_str = self . _hs_session . retrieve_string ( path ) # split string by lines, then split line by delimiter into a dict delimiter = \" \" data = { quote ( path ): checksum for checksum , path in [ line . split ( delimiter ) for line in file_str . split ( \" \\n \" ) if line ] } return data def _download ( self , save_path : str = \"\" , unzip_to : str = None ) -> str : main_file_path = self . main_file_path path = urljoin ( self . _resource_path , \"data\" , \"contents\" , main_file_path ) params = { \"zipped\" : \"true\" , \"aggregation\" : \"true\" } path = path . replace ( 'resource' , 'django_irods/rest_download' , 1 ) downloaded_zip = self . _hs_session . retrieve_zip ( path , save_path = save_path , params = params ) if unzip_to : import zipfile with zipfile . ZipFile ( downloaded_zip , 'r' ) as zip_ref : zip_ref . extractall ( unzip_to ) os . remove ( downloaded_zip ) return unzip_to return downloaded_zip @property def metadata_file ( self ): \"\"\"The path to the metadata file\"\"\" return self . metadata_path . split ( \"/data/contents/\" , 1 )[ 1 ] @property def metadata ( self ) -> BaseMetadata : \"\"\"A metadata object for reading and updating metadata values\"\"\" return self . _metadata @property def metadata_path ( self ) -> str : \"\"\"The path to the metadata file\"\"\" return urlparse ( str ( self . _map . describes . is_documented_by )) . path @property def main_file_path ( self ) -> str : \"\"\"The path to the main file in the aggregation\"\"\" if self . _main_file_path is not None : return self . _main_file_path mft = main_file_type ( self . metadata . type ) if mft : for file in self . files (): if str ( file ) . endswith ( mft ): self . _main_file_path = file . path return self . _main_file_path if self . metadata . type == AggregationType . FileSetAggregation : self . _main_file_path = self . files ()[ 0 ] . folder return self . _main_file_path self . _main_file_path = self . files ()[ 0 ] . path return self . _main_file_path @refresh def save ( self ) -> None : \"\"\" Saves the metadata back to HydroShare :return: None \"\"\" metadata_file = self . metadata_file metadata_string = rdf_string ( self . _retrieved_metadata , rdf_format = \"xml\" ) url = urljoin ( self . _hsapi_path , \"ingest_metadata\" ) self . _hs_session . upload_file ( url , files = { 'file' : ( metadata_file , metadata_string )}) def files ( self , search_aggregations : bool = False , ** kwargs ) -> List [ File ]: \"\"\" List files and filter by properties on the file object using kwargs (i.e. extension='.txt') :param search_aggregations: Defaults False, set to true to search aggregations :params **kwargs: Search by properties on the File object (path, name, extension, folder, checksum url) :return: a List of File objects matching the filter parameters \"\"\" files = self . _files for key , value in kwargs . items (): files = list ( filter ( lambda file : attribute_filter ( file , key , value ), files )) if search_aggregations : for aggregation in self . aggregations (): files = files + list ( aggregation . files ( search_aggregations = search_aggregations , ** kwargs )) return files def file ( self , search_aggregations = False , ** kwargs ) -> File : \"\"\" Returns a single file in the resource that matches the filtering parameters :param search_aggregations: Defaults False, set to true to search aggregations :params **kwargs: Search by properties on the File object (path, name, extension, folder, checksum url) :return: A File object matching the filter parameters or None if no matching File was found \"\"\" files = self . files ( search_aggregations = search_aggregations , ** kwargs ) if files : return files [ 0 ] return None def aggregations ( self , ** kwargs ) -> List [ BaseMetadata ]: \"\"\" List the aggregations in the resource. Filter by properties on the metadata object using kwargs. If you need to filter on nested properties, use __ (double underscore) to separate the properties. For example, to filter by the BandInformation name, call this method like aggregations(band_information__name=\"the name to search\"). :params **kwargs: Search by properties on the metadata object :return: a List of Aggregation objects matching the filter parameters \"\"\" aggregations = self . _aggregations for key , value in kwargs . items (): if key . startswith ( 'file__' ): file_args = { key [ len ( 'file__' ):]: value } aggregations = [ agg for agg in aggregations if agg . files ( ** file_args )] elif key . startswith ( 'files__' ): file_args = { key [ len ( 'files__' ):]: value } aggregations = [ agg for agg in aggregations if agg . files ( ** file_args )] else : aggregations = filter ( lambda agg : attribute_filter ( agg . metadata , key , value ), aggregations ) return list ( aggregations ) def aggregation ( self , ** kwargs ) -> BaseMetadata : \"\"\" Returns a single Aggregation in the resource that matches the filtering parameters. Uses the same filtering rules described in the aggregations method. :params **kwargs: Search by properties on the metadata object :return: An Aggregation object matching the filter parameters or None if no matching Aggregation was found. \"\"\" aggregations = self . aggregations ( ** kwargs ) if aggregations : return aggregations [ 0 ] return None def refresh ( self ) -> None : \"\"\" Forces the retrieval of the resource map and metadata files. Currently this is implemented to be lazy and will only retrieve those files again after another call to access them is made. This will be later updated to be eager and retrieve the files asynchronously. \"\"\" # TODO, refresh should destroy the aggregation objects and async fetch everything. self . _retrieved_map = None self . _retrieved_metadata = None self . _parsed_files = None self . _parsed_aggregations = None self . _parsed_checksums = None self . _main_file_path = None def delete ( self ) -> None : \"\"\"Deletes this aggregation from HydroShare\"\"\" path = urljoin ( self . _hsapi_path , \"functions\" , \"delete-file-type\" , self . metadata . type . value + \"LogicalFile\" , self . main_file_path , ) self . _hs_session . delete ( path , status_code = 200 ) self . refresh () main_file_path : str property The path to the main file in the aggregation metadata : BaseMetadata property A metadata object for reading and updating metadata values metadata_file property The path to the metadata file metadata_path : str property The path to the metadata file aggregation ( ** kwargs ) Returns a single Aggregation in the resource that matches the filtering parameters. Uses the same filtering rules described in the aggregations method. :params **kwargs: Search by properties on the metadata object :return: An Aggregation object matching the filter parameters or None if no matching Aggregation was found. Source code in hsclient\\hydroshare.py def aggregation ( self , ** kwargs ) -> BaseMetadata : \"\"\" Returns a single Aggregation in the resource that matches the filtering parameters. Uses the same filtering rules described in the aggregations method. :params **kwargs: Search by properties on the metadata object :return: An Aggregation object matching the filter parameters or None if no matching Aggregation was found. \"\"\" aggregations = self . aggregations ( ** kwargs ) if aggregations : return aggregations [ 0 ] return None aggregations ( ** kwargs ) List the aggregations in the resource. Filter by properties on the metadata object using kwargs. If you need to filter on nested properties, use __ (double underscore) to separate the properties. For example, to filter by the BandInformation name, call this method like aggregations(band_information__name=\"the name to search\"). :params **kwargs: Search by properties on the metadata object :return: a List of Aggregation objects matching the filter parameters Source code in hsclient\\hydroshare.py def aggregations ( self , ** kwargs ) -> List [ BaseMetadata ]: \"\"\" List the aggregations in the resource. Filter by properties on the metadata object using kwargs. If you need to filter on nested properties, use __ (double underscore) to separate the properties. For example, to filter by the BandInformation name, call this method like aggregations(band_information__name=\"the name to search\"). :params **kwargs: Search by properties on the metadata object :return: a List of Aggregation objects matching the filter parameters \"\"\" aggregations = self . _aggregations for key , value in kwargs . items (): if key . startswith ( 'file__' ): file_args = { key [ len ( 'file__' ):]: value } aggregations = [ agg for agg in aggregations if agg . files ( ** file_args )] elif key . startswith ( 'files__' ): file_args = { key [ len ( 'files__' ):]: value } aggregations = [ agg for agg in aggregations if agg . files ( ** file_args )] else : aggregations = filter ( lambda agg : attribute_filter ( agg . metadata , key , value ), aggregations ) return list ( aggregations ) delete () Deletes this aggregation from HydroShare Source code in hsclient\\hydroshare.py def delete ( self ) -> None : \"\"\"Deletes this aggregation from HydroShare\"\"\" path = urljoin ( self . _hsapi_path , \"functions\" , \"delete-file-type\" , self . metadata . type . value + \"LogicalFile\" , self . main_file_path , ) self . _hs_session . delete ( path , status_code = 200 ) self . refresh () file ( search_aggregations = False , ** kwargs ) Returns a single file in the resource that matches the filtering parameters :param search_aggregations: Defaults False, set to true to search aggregations :params **kwargs: Search by properties on the File object (path, name, extension, folder, checksum url) :return: A File object matching the filter parameters or None if no matching File was found Source code in hsclient\\hydroshare.py def file ( self , search_aggregations = False , ** kwargs ) -> File : \"\"\" Returns a single file in the resource that matches the filtering parameters :param search_aggregations: Defaults False, set to true to search aggregations :params **kwargs: Search by properties on the File object (path, name, extension, folder, checksum url) :return: A File object matching the filter parameters or None if no matching File was found \"\"\" files = self . files ( search_aggregations = search_aggregations , ** kwargs ) if files : return files [ 0 ] return None files ( search_aggregations = False , ** kwargs ) List files and filter by properties on the file object using kwargs (i.e. extension='.txt') :param search_aggregations: Defaults False, set to true to search aggregations :params **kwargs: Search by properties on the File object (path, name, extension, folder, checksum url) :return: a List of File objects matching the filter parameters Source code in hsclient\\hydroshare.py def files ( self , search_aggregations : bool = False , ** kwargs ) -> List [ File ]: \"\"\" List files and filter by properties on the file object using kwargs (i.e. extension='.txt') :param search_aggregations: Defaults False, set to true to search aggregations :params **kwargs: Search by properties on the File object (path, name, extension, folder, checksum url) :return: a List of File objects matching the filter parameters \"\"\" files = self . _files for key , value in kwargs . items (): files = list ( filter ( lambda file : attribute_filter ( file , key , value ), files )) if search_aggregations : for aggregation in self . aggregations (): files = files + list ( aggregation . files ( search_aggregations = search_aggregations , ** kwargs )) return files refresh () Forces the retrieval of the resource map and metadata files. Currently this is implemented to be lazy and will only retrieve those files again after another call to access them is made. This will be later updated to be eager and retrieve the files asynchronously. Source code in hsclient\\hydroshare.py def refresh ( self ) -> None : \"\"\" Forces the retrieval of the resource map and metadata files. Currently this is implemented to be lazy and will only retrieve those files again after another call to access them is made. This will be later updated to be eager and retrieve the files asynchronously. \"\"\" # TODO, refresh should destroy the aggregation objects and async fetch everything. self . _retrieved_map = None self . _retrieved_metadata = None self . _parsed_files = None self . _parsed_aggregations = None self . _parsed_checksums = None self . _main_file_path = None save () Saves the metadata back to HydroShare :return: None Source code in hsclient\\hydroshare.py @refresh def save ( self ) -> None : \"\"\" Saves the metadata back to HydroShare :return: None \"\"\" metadata_file = self . metadata_file metadata_string = rdf_string ( self . _retrieved_metadata , rdf_format = \"xml\" ) url = urljoin ( self . _hsapi_path , \"ingest_metadata\" ) self . _hs_session . upload_file ( url , files = { 'file' : ( metadata_file , metadata_string )})","title":"Aggregation"},{"location":"api/aggregation/#hsclient.hydroshare.Aggregation.main_file_path","text":"The path to the main file in the aggregation","title":"main_file_path"},{"location":"api/aggregation/#hsclient.hydroshare.Aggregation.metadata","text":"A metadata object for reading and updating metadata values","title":"metadata"},{"location":"api/aggregation/#hsclient.hydroshare.Aggregation.metadata_file","text":"The path to the metadata file","title":"metadata_file"},{"location":"api/aggregation/#hsclient.hydroshare.Aggregation.metadata_path","text":"The path to the metadata file","title":"metadata_path"},{"location":"api/aggregation/#hsclient.hydroshare.Aggregation.aggregation","text":"Returns a single Aggregation in the resource that matches the filtering parameters. Uses the same filtering rules described in the aggregations method. :params **kwargs: Search by properties on the metadata object :return: An Aggregation object matching the filter parameters or None if no matching Aggregation was found. Source code in hsclient\\hydroshare.py def aggregation ( self , ** kwargs ) -> BaseMetadata : \"\"\" Returns a single Aggregation in the resource that matches the filtering parameters. Uses the same filtering rules described in the aggregations method. :params **kwargs: Search by properties on the metadata object :return: An Aggregation object matching the filter parameters or None if no matching Aggregation was found. \"\"\" aggregations = self . aggregations ( ** kwargs ) if aggregations : return aggregations [ 0 ] return None","title":"aggregation"},{"location":"api/aggregation/#hsclient.hydroshare.Aggregation.aggregations","text":"List the aggregations in the resource. Filter by properties on the metadata object using kwargs. If you need to filter on nested properties, use __ (double underscore) to separate the properties. For example, to filter by the BandInformation name, call this method like aggregations(band_information__name=\"the name to search\"). :params **kwargs: Search by properties on the metadata object :return: a List of Aggregation objects matching the filter parameters Source code in hsclient\\hydroshare.py def aggregations ( self , ** kwargs ) -> List [ BaseMetadata ]: \"\"\" List the aggregations in the resource. Filter by properties on the metadata object using kwargs. If you need to filter on nested properties, use __ (double underscore) to separate the properties. For example, to filter by the BandInformation name, call this method like aggregations(band_information__name=\"the name to search\"). :params **kwargs: Search by properties on the metadata object :return: a List of Aggregation objects matching the filter parameters \"\"\" aggregations = self . _aggregations for key , value in kwargs . items (): if key . startswith ( 'file__' ): file_args = { key [ len ( 'file__' ):]: value } aggregations = [ agg for agg in aggregations if agg . files ( ** file_args )] elif key . startswith ( 'files__' ): file_args = { key [ len ( 'files__' ):]: value } aggregations = [ agg for agg in aggregations if agg . files ( ** file_args )] else : aggregations = filter ( lambda agg : attribute_filter ( agg . metadata , key , value ), aggregations ) return list ( aggregations )","title":"aggregations"},{"location":"api/aggregation/#hsclient.hydroshare.Aggregation.delete","text":"Deletes this aggregation from HydroShare Source code in hsclient\\hydroshare.py def delete ( self ) -> None : \"\"\"Deletes this aggregation from HydroShare\"\"\" path = urljoin ( self . _hsapi_path , \"functions\" , \"delete-file-type\" , self . metadata . type . value + \"LogicalFile\" , self . main_file_path , ) self . _hs_session . delete ( path , status_code = 200 ) self . refresh ()","title":"delete"},{"location":"api/aggregation/#hsclient.hydroshare.Aggregation.file","text":"Returns a single file in the resource that matches the filtering parameters :param search_aggregations: Defaults False, set to true to search aggregations :params **kwargs: Search by properties on the File object (path, name, extension, folder, checksum url) :return: A File object matching the filter parameters or None if no matching File was found Source code in hsclient\\hydroshare.py def file ( self , search_aggregations = False , ** kwargs ) -> File : \"\"\" Returns a single file in the resource that matches the filtering parameters :param search_aggregations: Defaults False, set to true to search aggregations :params **kwargs: Search by properties on the File object (path, name, extension, folder, checksum url) :return: A File object matching the filter parameters or None if no matching File was found \"\"\" files = self . files ( search_aggregations = search_aggregations , ** kwargs ) if files : return files [ 0 ] return None","title":"file"},{"location":"api/aggregation/#hsclient.hydroshare.Aggregation.files","text":"List files and filter by properties on the file object using kwargs (i.e. extension='.txt') :param search_aggregations: Defaults False, set to true to search aggregations :params **kwargs: Search by properties on the File object (path, name, extension, folder, checksum url) :return: a List of File objects matching the filter parameters Source code in hsclient\\hydroshare.py def files ( self , search_aggregations : bool = False , ** kwargs ) -> List [ File ]: \"\"\" List files and filter by properties on the file object using kwargs (i.e. extension='.txt') :param search_aggregations: Defaults False, set to true to search aggregations :params **kwargs: Search by properties on the File object (path, name, extension, folder, checksum url) :return: a List of File objects matching the filter parameters \"\"\" files = self . _files for key , value in kwargs . items (): files = list ( filter ( lambda file : attribute_filter ( file , key , value ), files )) if search_aggregations : for aggregation in self . aggregations (): files = files + list ( aggregation . files ( search_aggregations = search_aggregations , ** kwargs )) return files","title":"files"},{"location":"api/aggregation/#hsclient.hydroshare.Aggregation.refresh","text":"Forces the retrieval of the resource map and metadata files. Currently this is implemented to be lazy and will only retrieve those files again after another call to access them is made. This will be later updated to be eager and retrieve the files asynchronously. Source code in hsclient\\hydroshare.py def refresh ( self ) -> None : \"\"\" Forces the retrieval of the resource map and metadata files. Currently this is implemented to be lazy and will only retrieve those files again after another call to access them is made. This will be later updated to be eager and retrieve the files asynchronously. \"\"\" # TODO, refresh should destroy the aggregation objects and async fetch everything. self . _retrieved_map = None self . _retrieved_metadata = None self . _parsed_files = None self . _parsed_aggregations = None self . _parsed_checksums = None self . _main_file_path = None","title":"refresh"},{"location":"api/aggregation/#hsclient.hydroshare.Aggregation.save","text":"Saves the metadata back to HydroShare :return: None Source code in hsclient\\hydroshare.py @refresh def save ( self ) -> None : \"\"\" Saves the metadata back to HydroShare :return: None \"\"\" metadata_file = self . metadata_file metadata_string = rdf_string ( self . _retrieved_metadata , rdf_format = \"xml\" ) url = urljoin ( self . _hsapi_path , \"ingest_metadata\" ) self . _hs_session . upload_file ( url , files = { 'file' : ( metadata_file , metadata_string )})","title":"save"},{"location":"api/csv/","text":"Bases: DataObjectSupportingAggregation Represents a CSV Aggregation in HydroShare Source code in hsclient\\hydroshare.py class CSVAggregation ( DataObjectSupportingAggregation ): \"\"\"Represents a CSV Aggregation in HydroShare\"\"\" @classmethod def create ( cls , base_aggr ): return super () . create ( aggr_cls = cls , base_aggr = base_aggr ) def as_data_object ( self , agg_path : str ) -> 'pandas.DataFrame' : \"\"\" Loads the CSV aggregation to a pandas DataFrame object :param agg_path: the path to the Time Series aggregation :return: the CSV aggregation as a pandas DataFrame object \"\"\" if pandas is None : raise Exception ( \"pandas package not found\" ) return self . _get_data_object ( agg_path = agg_path , func = pandas . read_csv , comment = \"#\" , dtype = \"string\" , engine = \"python\" ) def save_data_object ( self , resource : 'Resource' , agg_path : str , as_new_aggr : bool = False , destination_path : str = \"\" ) -> 'Aggregation' : \"\"\" Saves the pandas DataFrame object to the CSV aggregation :param resource: the resource containing the aggregation :param agg_path: the path to the CSV aggregation :param as_new_aggr: Defaults False, set to True to create a new CSV aggregation :param destination_path: the destination path in Hydroshare to save the new aggregation :return: the updated or new CSV aggregation \"\"\" self . _validate_aggregation_for_update ( resource , AggregationType . CSVFileAggregation ) file_path = self . _validate_aggregation_path ( agg_path , for_save_data = True ) self . _data_object . to_csv ( file_path , index = False ) aggr_main_file_path = self . main_file_path data_object = self . _data_object if not as_new_aggr : # cache some of the metadata fields of the original aggregation to update the metadata of the # updated aggregation keywords = self . metadata . subjects additional_meta = self . metadata . additional_metadata title = self . metadata . title # upload the updated aggregation files to the temp folder - to create the updated aggregation self . _update_aggregation ( resource , file_path ) # retrieve the updated aggregation aggr = resource . aggregation ( file__path = aggr_main_file_path ) # update metadata for kw in keywords : if kw not in aggr . metadata . subjects : aggr . metadata . subjects . append ( kw ) aggr . metadata . additional_metadata = additional_meta aggr . metadata . title = title aggr . save () else : # creating a new aggregation by uploading the updated data files resource . file_upload ( file_path , destination_path = destination_path ) # retrieve the new aggregation agg_path = urljoin ( destination_path , os . path . basename ( aggr_main_file_path )) aggr = resource . aggregation ( file__path = agg_path ) data_object = None aggr . _data_object = data_object return aggr as_data_object ( agg_path ) Loads the CSV aggregation to a pandas DataFrame object :param agg_path: the path to the Time Series aggregation :return: the CSV aggregation as a pandas DataFrame object Source code in hsclient\\hydroshare.py def as_data_object ( self , agg_path : str ) -> 'pandas.DataFrame' : \"\"\" Loads the CSV aggregation to a pandas DataFrame object :param agg_path: the path to the Time Series aggregation :return: the CSV aggregation as a pandas DataFrame object \"\"\" if pandas is None : raise Exception ( \"pandas package not found\" ) return self . _get_data_object ( agg_path = agg_path , func = pandas . read_csv , comment = \"#\" , dtype = \"string\" , engine = \"python\" ) save_data_object ( resource , agg_path , as_new_aggr = False , destination_path = '' ) Saves the pandas DataFrame object to the CSV aggregation :param resource: the resource containing the aggregation :param agg_path: the path to the CSV aggregation :param as_new_aggr: Defaults False, set to True to create a new CSV aggregation :param destination_path: the destination path in Hydroshare to save the new aggregation :return: the updated or new CSV aggregation Source code in hsclient\\hydroshare.py def save_data_object ( self , resource : 'Resource' , agg_path : str , as_new_aggr : bool = False , destination_path : str = \"\" ) -> 'Aggregation' : \"\"\" Saves the pandas DataFrame object to the CSV aggregation :param resource: the resource containing the aggregation :param agg_path: the path to the CSV aggregation :param as_new_aggr: Defaults False, set to True to create a new CSV aggregation :param destination_path: the destination path in Hydroshare to save the new aggregation :return: the updated or new CSV aggregation \"\"\" self . _validate_aggregation_for_update ( resource , AggregationType . CSVFileAggregation ) file_path = self . _validate_aggregation_path ( agg_path , for_save_data = True ) self . _data_object . to_csv ( file_path , index = False ) aggr_main_file_path = self . main_file_path data_object = self . _data_object if not as_new_aggr : # cache some of the metadata fields of the original aggregation to update the metadata of the # updated aggregation keywords = self . metadata . subjects additional_meta = self . metadata . additional_metadata title = self . metadata . title # upload the updated aggregation files to the temp folder - to create the updated aggregation self . _update_aggregation ( resource , file_path ) # retrieve the updated aggregation aggr = resource . aggregation ( file__path = aggr_main_file_path ) # update metadata for kw in keywords : if kw not in aggr . metadata . subjects : aggr . metadata . subjects . append ( kw ) aggr . metadata . additional_metadata = additional_meta aggr . metadata . title = title aggr . save () else : # creating a new aggregation by uploading the updated data files resource . file_upload ( file_path , destination_path = destination_path ) # retrieve the new aggregation agg_path = urljoin ( destination_path , os . path . basename ( aggr_main_file_path )) aggr = resource . aggregation ( file__path = agg_path ) data_object = None aggr . _data_object = data_object return aggr","title":"CSV Aggregation"},{"location":"api/csv/#hsclient.hydroshare.CSVAggregation.as_data_object","text":"Loads the CSV aggregation to a pandas DataFrame object :param agg_path: the path to the Time Series aggregation :return: the CSV aggregation as a pandas DataFrame object Source code in hsclient\\hydroshare.py def as_data_object ( self , agg_path : str ) -> 'pandas.DataFrame' : \"\"\" Loads the CSV aggregation to a pandas DataFrame object :param agg_path: the path to the Time Series aggregation :return: the CSV aggregation as a pandas DataFrame object \"\"\" if pandas is None : raise Exception ( \"pandas package not found\" ) return self . _get_data_object ( agg_path = agg_path , func = pandas . read_csv , comment = \"#\" , dtype = \"string\" , engine = \"python\" )","title":"as_data_object"},{"location":"api/csv/#hsclient.hydroshare.CSVAggregation.save_data_object","text":"Saves the pandas DataFrame object to the CSV aggregation :param resource: the resource containing the aggregation :param agg_path: the path to the CSV aggregation :param as_new_aggr: Defaults False, set to True to create a new CSV aggregation :param destination_path: the destination path in Hydroshare to save the new aggregation :return: the updated or new CSV aggregation Source code in hsclient\\hydroshare.py def save_data_object ( self , resource : 'Resource' , agg_path : str , as_new_aggr : bool = False , destination_path : str = \"\" ) -> 'Aggregation' : \"\"\" Saves the pandas DataFrame object to the CSV aggregation :param resource: the resource containing the aggregation :param agg_path: the path to the CSV aggregation :param as_new_aggr: Defaults False, set to True to create a new CSV aggregation :param destination_path: the destination path in Hydroshare to save the new aggregation :return: the updated or new CSV aggregation \"\"\" self . _validate_aggregation_for_update ( resource , AggregationType . CSVFileAggregation ) file_path = self . _validate_aggregation_path ( agg_path , for_save_data = True ) self . _data_object . to_csv ( file_path , index = False ) aggr_main_file_path = self . main_file_path data_object = self . _data_object if not as_new_aggr : # cache some of the metadata fields of the original aggregation to update the metadata of the # updated aggregation keywords = self . metadata . subjects additional_meta = self . metadata . additional_metadata title = self . metadata . title # upload the updated aggregation files to the temp folder - to create the updated aggregation self . _update_aggregation ( resource , file_path ) # retrieve the updated aggregation aggr = resource . aggregation ( file__path = aggr_main_file_path ) # update metadata for kw in keywords : if kw not in aggr . metadata . subjects : aggr . metadata . subjects . append ( kw ) aggr . metadata . additional_metadata = additional_meta aggr . metadata . title = title aggr . save () else : # creating a new aggregation by uploading the updated data files resource . file_upload ( file_path , destination_path = destination_path ) # retrieve the new aggregation agg_path = urljoin ( destination_path , os . path . basename ( aggr_main_file_path )) aggr = resource . aggregation ( file__path = agg_path ) data_object = None aggr . _data_object = data_object return aggr","title":"save_data_object"},{"location":"api/file/","text":"Bases: str A File path string representing the path to a file within a resource. :param value: the string path value :param file_url: the fully qualified url to the file on hydroshare.org :param checksum: the md5 checksum of the file Source code in hsclient\\hydroshare.py class File ( str ): \"\"\" A File path string representing the path to a file within a resource. :param value: the string path value :param file_url: the fully qualified url to the file on hydroshare.org :param checksum: the md5 checksum of the file \"\"\" def __new__ ( cls , value , file_url , checksum ): return super ( File , cls ) . __new__ ( cls , value ) def __init__ ( self , value , file_url , checksum ): self . _file_url = file_url self . _checksum = checksum @property def path ( self ) -> str : \"\"\"The path of the file\"\"\" return self @property def name ( self ) -> str : \"\"\"The filename\"\"\" return basename ( self ) @property def extension ( self ) -> str : \"\"\"The extension of the file\"\"\" return splitext ( self . name )[ 1 ] @property def folder ( self ) -> str : \"\"\"The folder the file is in\"\"\" return dirname ( self ) @property def checksum ( self ): \"\"\"The md5 checksum of the file\"\"\" return self . _checksum @property def url ( self ): \"\"\"The url to the file on HydroShare\"\"\" return self . _file_url checksum property The md5 checksum of the file extension : str property The extension of the file folder : str property The folder the file is in name : str property The filename path : str property The path of the file url property The url to the file on HydroShare","title":"File"},{"location":"api/file/#hsclient.hydroshare.File.checksum","text":"The md5 checksum of the file","title":"checksum"},{"location":"api/file/#hsclient.hydroshare.File.extension","text":"The extension of the file","title":"extension"},{"location":"api/file/#hsclient.hydroshare.File.folder","text":"The folder the file is in","title":"folder"},{"location":"api/file/#hsclient.hydroshare.File.name","text":"The filename","title":"name"},{"location":"api/file/#hsclient.hydroshare.File.path","text":"The path of the file","title":"path"},{"location":"api/file/#hsclient.hydroshare.File.url","text":"The url to the file on HydroShare","title":"url"},{"location":"api/geo_feature_aggregation/","text":"Bases: DataObjectSupportingAggregation Represents a Geo Feature Aggregation in HydroShare Source code in hsclient\\hydroshare.py class GeoFeatureAggregation ( DataObjectSupportingAggregation ): \"\"\"Represents a Geo Feature Aggregation in HydroShare\"\"\" @classmethod def create ( cls , base_aggr ): return super () . create ( aggr_cls = cls , base_aggr = base_aggr ) def _validate_aggregation_path ( self , agg_path : str , for_save_data : bool = False ) -> str : if for_save_data : for aggr_file in self . files (): aggr_file = basename ( aggr_file ) if aggr_file . endswith ( \".shp.xml\" ) or aggr_file . endswith ( \".sbn\" ) or aggr_file . endswith ( \".sbx\" ): # these are optional files for geo feature aggregation continue if not os . path . exists ( os . path . join ( agg_path , aggr_file )): raise Exception ( f \"Aggregation path ' { agg_path } ' is not a valid path. \" f \"Missing file ' { aggr_file } '\" ) file_path = self . _get_file_path ( agg_path ) return file_path def as_data_object ( self , agg_path : str ) -> 'fiona.Collection' : \"\"\" Loads the Geo Feature aggregation to a fiona Collection object :param agg_path: the path to the Geo Feature aggregation :return: the Geo Feature aggregation as a fiona Collection object \"\"\" if fiona is None : raise Exception ( \"fiona package was not found\" ) return self . _get_data_object ( agg_path = agg_path , func = fiona . open ) def save_data_object ( self , resource : 'Resource' , agg_path : str , as_new_aggr : bool = False , destination_path : str = \"\" ) -> 'Aggregation' : \"\"\" Saves the fiona Collection object to the Geo Feature aggregation :param resource: the resource containing the aggregation :param agg_path: the path to the Geo Feature aggregation :param as_new_aggr: Defaults False, set to True to create a new Geo Feature aggregation :param destination_path: the destination path in Hydroshare to save the new aggregation :return: the updated or new Geo Feature aggregation \"\"\" def upload_shape_files ( main_file_path , dst_path = \"\" ): shp_file_dir_path = os . path . dirname ( main_file_path ) filename_starts_with = f \" { pathlib . Path ( main_file_path ) . stem } .\" shape_files = [] for item in os . listdir ( shp_file_dir_path ): if item . startswith ( filename_starts_with ): file_full_path = os . path . join ( shp_file_dir_path , item ) shape_files . append ( file_full_path ) if not dst_path : self . _update_aggregation ( resource , * shape_files ) else : resource . file_upload ( * shape_files , destination_path = dst_path ) self . _validate_aggregation_for_update ( resource , AggregationType . GeographicFeatureAggregation ) file_path = self . _validate_aggregation_path ( agg_path , for_save_data = True ) aggr_main_file_path = self . main_file_path data_object = self . _data_object # need to close the fiona.Collection object to free up access to all the original shape files data_object . close () if not as_new_aggr : # cache some of the metadata fields of the original aggregation to update the metadata of the # updated aggregation keywords = self . metadata . subjects additional_meta = self . metadata . additional_metadata # copy the updated shape files to the original shape file location where the user downloaded the # aggregation previously src_shp_file_dir_path = os . path . dirname ( file_path ) tgt_shp_file_dir_path = os . path . dirname ( data_object . path ) filename_starts_with = f \" { pathlib . Path ( file_path ) . stem } .\" for item in os . listdir ( src_shp_file_dir_path ): if item . startswith ( filename_starts_with ): src_file_full_path = os . path . join ( src_shp_file_dir_path , item ) tgt_file_full_path = os . path . join ( tgt_shp_file_dir_path , item ) shutil . copyfile ( src_file_full_path , tgt_file_full_path ) # upload the updated shape files to replace this aggregation upload_shape_files ( main_file_path = data_object . path ) # retrieve the updated aggregation aggr = resource . aggregation ( file__path = aggr_main_file_path ) # update aggregation metadata for kw in keywords : if kw not in aggr . metadata . subjects : aggr . metadata . subjects . append ( kw ) aggr . metadata . additional_metadata = additional_meta aggr . save () else : # upload the updated shape files to create a new geo feature aggregation upload_shape_files ( main_file_path = file_path , dst_path = destination_path ) # retrieve the new aggregation agg_path = urljoin ( destination_path , os . path . basename ( aggr_main_file_path )) aggr = resource . aggregation ( file__path = agg_path ) aggr . _data_object = None return aggr as_data_object ( agg_path ) Loads the Geo Feature aggregation to a fiona Collection object :param agg_path: the path to the Geo Feature aggregation :return: the Geo Feature aggregation as a fiona Collection object Source code in hsclient\\hydroshare.py def as_data_object ( self , agg_path : str ) -> 'fiona.Collection' : \"\"\" Loads the Geo Feature aggregation to a fiona Collection object :param agg_path: the path to the Geo Feature aggregation :return: the Geo Feature aggregation as a fiona Collection object \"\"\" if fiona is None : raise Exception ( \"fiona package was not found\" ) return self . _get_data_object ( agg_path = agg_path , func = fiona . open ) save_data_object ( resource , agg_path , as_new_aggr = False , destination_path = '' ) Saves the fiona Collection object to the Geo Feature aggregation :param resource: the resource containing the aggregation :param agg_path: the path to the Geo Feature aggregation :param as_new_aggr: Defaults False, set to True to create a new Geo Feature aggregation :param destination_path: the destination path in Hydroshare to save the new aggregation :return: the updated or new Geo Feature aggregation Source code in hsclient\\hydroshare.py def save_data_object ( self , resource : 'Resource' , agg_path : str , as_new_aggr : bool = False , destination_path : str = \"\" ) -> 'Aggregation' : \"\"\" Saves the fiona Collection object to the Geo Feature aggregation :param resource: the resource containing the aggregation :param agg_path: the path to the Geo Feature aggregation :param as_new_aggr: Defaults False, set to True to create a new Geo Feature aggregation :param destination_path: the destination path in Hydroshare to save the new aggregation :return: the updated or new Geo Feature aggregation \"\"\" def upload_shape_files ( main_file_path , dst_path = \"\" ): shp_file_dir_path = os . path . dirname ( main_file_path ) filename_starts_with = f \" { pathlib . Path ( main_file_path ) . stem } .\" shape_files = [] for item in os . listdir ( shp_file_dir_path ): if item . startswith ( filename_starts_with ): file_full_path = os . path . join ( shp_file_dir_path , item ) shape_files . append ( file_full_path ) if not dst_path : self . _update_aggregation ( resource , * shape_files ) else : resource . file_upload ( * shape_files , destination_path = dst_path ) self . _validate_aggregation_for_update ( resource , AggregationType . GeographicFeatureAggregation ) file_path = self . _validate_aggregation_path ( agg_path , for_save_data = True ) aggr_main_file_path = self . main_file_path data_object = self . _data_object # need to close the fiona.Collection object to free up access to all the original shape files data_object . close () if not as_new_aggr : # cache some of the metadata fields of the original aggregation to update the metadata of the # updated aggregation keywords = self . metadata . subjects additional_meta = self . metadata . additional_metadata # copy the updated shape files to the original shape file location where the user downloaded the # aggregation previously src_shp_file_dir_path = os . path . dirname ( file_path ) tgt_shp_file_dir_path = os . path . dirname ( data_object . path ) filename_starts_with = f \" { pathlib . Path ( file_path ) . stem } .\" for item in os . listdir ( src_shp_file_dir_path ): if item . startswith ( filename_starts_with ): src_file_full_path = os . path . join ( src_shp_file_dir_path , item ) tgt_file_full_path = os . path . join ( tgt_shp_file_dir_path , item ) shutil . copyfile ( src_file_full_path , tgt_file_full_path ) # upload the updated shape files to replace this aggregation upload_shape_files ( main_file_path = data_object . path ) # retrieve the updated aggregation aggr = resource . aggregation ( file__path = aggr_main_file_path ) # update aggregation metadata for kw in keywords : if kw not in aggr . metadata . subjects : aggr . metadata . subjects . append ( kw ) aggr . metadata . additional_metadata = additional_meta aggr . save () else : # upload the updated shape files to create a new geo feature aggregation upload_shape_files ( main_file_path = file_path , dst_path = destination_path ) # retrieve the new aggregation agg_path = urljoin ( destination_path , os . path . basename ( aggr_main_file_path )) aggr = resource . aggregation ( file__path = agg_path ) aggr . _data_object = None return aggr","title":"Geographic Feature Aggregation"},{"location":"api/geo_feature_aggregation/#hsclient.hydroshare.GeoFeatureAggregation.as_data_object","text":"Loads the Geo Feature aggregation to a fiona Collection object :param agg_path: the path to the Geo Feature aggregation :return: the Geo Feature aggregation as a fiona Collection object Source code in hsclient\\hydroshare.py def as_data_object ( self , agg_path : str ) -> 'fiona.Collection' : \"\"\" Loads the Geo Feature aggregation to a fiona Collection object :param agg_path: the path to the Geo Feature aggregation :return: the Geo Feature aggregation as a fiona Collection object \"\"\" if fiona is None : raise Exception ( \"fiona package was not found\" ) return self . _get_data_object ( agg_path = agg_path , func = fiona . open )","title":"as_data_object"},{"location":"api/geo_feature_aggregation/#hsclient.hydroshare.GeoFeatureAggregation.save_data_object","text":"Saves the fiona Collection object to the Geo Feature aggregation :param resource: the resource containing the aggregation :param agg_path: the path to the Geo Feature aggregation :param as_new_aggr: Defaults False, set to True to create a new Geo Feature aggregation :param destination_path: the destination path in Hydroshare to save the new aggregation :return: the updated or new Geo Feature aggregation Source code in hsclient\\hydroshare.py def save_data_object ( self , resource : 'Resource' , agg_path : str , as_new_aggr : bool = False , destination_path : str = \"\" ) -> 'Aggregation' : \"\"\" Saves the fiona Collection object to the Geo Feature aggregation :param resource: the resource containing the aggregation :param agg_path: the path to the Geo Feature aggregation :param as_new_aggr: Defaults False, set to True to create a new Geo Feature aggregation :param destination_path: the destination path in Hydroshare to save the new aggregation :return: the updated or new Geo Feature aggregation \"\"\" def upload_shape_files ( main_file_path , dst_path = \"\" ): shp_file_dir_path = os . path . dirname ( main_file_path ) filename_starts_with = f \" { pathlib . Path ( main_file_path ) . stem } .\" shape_files = [] for item in os . listdir ( shp_file_dir_path ): if item . startswith ( filename_starts_with ): file_full_path = os . path . join ( shp_file_dir_path , item ) shape_files . append ( file_full_path ) if not dst_path : self . _update_aggregation ( resource , * shape_files ) else : resource . file_upload ( * shape_files , destination_path = dst_path ) self . _validate_aggregation_for_update ( resource , AggregationType . GeographicFeatureAggregation ) file_path = self . _validate_aggregation_path ( agg_path , for_save_data = True ) aggr_main_file_path = self . main_file_path data_object = self . _data_object # need to close the fiona.Collection object to free up access to all the original shape files data_object . close () if not as_new_aggr : # cache some of the metadata fields of the original aggregation to update the metadata of the # updated aggregation keywords = self . metadata . subjects additional_meta = self . metadata . additional_metadata # copy the updated shape files to the original shape file location where the user downloaded the # aggregation previously src_shp_file_dir_path = os . path . dirname ( file_path ) tgt_shp_file_dir_path = os . path . dirname ( data_object . path ) filename_starts_with = f \" { pathlib . Path ( file_path ) . stem } .\" for item in os . listdir ( src_shp_file_dir_path ): if item . startswith ( filename_starts_with ): src_file_full_path = os . path . join ( src_shp_file_dir_path , item ) tgt_file_full_path = os . path . join ( tgt_shp_file_dir_path , item ) shutil . copyfile ( src_file_full_path , tgt_file_full_path ) # upload the updated shape files to replace this aggregation upload_shape_files ( main_file_path = data_object . path ) # retrieve the updated aggregation aggr = resource . aggregation ( file__path = aggr_main_file_path ) # update aggregation metadata for kw in keywords : if kw not in aggr . metadata . subjects : aggr . metadata . subjects . append ( kw ) aggr . metadata . additional_metadata = additional_meta aggr . save () else : # upload the updated shape files to create a new geo feature aggregation upload_shape_files ( main_file_path = file_path , dst_path = destination_path ) # retrieve the new aggregation agg_path = urljoin ( destination_path , os . path . basename ( aggr_main_file_path )) aggr = resource . aggregation ( file__path = agg_path ) aggr . _data_object = None return aggr","title":"save_data_object"},{"location":"api/geo_raster_aggregation/","text":"Bases: DataObjectSupportingAggregation Represents a Geo Raster Aggregation in HydroShare Source code in hsclient\\hydroshare.py class GeoRasterAggregation ( DataObjectSupportingAggregation ): \"\"\"Represents a Geo Raster Aggregation in HydroShare\"\"\" @classmethod def create ( cls , base_aggr ): return super () . create ( aggr_cls = cls , base_aggr = base_aggr ) def _compute_updated_aggregation_path ( self , temp_folder , * files ) -> str : file_path = \"\" for _file in files : filename = os . path . basename ( _file ) if filename . endswith ( \".vrt\" ): file_path = urljoin ( temp_folder , filename ) break else : filename = pathlib . Path ( filename ) . stem + \".vrt\" file_path = urljoin ( temp_folder , filename ) break return file_path def _validate_aggregation_path ( self , agg_path : str , for_save_data : bool = False ) -> str : if for_save_data : tif_file_count = 0 vrt_file_count = 0 tif_file_path = \"\" vrt_file_path = \"\" for item in os . listdir ( agg_path ): item_full_path = os . path . join ( agg_path , item ) if os . path . isfile ( item_full_path ): file_ext = pathlib . Path ( item_full_path ) . suffix . lower () if file_ext in ( \".tif\" , \".tiff\" ): tif_file_count += 1 tif_file_path = item_full_path elif file_ext == '.vrt' : vrt_file_path = item_full_path vrt_file_count += 1 if vrt_file_count > 1 : raise Exception ( f \"Aggregation path ' { agg_path } ' is not a valid path. \" f \"More than one vrt was file found\" ) else : raise Exception ( f \"Aggregation path ' { agg_path } ' is not a valid path. \" f \"There are files that are not of raster file types\" ) if tif_file_count == 0 : raise Exception ( f \"Aggregation path ' { agg_path } ' is not a valid path. \" f \"No tif file was found\" ) if tif_file_count > 1 and vrt_file_count == 0 : raise Exception ( f \"Aggregation path ' { agg_path } ' is not a valid path. \" f \"Missing a vrt file\" ) if vrt_file_path : file_path = vrt_file_path else : file_path = tif_file_path else : file_path = self . _get_file_path ( agg_path ) return file_path def as_data_object ( self , agg_path : str ) -> 'rasterio.DatasetReader' : \"\"\" Loads the Geo Raster aggregation to a rasterio DatasetReader object :param agg_path: the path to the Geo Raster aggregation :return: the Geo Raster aggregation as a rasterio DatasetReader object \"\"\" if rasterio is None : raise Exception ( \"rasterio package was not found\" ) return self . _get_data_object ( agg_path = agg_path , func = rasterio . open ) def save_data_object ( self , resource : 'Resource' , agg_path : str , as_new_aggr : bool = False , destination_path : str = \"\" ) -> 'Aggregation' : \"\"\" Saves the rasterio DatasetReader object to the Geo Raster aggregation :param resource: the resource containing the aggregation :param agg_path: the path to the Geo Raster aggregation :param as_new_aggr: Defaults False, set to True to create a new Geo Raster aggregation :param destination_path: the destination path in Hydroshare to save the new aggregation :return: the updated or new Geo Raster aggregation \"\"\" def upload_raster_files ( dst_path = \"\" ): raster_files = [] for item in os . listdir ( agg_path ): item_full_path = os . path . join ( agg_path , item ) if os . path . isfile ( item_full_path ): raster_files . append ( item_full_path ) if not dst_path : self . _update_aggregation ( resource , * raster_files ) else : resource . file_upload ( * raster_files , destination_path = dst_path ) def get_main_file_path (): main_file_name = os . path . basename ( file_path ) if not main_file_name . lower () . endswith ( '.vrt' ): main_file_name = pathlib . Path ( main_file_name ) . stem + \".vrt\" if destination_path : aggr_main_file_path = os . path . join ( destination_path , main_file_name ) else : aggr_main_file_path = main_file_name return aggr_main_file_path self . _validate_aggregation_for_update ( resource , AggregationType . GeographicRasterAggregation ) file_path = self . _validate_aggregation_path ( agg_path , for_save_data = True ) if not as_new_aggr : destination_path = dirname ( self . main_file_path ) # cache some of the metadata fields of the original aggregation to update the metadata of the # updated aggregation keywords = self . metadata . subjects additional_meta = self . metadata . additional_metadata upload_raster_files ( dst_path = destination_path ) aggr_main_file_path = get_main_file_path () # retrieve the updated aggregation aggr = resource . aggregation ( file__path = aggr_main_file_path ) # update metadata for kw in keywords : if kw not in aggr . metadata . subjects : aggr . metadata . subjects . append ( kw ) aggr . metadata . additional_metadata = additional_meta aggr . save () else : # creating a new aggregation by uploading the updated data files upload_raster_files ( dst_path = destination_path ) # retrieve the new aggregation aggr_main_file_path = get_main_file_path () agg_path = urljoin ( destination_path , os . path . basename ( aggr_main_file_path )) aggr = resource . aggregation ( file__path = agg_path ) aggr . _data_object = None return aggr as_data_object ( agg_path ) Loads the Geo Raster aggregation to a rasterio DatasetReader object :param agg_path: the path to the Geo Raster aggregation :return: the Geo Raster aggregation as a rasterio DatasetReader object Source code in hsclient\\hydroshare.py def as_data_object ( self , agg_path : str ) -> 'rasterio.DatasetReader' : \"\"\" Loads the Geo Raster aggregation to a rasterio DatasetReader object :param agg_path: the path to the Geo Raster aggregation :return: the Geo Raster aggregation as a rasterio DatasetReader object \"\"\" if rasterio is None : raise Exception ( \"rasterio package was not found\" ) return self . _get_data_object ( agg_path = agg_path , func = rasterio . open ) save_data_object ( resource , agg_path , as_new_aggr = False , destination_path = '' ) Saves the rasterio DatasetReader object to the Geo Raster aggregation :param resource: the resource containing the aggregation :param agg_path: the path to the Geo Raster aggregation :param as_new_aggr: Defaults False, set to True to create a new Geo Raster aggregation :param destination_path: the destination path in Hydroshare to save the new aggregation :return: the updated or new Geo Raster aggregation Source code in hsclient\\hydroshare.py def save_data_object ( self , resource : 'Resource' , agg_path : str , as_new_aggr : bool = False , destination_path : str = \"\" ) -> 'Aggregation' : \"\"\" Saves the rasterio DatasetReader object to the Geo Raster aggregation :param resource: the resource containing the aggregation :param agg_path: the path to the Geo Raster aggregation :param as_new_aggr: Defaults False, set to True to create a new Geo Raster aggregation :param destination_path: the destination path in Hydroshare to save the new aggregation :return: the updated or new Geo Raster aggregation \"\"\" def upload_raster_files ( dst_path = \"\" ): raster_files = [] for item in os . listdir ( agg_path ): item_full_path = os . path . join ( agg_path , item ) if os . path . isfile ( item_full_path ): raster_files . append ( item_full_path ) if not dst_path : self . _update_aggregation ( resource , * raster_files ) else : resource . file_upload ( * raster_files , destination_path = dst_path ) def get_main_file_path (): main_file_name = os . path . basename ( file_path ) if not main_file_name . lower () . endswith ( '.vrt' ): main_file_name = pathlib . Path ( main_file_name ) . stem + \".vrt\" if destination_path : aggr_main_file_path = os . path . join ( destination_path , main_file_name ) else : aggr_main_file_path = main_file_name return aggr_main_file_path self . _validate_aggregation_for_update ( resource , AggregationType . GeographicRasterAggregation ) file_path = self . _validate_aggregation_path ( agg_path , for_save_data = True ) if not as_new_aggr : destination_path = dirname ( self . main_file_path ) # cache some of the metadata fields of the original aggregation to update the metadata of the # updated aggregation keywords = self . metadata . subjects additional_meta = self . metadata . additional_metadata upload_raster_files ( dst_path = destination_path ) aggr_main_file_path = get_main_file_path () # retrieve the updated aggregation aggr = resource . aggregation ( file__path = aggr_main_file_path ) # update metadata for kw in keywords : if kw not in aggr . metadata . subjects : aggr . metadata . subjects . append ( kw ) aggr . metadata . additional_metadata = additional_meta aggr . save () else : # creating a new aggregation by uploading the updated data files upload_raster_files ( dst_path = destination_path ) # retrieve the new aggregation aggr_main_file_path = get_main_file_path () agg_path = urljoin ( destination_path , os . path . basename ( aggr_main_file_path )) aggr = resource . aggregation ( file__path = agg_path ) aggr . _data_object = None return aggr","title":"Geographic Raster Aggregation"},{"location":"api/geo_raster_aggregation/#hsclient.hydroshare.GeoRasterAggregation.as_data_object","text":"Loads the Geo Raster aggregation to a rasterio DatasetReader object :param agg_path: the path to the Geo Raster aggregation :return: the Geo Raster aggregation as a rasterio DatasetReader object Source code in hsclient\\hydroshare.py def as_data_object ( self , agg_path : str ) -> 'rasterio.DatasetReader' : \"\"\" Loads the Geo Raster aggregation to a rasterio DatasetReader object :param agg_path: the path to the Geo Raster aggregation :return: the Geo Raster aggregation as a rasterio DatasetReader object \"\"\" if rasterio is None : raise Exception ( \"rasterio package was not found\" ) return self . _get_data_object ( agg_path = agg_path , func = rasterio . open )","title":"as_data_object"},{"location":"api/geo_raster_aggregation/#hsclient.hydroshare.GeoRasterAggregation.save_data_object","text":"Saves the rasterio DatasetReader object to the Geo Raster aggregation :param resource: the resource containing the aggregation :param agg_path: the path to the Geo Raster aggregation :param as_new_aggr: Defaults False, set to True to create a new Geo Raster aggregation :param destination_path: the destination path in Hydroshare to save the new aggregation :return: the updated or new Geo Raster aggregation Source code in hsclient\\hydroshare.py def save_data_object ( self , resource : 'Resource' , agg_path : str , as_new_aggr : bool = False , destination_path : str = \"\" ) -> 'Aggregation' : \"\"\" Saves the rasterio DatasetReader object to the Geo Raster aggregation :param resource: the resource containing the aggregation :param agg_path: the path to the Geo Raster aggregation :param as_new_aggr: Defaults False, set to True to create a new Geo Raster aggregation :param destination_path: the destination path in Hydroshare to save the new aggregation :return: the updated or new Geo Raster aggregation \"\"\" def upload_raster_files ( dst_path = \"\" ): raster_files = [] for item in os . listdir ( agg_path ): item_full_path = os . path . join ( agg_path , item ) if os . path . isfile ( item_full_path ): raster_files . append ( item_full_path ) if not dst_path : self . _update_aggregation ( resource , * raster_files ) else : resource . file_upload ( * raster_files , destination_path = dst_path ) def get_main_file_path (): main_file_name = os . path . basename ( file_path ) if not main_file_name . lower () . endswith ( '.vrt' ): main_file_name = pathlib . Path ( main_file_name ) . stem + \".vrt\" if destination_path : aggr_main_file_path = os . path . join ( destination_path , main_file_name ) else : aggr_main_file_path = main_file_name return aggr_main_file_path self . _validate_aggregation_for_update ( resource , AggregationType . GeographicRasterAggregation ) file_path = self . _validate_aggregation_path ( agg_path , for_save_data = True ) if not as_new_aggr : destination_path = dirname ( self . main_file_path ) # cache some of the metadata fields of the original aggregation to update the metadata of the # updated aggregation keywords = self . metadata . subjects additional_meta = self . metadata . additional_metadata upload_raster_files ( dst_path = destination_path ) aggr_main_file_path = get_main_file_path () # retrieve the updated aggregation aggr = resource . aggregation ( file__path = aggr_main_file_path ) # update metadata for kw in keywords : if kw not in aggr . metadata . subjects : aggr . metadata . subjects . append ( kw ) aggr . metadata . additional_metadata = additional_meta aggr . save () else : # creating a new aggregation by uploading the updated data files upload_raster_files ( dst_path = destination_path ) # retrieve the new aggregation aggr_main_file_path = get_main_file_path () agg_path = urljoin ( destination_path , os . path . basename ( aggr_main_file_path )) aggr = resource . aggregation ( file__path = agg_path ) aggr . _data_object = None return aggr","title":"save_data_object"},{"location":"api/hydroshare/","text":"A HydroShare object for querying HydroShare's REST API. Provide a username and password at initialization or call the sign_in() method to prompt for the username and password. If using OAuth2 is desired, provide the client_id and token to use. If on CUAHSI JupyterHub or another JupyterHub environment that authenticates with Hydroshare, call the hs_juptyerhub() method to read the credentials from Jupyterhub. :param username: A HydroShare username :param password: A HydroShare password associated with the username :param host: The host to use, defaults to www.hydroshare.org :param protocol: The protocol to use, defaults to https :param port: The port to use, defaults to 443 :param client_id: The client id associated with the OAuth2 token :param token: The OAuth2 token to use Source code in hsclient\\hydroshare.py class HydroShare : \"\"\" A HydroShare object for querying HydroShare's REST API. Provide a username and password at initialization or call the sign_in() method to prompt for the username and password. If using OAuth2 is desired, provide the client_id and token to use. If on CUAHSI JupyterHub or another JupyterHub environment that authenticates with Hydroshare, call the hs_juptyerhub() method to read the credentials from Jupyterhub. :param username: A HydroShare username :param password: A HydroShare password associated with the username :param host: The host to use, defaults to `www.hydroshare.org` :param protocol: The protocol to use, defaults to `https` :param port: The port to use, defaults to `443` :param client_id: The client id associated with the OAuth2 token :param token: The OAuth2 token to use \"\"\" default_host = 'www.hydroshare.org' default_protocol = \"https\" default_port = 443 def __init__ ( self , username : str = None , password : str = None , host : str = default_host , protocol : str = default_protocol , port : int = default_port , client_id : str = None , token : Union [ Token , Dict [ str , str ]] = None , ): if client_id or token : if not client_id or not token : raise ValueError ( \"Oauth2 requires a client_id to be paired with a token\" ) else : self . _hs_session = HydroShareSession ( host = host , protocol = protocol , port = port , client_id = client_id , token = token ) self . my_user_info () # validate credentials else : self . _hs_session = HydroShareSession ( username = username , password = password , host = host , protocol = protocol , port = port ) if username or password : self . my_user_info () # validate credentials self . _resource_object_cache : Dict [ str , Resource ] = dict () def sign_in ( self ) -> None : \"\"\"Prompts for username/password. Useful for avoiding saving your HydroShare credentials to a notebook\"\"\" username = input ( \"Username: \" ) . strip () password = getpass . getpass ( \"Password for {} : \" . format ( username )) self . _hs_session . set_auth (( username , password )) self . my_user_info () # validate credentials @classmethod def hs_juptyerhub ( cls , hs_auth_path = \"/home/jovyan/data/.hs_auth\" ): \"\"\" Create a new HydroShare object using OAuth2 credentials stored in a canonical CUAHSI Jupyterhub OAuth2 pickle file (stored at :param hs_auth_path:). Provide a non-default (default: `/home/jovyan/data/.hs_auth`) path to the hs_auth file with :param hs_auth_path:. \"\"\" if not os . path . isfile ( hs_auth_path ): raise ValueError ( f \"hs_auth_path { hs_auth_path } does not exist.\" ) with open ( hs_auth_path , 'rb' ) as f : token , client_id = pickle . load ( f ) instance = cls ( client_id = client_id , token = token ) instance . my_user_info () # validate credentials return instance def search ( self , creator : str = None , contributor : str = None , owner : str = None , group_name : str = None , from_date : datetime = None , to_date : datetime = None , edit_permission : bool = False , resource_types : List [ str ] = [], subject : List [ str ] = [], full_text_search : str = None , published : bool = False , spatial_coverage : Union [ BoxCoverage , PointCoverage ] = None , ): \"\"\" Query the GET /hsapi/resource/ REST end point of the HydroShare server. :param creator: Filter results by the HydroShare username or email :param author: Filter results by the HydroShare username or email :param owner: Filter results by the HydroShare username or email :param group_name: Filter results by the HydroShare group name associated with resources :param from_date: Filter results to those created after from_date. Must be datetime.date. :param to_date: Filter results to those created before to_date. Must be datetime.date. Because dates have no time information, you must specify date+1 day to get results for date (e.g. use 2015-05-06 to get resources created up to and including 2015-05-05) :param types: Filter results to particular HydroShare resource types (Deprecated, all types are Composite) :param subject: Filter by comma separated list of subjects :param full_text_search: Filter by full text search :param edit_permission: Filter by boolean edit permission :param published: Filter by boolean published status :param spatial_coverage: Filtering by spatial coverage raises a 500, do not use :return: A generator to iterate over a ResourcePreview object \"\"\" params = { \"edit_permission\" : edit_permission , \"published\" : published } if creator : params [ \"creator\" ] = creator if contributor : params [ \"author\" ] = contributor if owner : params [ \"owner\" ] = owner if group_name : params [ \"group\" ] = group_name if resource_types : params [ \"type[]\" ] = resource_types if subject : params [ \"subject\" ] = \",\" . join ( subject ) if full_text_search : params [ \"full_text_search\" ] = full_text_search if from_date : params [ \"from_date\" ] = from_date . strftime ( '%Y-%m- %d ' ) if to_date : params [ \"to_date\" ] = to_date . strftime ( '%Y-%m- %d ' ) if spatial_coverage : yield Exception ( \"Bad Request, status_code 400, spatial_coverage queries are disabled.\" ) # TODO: re-enable after resolution of https://github.com/hydroshare/hydroshare/issues/5240 # params[\"coverage_type\"] = spatial_coverage.type # if spatial_coverage.type == \"point\": # params[\"north\"] = spatial_coverage.north # params[\"east\"] = spatial_coverage.east # else: # params[\"north\"] = spatial_coverage.northlimit # params[\"east\"] = spatial_coverage.eastlimit # params[\"south\"] = spatial_coverage.southlimit # params[\"west\"] = spatial_coverage.westlimit response = self . _hs_session . get ( \"/hsapi/resource/\" , 200 , params = params ) res = response . json () results = res [ 'results' ] for item in results : yield ResourcePreview ( ** item ) while res [ 'next' ]: next_url = res [ 'next' ] next_url = urlparse ( next_url ) path = next_url . path params = next_url . query response = self . _hs_session . get ( path , 200 , params = params ) res = response . json () results = res [ 'results' ] for item in results : yield ResourcePreview ( ** item ) def resource ( self , resource_id : str , validate : bool = True , use_cache : bool = True ) -> Resource : \"\"\" Creates a resource object from HydroShare with the provided resource_id :param resource_id: The resource id of the resource to retrieve :param validate: Defaults to True, set to False to not validate the resource exists :param use_cache: Defaults to True, set to False to skip the cache, and always retrieve the resource from HydroShare. This parameter also does not cache the retrieved Resource object. :return: A Resource object representing a resource on HydroShare \"\"\" if resource_id in self . _resource_object_cache and use_cache : return self . _resource_object_cache [ resource_id ] res = Resource ( \"/resource/ {} /data/resourcemap.xml\" . format ( resource_id ), self . _hs_session ) if validate : res . metadata if use_cache : self . _resource_object_cache [ resource_id ] = res return res def create ( self , use_cache : bool = True ) -> Resource : \"\"\" Creates a new resource on HydroShare :param use_cache: Defaults to True, set to False to skip the cache, and always retrieve the resource from HydroShare. This parameter also does not cache the retrieved Resource object. :return: A Resource object representing a resource on HydroShare \"\"\" response = self . _hs_session . post ( '/hsapi/resource/' , status_code = 201 ) resource_id = response . json ()[ 'resource_id' ] return self . resource ( resource_id , use_cache = use_cache ) def user ( self , user_id : int ) -> User : \"\"\" Retrieves the user details of a Hydroshare user :param user_id: The user id of the user details to retrieve :return: User object representing the user details \"\"\" response = self . _hs_session . get ( f '/hsapi/userDetails/ { user_id } /' , status_code = 200 ) return User ( ** response . json ()) def my_user_info ( self ): \"\"\" Retrieves the user info of the user's credentials provided :return: JSON object representing the user info \"\"\" response = self . _hs_session . get ( '/hsapi/userInfo/' , status_code = 200 ) return response . json () create ( use_cache = True ) Creates a new resource on HydroShare :param use_cache: Defaults to True, set to False to skip the cache, and always retrieve the resource from HydroShare. This parameter also does not cache the retrieved Resource object. :return: A Resource object representing a resource on HydroShare Source code in hsclient\\hydroshare.py def create ( self , use_cache : bool = True ) -> Resource : \"\"\" Creates a new resource on HydroShare :param use_cache: Defaults to True, set to False to skip the cache, and always retrieve the resource from HydroShare. This parameter also does not cache the retrieved Resource object. :return: A Resource object representing a resource on HydroShare \"\"\" response = self . _hs_session . post ( '/hsapi/resource/' , status_code = 201 ) resource_id = response . json ()[ 'resource_id' ] return self . resource ( resource_id , use_cache = use_cache ) hs_juptyerhub ( hs_auth_path = '/home/jovyan/data/.hs_auth' ) classmethod Create a new HydroShare object using OAuth2 credentials stored in a canonical CUAHSI Jupyterhub OAuth2 pickle file (stored at :param hs_auth_path:). Provide a non-default (default: /home/jovyan/data/.hs_auth ) path to the hs_auth file with :param hs_auth_path:. Source code in hsclient\\hydroshare.py @classmethod def hs_juptyerhub ( cls , hs_auth_path = \"/home/jovyan/data/.hs_auth\" ): \"\"\" Create a new HydroShare object using OAuth2 credentials stored in a canonical CUAHSI Jupyterhub OAuth2 pickle file (stored at :param hs_auth_path:). Provide a non-default (default: `/home/jovyan/data/.hs_auth`) path to the hs_auth file with :param hs_auth_path:. \"\"\" if not os . path . isfile ( hs_auth_path ): raise ValueError ( f \"hs_auth_path { hs_auth_path } does not exist.\" ) with open ( hs_auth_path , 'rb' ) as f : token , client_id = pickle . load ( f ) instance = cls ( client_id = client_id , token = token ) instance . my_user_info () # validate credentials return instance my_user_info () Retrieves the user info of the user's credentials provided :return: JSON object representing the user info Source code in hsclient\\hydroshare.py def my_user_info ( self ): \"\"\" Retrieves the user info of the user's credentials provided :return: JSON object representing the user info \"\"\" response = self . _hs_session . get ( '/hsapi/userInfo/' , status_code = 200 ) return response . json () resource ( resource_id , validate = True , use_cache = True ) Creates a resource object from HydroShare with the provided resource_id :param resource_id: The resource id of the resource to retrieve :param validate: Defaults to True, set to False to not validate the resource exists :param use_cache: Defaults to True, set to False to skip the cache, and always retrieve the resource from HydroShare. This parameter also does not cache the retrieved Resource object. :return: A Resource object representing a resource on HydroShare Source code in hsclient\\hydroshare.py def resource ( self , resource_id : str , validate : bool = True , use_cache : bool = True ) -> Resource : \"\"\" Creates a resource object from HydroShare with the provided resource_id :param resource_id: The resource id of the resource to retrieve :param validate: Defaults to True, set to False to not validate the resource exists :param use_cache: Defaults to True, set to False to skip the cache, and always retrieve the resource from HydroShare. This parameter also does not cache the retrieved Resource object. :return: A Resource object representing a resource on HydroShare \"\"\" if resource_id in self . _resource_object_cache and use_cache : return self . _resource_object_cache [ resource_id ] res = Resource ( \"/resource/ {} /data/resourcemap.xml\" . format ( resource_id ), self . _hs_session ) if validate : res . metadata if use_cache : self . _resource_object_cache [ resource_id ] = res return res search ( creator = None , contributor = None , owner = None , group_name = None , from_date = None , to_date = None , edit_permission = False , resource_types = [], subject = [], full_text_search = None , published = False , spatial_coverage = None ) Query the GET /hsapi/resource/ REST end point of the HydroShare server. :param creator: Filter results by the HydroShare username or email :param author: Filter results by the HydroShare username or email :param owner: Filter results by the HydroShare username or email :param group_name: Filter results by the HydroShare group name associated with resources :param from_date: Filter results to those created after from_date. Must be datetime.date. :param to_date: Filter results to those created before to_date. Must be datetime.date. Because dates have no time information, you must specify date+1 day to get results for date (e.g. use 2015-05-06 to get resources created up to and including 2015-05-05) :param types: Filter results to particular HydroShare resource types (Deprecated, all types are Composite) :param subject: Filter by comma separated list of subjects :param full_text_search: Filter by full text search :param edit_permission: Filter by boolean edit permission :param published: Filter by boolean published status :param spatial_coverage: Filtering by spatial coverage raises a 500, do not use :return: A generator to iterate over a ResourcePreview object Source code in hsclient\\hydroshare.py def search ( self , creator : str = None , contributor : str = None , owner : str = None , group_name : str = None , from_date : datetime = None , to_date : datetime = None , edit_permission : bool = False , resource_types : List [ str ] = [], subject : List [ str ] = [], full_text_search : str = None , published : bool = False , spatial_coverage : Union [ BoxCoverage , PointCoverage ] = None , ): \"\"\" Query the GET /hsapi/resource/ REST end point of the HydroShare server. :param creator: Filter results by the HydroShare username or email :param author: Filter results by the HydroShare username or email :param owner: Filter results by the HydroShare username or email :param group_name: Filter results by the HydroShare group name associated with resources :param from_date: Filter results to those created after from_date. Must be datetime.date. :param to_date: Filter results to those created before to_date. Must be datetime.date. Because dates have no time information, you must specify date+1 day to get results for date (e.g. use 2015-05-06 to get resources created up to and including 2015-05-05) :param types: Filter results to particular HydroShare resource types (Deprecated, all types are Composite) :param subject: Filter by comma separated list of subjects :param full_text_search: Filter by full text search :param edit_permission: Filter by boolean edit permission :param published: Filter by boolean published status :param spatial_coverage: Filtering by spatial coverage raises a 500, do not use :return: A generator to iterate over a ResourcePreview object \"\"\" params = { \"edit_permission\" : edit_permission , \"published\" : published } if creator : params [ \"creator\" ] = creator if contributor : params [ \"author\" ] = contributor if owner : params [ \"owner\" ] = owner if group_name : params [ \"group\" ] = group_name if resource_types : params [ \"type[]\" ] = resource_types if subject : params [ \"subject\" ] = \",\" . join ( subject ) if full_text_search : params [ \"full_text_search\" ] = full_text_search if from_date : params [ \"from_date\" ] = from_date . strftime ( '%Y-%m- %d ' ) if to_date : params [ \"to_date\" ] = to_date . strftime ( '%Y-%m- %d ' ) if spatial_coverage : yield Exception ( \"Bad Request, status_code 400, spatial_coverage queries are disabled.\" ) # TODO: re-enable after resolution of https://github.com/hydroshare/hydroshare/issues/5240 # params[\"coverage_type\"] = spatial_coverage.type # if spatial_coverage.type == \"point\": # params[\"north\"] = spatial_coverage.north # params[\"east\"] = spatial_coverage.east # else: # params[\"north\"] = spatial_coverage.northlimit # params[\"east\"] = spatial_coverage.eastlimit # params[\"south\"] = spatial_coverage.southlimit # params[\"west\"] = spatial_coverage.westlimit response = self . _hs_session . get ( \"/hsapi/resource/\" , 200 , params = params ) res = response . json () results = res [ 'results' ] for item in results : yield ResourcePreview ( ** item ) while res [ 'next' ]: next_url = res [ 'next' ] next_url = urlparse ( next_url ) path = next_url . path params = next_url . query response = self . _hs_session . get ( path , 200 , params = params ) res = response . json () results = res [ 'results' ] for item in results : yield ResourcePreview ( ** item ) sign_in () Prompts for username/password. Useful for avoiding saving your HydroShare credentials to a notebook Source code in hsclient\\hydroshare.py def sign_in ( self ) -> None : \"\"\"Prompts for username/password. Useful for avoiding saving your HydroShare credentials to a notebook\"\"\" username = input ( \"Username: \" ) . strip () password = getpass . getpass ( \"Password for {} : \" . format ( username )) self . _hs_session . set_auth (( username , password )) self . my_user_info () # validate credentials user ( user_id ) Retrieves the user details of a Hydroshare user :param user_id: The user id of the user details to retrieve :return: User object representing the user details Source code in hsclient\\hydroshare.py def user ( self , user_id : int ) -> User : \"\"\" Retrieves the user details of a Hydroshare user :param user_id: The user id of the user details to retrieve :return: User object representing the user details \"\"\" response = self . _hs_session . get ( f '/hsapi/userDetails/ { user_id } /' , status_code = 200 ) return User ( ** response . json ())","title":"HydroShare"},{"location":"api/hydroshare/#hsclient.hydroshare.HydroShare.create","text":"Creates a new resource on HydroShare :param use_cache: Defaults to True, set to False to skip the cache, and always retrieve the resource from HydroShare. This parameter also does not cache the retrieved Resource object. :return: A Resource object representing a resource on HydroShare Source code in hsclient\\hydroshare.py def create ( self , use_cache : bool = True ) -> Resource : \"\"\" Creates a new resource on HydroShare :param use_cache: Defaults to True, set to False to skip the cache, and always retrieve the resource from HydroShare. This parameter also does not cache the retrieved Resource object. :return: A Resource object representing a resource on HydroShare \"\"\" response = self . _hs_session . post ( '/hsapi/resource/' , status_code = 201 ) resource_id = response . json ()[ 'resource_id' ] return self . resource ( resource_id , use_cache = use_cache )","title":"create"},{"location":"api/hydroshare/#hsclient.hydroshare.HydroShare.hs_juptyerhub","text":"Create a new HydroShare object using OAuth2 credentials stored in a canonical CUAHSI Jupyterhub OAuth2 pickle file (stored at :param hs_auth_path:). Provide a non-default (default: /home/jovyan/data/.hs_auth ) path to the hs_auth file with :param hs_auth_path:. Source code in hsclient\\hydroshare.py @classmethod def hs_juptyerhub ( cls , hs_auth_path = \"/home/jovyan/data/.hs_auth\" ): \"\"\" Create a new HydroShare object using OAuth2 credentials stored in a canonical CUAHSI Jupyterhub OAuth2 pickle file (stored at :param hs_auth_path:). Provide a non-default (default: `/home/jovyan/data/.hs_auth`) path to the hs_auth file with :param hs_auth_path:. \"\"\" if not os . path . isfile ( hs_auth_path ): raise ValueError ( f \"hs_auth_path { hs_auth_path } does not exist.\" ) with open ( hs_auth_path , 'rb' ) as f : token , client_id = pickle . load ( f ) instance = cls ( client_id = client_id , token = token ) instance . my_user_info () # validate credentials return instance","title":"hs_juptyerhub"},{"location":"api/hydroshare/#hsclient.hydroshare.HydroShare.my_user_info","text":"Retrieves the user info of the user's credentials provided :return: JSON object representing the user info Source code in hsclient\\hydroshare.py def my_user_info ( self ): \"\"\" Retrieves the user info of the user's credentials provided :return: JSON object representing the user info \"\"\" response = self . _hs_session . get ( '/hsapi/userInfo/' , status_code = 200 ) return response . json ()","title":"my_user_info"},{"location":"api/hydroshare/#hsclient.hydroshare.HydroShare.resource","text":"Creates a resource object from HydroShare with the provided resource_id :param resource_id: The resource id of the resource to retrieve :param validate: Defaults to True, set to False to not validate the resource exists :param use_cache: Defaults to True, set to False to skip the cache, and always retrieve the resource from HydroShare. This parameter also does not cache the retrieved Resource object. :return: A Resource object representing a resource on HydroShare Source code in hsclient\\hydroshare.py def resource ( self , resource_id : str , validate : bool = True , use_cache : bool = True ) -> Resource : \"\"\" Creates a resource object from HydroShare with the provided resource_id :param resource_id: The resource id of the resource to retrieve :param validate: Defaults to True, set to False to not validate the resource exists :param use_cache: Defaults to True, set to False to skip the cache, and always retrieve the resource from HydroShare. This parameter also does not cache the retrieved Resource object. :return: A Resource object representing a resource on HydroShare \"\"\" if resource_id in self . _resource_object_cache and use_cache : return self . _resource_object_cache [ resource_id ] res = Resource ( \"/resource/ {} /data/resourcemap.xml\" . format ( resource_id ), self . _hs_session ) if validate : res . metadata if use_cache : self . _resource_object_cache [ resource_id ] = res return res","title":"resource"},{"location":"api/hydroshare/#hsclient.hydroshare.HydroShare.search","text":"Query the GET /hsapi/resource/ REST end point of the HydroShare server. :param creator: Filter results by the HydroShare username or email :param author: Filter results by the HydroShare username or email :param owner: Filter results by the HydroShare username or email :param group_name: Filter results by the HydroShare group name associated with resources :param from_date: Filter results to those created after from_date. Must be datetime.date. :param to_date: Filter results to those created before to_date. Must be datetime.date. Because dates have no time information, you must specify date+1 day to get results for date (e.g. use 2015-05-06 to get resources created up to and including 2015-05-05) :param types: Filter results to particular HydroShare resource types (Deprecated, all types are Composite) :param subject: Filter by comma separated list of subjects :param full_text_search: Filter by full text search :param edit_permission: Filter by boolean edit permission :param published: Filter by boolean published status :param spatial_coverage: Filtering by spatial coverage raises a 500, do not use :return: A generator to iterate over a ResourcePreview object Source code in hsclient\\hydroshare.py def search ( self , creator : str = None , contributor : str = None , owner : str = None , group_name : str = None , from_date : datetime = None , to_date : datetime = None , edit_permission : bool = False , resource_types : List [ str ] = [], subject : List [ str ] = [], full_text_search : str = None , published : bool = False , spatial_coverage : Union [ BoxCoverage , PointCoverage ] = None , ): \"\"\" Query the GET /hsapi/resource/ REST end point of the HydroShare server. :param creator: Filter results by the HydroShare username or email :param author: Filter results by the HydroShare username or email :param owner: Filter results by the HydroShare username or email :param group_name: Filter results by the HydroShare group name associated with resources :param from_date: Filter results to those created after from_date. Must be datetime.date. :param to_date: Filter results to those created before to_date. Must be datetime.date. Because dates have no time information, you must specify date+1 day to get results for date (e.g. use 2015-05-06 to get resources created up to and including 2015-05-05) :param types: Filter results to particular HydroShare resource types (Deprecated, all types are Composite) :param subject: Filter by comma separated list of subjects :param full_text_search: Filter by full text search :param edit_permission: Filter by boolean edit permission :param published: Filter by boolean published status :param spatial_coverage: Filtering by spatial coverage raises a 500, do not use :return: A generator to iterate over a ResourcePreview object \"\"\" params = { \"edit_permission\" : edit_permission , \"published\" : published } if creator : params [ \"creator\" ] = creator if contributor : params [ \"author\" ] = contributor if owner : params [ \"owner\" ] = owner if group_name : params [ \"group\" ] = group_name if resource_types : params [ \"type[]\" ] = resource_types if subject : params [ \"subject\" ] = \",\" . join ( subject ) if full_text_search : params [ \"full_text_search\" ] = full_text_search if from_date : params [ \"from_date\" ] = from_date . strftime ( '%Y-%m- %d ' ) if to_date : params [ \"to_date\" ] = to_date . strftime ( '%Y-%m- %d ' ) if spatial_coverage : yield Exception ( \"Bad Request, status_code 400, spatial_coverage queries are disabled.\" ) # TODO: re-enable after resolution of https://github.com/hydroshare/hydroshare/issues/5240 # params[\"coverage_type\"] = spatial_coverage.type # if spatial_coverage.type == \"point\": # params[\"north\"] = spatial_coverage.north # params[\"east\"] = spatial_coverage.east # else: # params[\"north\"] = spatial_coverage.northlimit # params[\"east\"] = spatial_coverage.eastlimit # params[\"south\"] = spatial_coverage.southlimit # params[\"west\"] = spatial_coverage.westlimit response = self . _hs_session . get ( \"/hsapi/resource/\" , 200 , params = params ) res = response . json () results = res [ 'results' ] for item in results : yield ResourcePreview ( ** item ) while res [ 'next' ]: next_url = res [ 'next' ] next_url = urlparse ( next_url ) path = next_url . path params = next_url . query response = self . _hs_session . get ( path , 200 , params = params ) res = response . json () results = res [ 'results' ] for item in results : yield ResourcePreview ( ** item )","title":"search"},{"location":"api/hydroshare/#hsclient.hydroshare.HydroShare.sign_in","text":"Prompts for username/password. Useful for avoiding saving your HydroShare credentials to a notebook Source code in hsclient\\hydroshare.py def sign_in ( self ) -> None : \"\"\"Prompts for username/password. Useful for avoiding saving your HydroShare credentials to a notebook\"\"\" username = input ( \"Username: \" ) . strip () password = getpass . getpass ( \"Password for {} : \" . format ( username )) self . _hs_session . set_auth (( username , password )) self . my_user_info () # validate credentials","title":"sign_in"},{"location":"api/hydroshare/#hsclient.hydroshare.HydroShare.user","text":"Retrieves the user details of a Hydroshare user :param user_id: The user id of the user details to retrieve :return: User object representing the user details Source code in hsclient\\hydroshare.py def user ( self , user_id : int ) -> User : \"\"\" Retrieves the user details of a Hydroshare user :param user_id: The user id of the user details to retrieve :return: User object representing the user details \"\"\" response = self . _hs_session . get ( f '/hsapi/userDetails/ { user_id } /' , status_code = 200 ) return User ( ** response . json ())","title":"user"},{"location":"api/netcdf_aggregation/","text":"Bases: DataObjectSupportingAggregation Represents a Multidimensional Aggregation in HydroShare Source code in hsclient\\hydroshare.py class NetCDFAggregation ( DataObjectSupportingAggregation ): \"\"\"Represents a Multidimensional Aggregation in HydroShare\"\"\" @classmethod def create ( cls , base_aggr ): return super () . create ( aggr_cls = cls , base_aggr = base_aggr ) def as_data_object ( self , agg_path : str ) -> 'xarray.Dataset' : \"\"\" Loads the Multidimensional aggregation to a xarray Dataset object :param agg_path: the path to the Multidimensional aggregation :return: the Multidimensional aggregation as a xarray Dataset object \"\"\" if xarray is None : raise Exception ( \"xarray package was not found\" ) return self . _get_data_object ( agg_path = agg_path , func = xarray . open_dataset ) def save_data_object ( self , resource : 'Resource' , agg_path : str , as_new_aggr : bool = False , destination_path : str = \"\" ) -> 'Aggregation' : \"\"\" Saves the xarray Dataset object to the Multidimensional aggregation :param resource: the resource containing the aggregation :param agg_path: the path to the Multidimensional aggregation :param as_new_aggr: Defaults False, set to True to create a new Multidimensional aggregation :param destination_path: the destination path in Hydroshare to save the new aggregation :return: the updated or new Multidimensional aggregation \"\"\" self . _validate_aggregation_for_update ( resource , AggregationType . MultidimensionalAggregation ) file_path = self . _validate_aggregation_path ( agg_path , for_save_data = True ) self . _data_object . to_netcdf ( file_path , format = \"NETCDF4\" ) aggr_main_file_path = self . main_file_path if not as_new_aggr : # cache some of the metadata fields of the original aggregation to update the metadata of the # updated aggregation keywords = self . metadata . subjects additional_meta = self . metadata . additional_metadata # upload the updated aggregation files self . _update_aggregation ( resource , file_path ) # retrieve the updated aggregation aggr = resource . aggregation ( file__path = aggr_main_file_path ) # update metadata for kw in keywords : if kw not in aggr . metadata . subjects : aggr . metadata . subjects . append ( kw ) aggr . metadata . additional_metadata = additional_meta aggr . save () else : # creating a new aggregation resource . file_upload ( file_path , destination_path = destination_path ) # retrieve the new aggregation agg_path = urljoin ( destination_path , os . path . basename ( aggr_main_file_path )) aggr = resource . aggregation ( file__path = agg_path ) aggr . _data_object = None return aggr as_data_object ( agg_path ) Loads the Multidimensional aggregation to a xarray Dataset object :param agg_path: the path to the Multidimensional aggregation :return: the Multidimensional aggregation as a xarray Dataset object Source code in hsclient\\hydroshare.py def as_data_object ( self , agg_path : str ) -> 'xarray.Dataset' : \"\"\" Loads the Multidimensional aggregation to a xarray Dataset object :param agg_path: the path to the Multidimensional aggregation :return: the Multidimensional aggregation as a xarray Dataset object \"\"\" if xarray is None : raise Exception ( \"xarray package was not found\" ) return self . _get_data_object ( agg_path = agg_path , func = xarray . open_dataset ) save_data_object ( resource , agg_path , as_new_aggr = False , destination_path = '' ) Saves the xarray Dataset object to the Multidimensional aggregation :param resource: the resource containing the aggregation :param agg_path: the path to the Multidimensional aggregation :param as_new_aggr: Defaults False, set to True to create a new Multidimensional aggregation :param destination_path: the destination path in Hydroshare to save the new aggregation :return: the updated or new Multidimensional aggregation Source code in hsclient\\hydroshare.py def save_data_object ( self , resource : 'Resource' , agg_path : str , as_new_aggr : bool = False , destination_path : str = \"\" ) -> 'Aggregation' : \"\"\" Saves the xarray Dataset object to the Multidimensional aggregation :param resource: the resource containing the aggregation :param agg_path: the path to the Multidimensional aggregation :param as_new_aggr: Defaults False, set to True to create a new Multidimensional aggregation :param destination_path: the destination path in Hydroshare to save the new aggregation :return: the updated or new Multidimensional aggregation \"\"\" self . _validate_aggregation_for_update ( resource , AggregationType . MultidimensionalAggregation ) file_path = self . _validate_aggregation_path ( agg_path , for_save_data = True ) self . _data_object . to_netcdf ( file_path , format = \"NETCDF4\" ) aggr_main_file_path = self . main_file_path if not as_new_aggr : # cache some of the metadata fields of the original aggregation to update the metadata of the # updated aggregation keywords = self . metadata . subjects additional_meta = self . metadata . additional_metadata # upload the updated aggregation files self . _update_aggregation ( resource , file_path ) # retrieve the updated aggregation aggr = resource . aggregation ( file__path = aggr_main_file_path ) # update metadata for kw in keywords : if kw not in aggr . metadata . subjects : aggr . metadata . subjects . append ( kw ) aggr . metadata . additional_metadata = additional_meta aggr . save () else : # creating a new aggregation resource . file_upload ( file_path , destination_path = destination_path ) # retrieve the new aggregation agg_path = urljoin ( destination_path , os . path . basename ( aggr_main_file_path )) aggr = resource . aggregation ( file__path = agg_path ) aggr . _data_object = None return aggr","title":"Multidimensional Aggregation"},{"location":"api/netcdf_aggregation/#hsclient.hydroshare.NetCDFAggregation.as_data_object","text":"Loads the Multidimensional aggregation to a xarray Dataset object :param agg_path: the path to the Multidimensional aggregation :return: the Multidimensional aggregation as a xarray Dataset object Source code in hsclient\\hydroshare.py def as_data_object ( self , agg_path : str ) -> 'xarray.Dataset' : \"\"\" Loads the Multidimensional aggregation to a xarray Dataset object :param agg_path: the path to the Multidimensional aggregation :return: the Multidimensional aggregation as a xarray Dataset object \"\"\" if xarray is None : raise Exception ( \"xarray package was not found\" ) return self . _get_data_object ( agg_path = agg_path , func = xarray . open_dataset )","title":"as_data_object"},{"location":"api/netcdf_aggregation/#hsclient.hydroshare.NetCDFAggregation.save_data_object","text":"Saves the xarray Dataset object to the Multidimensional aggregation :param resource: the resource containing the aggregation :param agg_path: the path to the Multidimensional aggregation :param as_new_aggr: Defaults False, set to True to create a new Multidimensional aggregation :param destination_path: the destination path in Hydroshare to save the new aggregation :return: the updated or new Multidimensional aggregation Source code in hsclient\\hydroshare.py def save_data_object ( self , resource : 'Resource' , agg_path : str , as_new_aggr : bool = False , destination_path : str = \"\" ) -> 'Aggregation' : \"\"\" Saves the xarray Dataset object to the Multidimensional aggregation :param resource: the resource containing the aggregation :param agg_path: the path to the Multidimensional aggregation :param as_new_aggr: Defaults False, set to True to create a new Multidimensional aggregation :param destination_path: the destination path in Hydroshare to save the new aggregation :return: the updated or new Multidimensional aggregation \"\"\" self . _validate_aggregation_for_update ( resource , AggregationType . MultidimensionalAggregation ) file_path = self . _validate_aggregation_path ( agg_path , for_save_data = True ) self . _data_object . to_netcdf ( file_path , format = \"NETCDF4\" ) aggr_main_file_path = self . main_file_path if not as_new_aggr : # cache some of the metadata fields of the original aggregation to update the metadata of the # updated aggregation keywords = self . metadata . subjects additional_meta = self . metadata . additional_metadata # upload the updated aggregation files self . _update_aggregation ( resource , file_path ) # retrieve the updated aggregation aggr = resource . aggregation ( file__path = aggr_main_file_path ) # update metadata for kw in keywords : if kw not in aggr . metadata . subjects : aggr . metadata . subjects . append ( kw ) aggr . metadata . additional_metadata = additional_meta aggr . save () else : # creating a new aggregation resource . file_upload ( file_path , destination_path = destination_path ) # retrieve the new aggregation agg_path = urljoin ( destination_path , os . path . basename ( aggr_main_file_path )) aggr = resource . aggregation ( file__path = agg_path ) aggr . _data_object = None return aggr","title":"save_data_object"},{"location":"api/resource/","text":"Bases: Aggregation Represents a Resource in HydroShare Source code in hsclient\\hydroshare.py class Resource ( Aggregation ): \"\"\"Represents a Resource in HydroShare\"\"\" @property def _hsapi_path ( self ): path = urlparse ( str ( self . metadata . identifier )) . path return '/hsapi' + path def _upload ( self , file , destination_path ): path = urljoin ( self . _hsapi_path , \"files\" , destination_path . strip ( \"/\" )) self . _hs_session . upload_file ( path , files = { 'file' : open ( file , 'rb' )}, status_code = 201 ) def _delete_file ( self , path ) -> None : path = urljoin ( self . _hsapi_path , \"files\" , path ) self . _hs_session . delete ( path , status_code = 200 ) def _download_file_folder ( self , path : str , save_path : str ) -> None : return self . _hs_session . retrieve_zip ( path , save_path ) def _delete_file_folder ( self , path : str ) -> None : path = urljoin ( self . _hsapi_path , \"folders\" , path ) self . _hs_session . delete ( path , status_code = 200 ) # system information @property def resource_id ( self ) -> str : \"\"\"The resource id (guid) of the HydroShare resource\"\"\" return self . _map . identifier @property def metadata_file ( self ): \"\"\"The path to the metadata file\"\"\" return self . metadata_path . split ( \"/data/\" , 1 )[ 1 ] def system_metadata ( self ): \"\"\" The system metadata associated with the HydroShare resource returns: JSON object \"\"\" hsapi_path = urljoin ( self . _hsapi_path , 'sysmeta' ) return self . _hs_session . get ( hsapi_path , status_code = 200 ) . json () # access operations def set_sharing_status ( self , public : bool ): \"\"\" Set the sharing status of the resource to public or private :param public: bool, set to True for public, False for private \"\"\" path = urljoin ( \"hsapi\" , \"resource\" , \"accessRules\" , self . resource_id ) data = { 'public' : public } self . _hs_session . put ( path , status_code = 200 , data = data ) @property def access_permission ( self ): \"\"\" Retrieves the access permissions of the resource :return: JSON object \"\"\" path = urljoin ( self . _hsapi_path , \"access\" ) response = self . _hs_session . get ( path , status_code = 200 ) return response . json () # resource operations def new_version ( self ): \"\"\" Creates a new version of the resource on HydroShare :return: A Resource object of the newly created resource version \"\"\" path = urljoin ( self . _hsapi_path , \"version\" ) response = self . _hs_session . post ( path , status_code = 202 ) resource_id = response . text return Resource ( \"/resource/ {} /data/resourcemap.xml\" . format ( resource_id ), self . _hs_session ) def copy ( self ): \"\"\" Copies this Resource into a new resource on HydroShare returns: A Resource object of the newly copied resource \"\"\" path = urljoin ( self . _hsapi_path , \"copy\" ) response = self . _hs_session . post ( path , status_code = 202 ) resource_id = response . text return Resource ( \"/resource/ {} /data/resourcemap.xml\" . format ( resource_id ), self . _hs_session ) def download ( self , save_path : str = \"\" ) -> str : \"\"\" Downloads a zipped bagit archive of the resource from HydroShare param save_path: A local path to save the bag to, defaults to the current working directory returns: The relative pathname of the download \"\"\" return self . _hs_session . retrieve_bag ( self . _hsapi_path , save_path = save_path ) @refresh def delete ( self ) -> None : \"\"\" Deletes the resource on HydroShare :return: None \"\"\" hsapi_path = self . _hsapi_path self . _hs_session . delete ( hsapi_path , status_code = 204 ) @refresh def save ( self ) -> None : \"\"\" Saves the metadata to HydroShare :return: None \"\"\" metadata_string = rdf_string ( self . _retrieved_metadata , rdf_format = \"xml\" ) path = urljoin ( self . _hsapi_path , \"ingest_metadata\" ) self . _hs_session . upload_file ( path , files = { 'file' : ( 'resourcemetadata.xml' , metadata_string )}) # referenced content operations @refresh def reference_create ( self , file_name : str , url : str , path : str = '' ) -> None : \"\"\" Creates a HydroShare reference object to reference content outside of the resource :param file_name: the file name of the resulting .url file :param url: the url of the referenced content :param path: the path to create the reference in :return: None \"\"\" request_path = urljoin ( self . _hsapi_path . replace ( self . resource_id , \"\" ), \"data-store-add-reference\" ) self . _hs_session . post ( request_path , data = { \"res_id\" : self . resource_id , \"curr_path\" : path , \"ref_name\" : file_name , \"ref_url\" : url }, status_code = 200 , ) @refresh def reference_update ( self , file_name : str , url : str , path : str = '' ) -> None : \"\"\" Updates a HydroShare reference object :param file_name: the file name for the .url file :param url: the url of the referenced content :param path: the path to the directory where the reference is located :return: None \"\"\" request_path = urljoin ( self . _hsapi_path . replace ( self . resource_id , \"\" ), \"data_store_edit_reference_url\" ) self . _hs_session . post ( request_path , data = { \"res_id\" : self . resource_id , \"curr_path\" : path , \"url_filename\" : file_name , \"new_ref_url\" : url }, status_code = 200 , ) # file operations @refresh def folder_create ( self , folder : str ) -> None : \"\"\" Creates a folder on HydroShare :param folder: the folder path to create :return: None \"\"\" path = urljoin ( self . _hsapi_path , \"folders\" , folder ) self . _hs_session . put ( path , status_code = 201 ) @refresh def folder_rename ( self , path : str , new_path : str ) -> None : \"\"\" Renames a folder on HydroShare :param path: the path to the folder to rename :param new_path: the new path folder name :return: None \"\"\" self . file_rename ( path = path , new_path = new_path ) @refresh def folder_delete ( self , path : str = None ) -> None : \"\"\" Deletes a folder on HydroShare :param path: the path to the folder :return: None \"\"\" self . _delete_file_folder ( path ) def folder_download ( self , path : str , save_path : str = \"\" ): \"\"\" Downloads a folder from HydroShare :param path: The path to folder :param save_path: The local path to save the download to, defaults to the current directory :return: The path to the download zipped folder \"\"\" return self . _hs_session . retrieve_zip ( urljoin ( self . _resource_path , \"data\" , \"contents\" , path ), save_path , params = { \"zipped\" : \"true\" } ) def file_download ( self , path : str , save_path : str = \"\" , zipped : bool = False ): \"\"\" Downloads a file from HydroShare :param path: The path to the file :param save_path: The local path to save the file to :param zipped: Defaults to False, set to True to download the file zipped :return: The path to the downloaded file \"\"\" if zipped : return self . _hs_session . retrieve_zip ( urljoin ( self . _resource_path , \"data\" , \"contents\" , path ), save_path , params = { \"zipped\" : \"true\" } ) else : return self . _hs_session . retrieve_file ( urljoin ( self . _resource_path , \"data\" , \"contents\" , path ), save_path ) @refresh def file_delete ( self , path : str = None ) -> None : \"\"\" Delete a file on HydroShare :param path: The path to the file :return: None \"\"\" self . _delete_file ( path ) @refresh def file_rename ( self , path : str , new_path : str ) -> None : \"\"\" Rename a file on HydroShare :param path: The path to the file :param new_path: the renamed path to the file :return: None \"\"\" rename_path = urljoin ( self . _hsapi_path , \"functions\" , \"move-or-rename\" ) self . _hs_session . post ( rename_path , status_code = 200 , data = { \"source_path\" : path , \"target_path\" : new_path }) @refresh def file_zip ( self , path : str , zip_name : str = None , remove_file : bool = True ) -> None : \"\"\" Zip a file on HydroShare :param path: The path to the file :param zip_name: The name of the zipped file :param remove_file: Defaults to True, set to False to not delete the file that was zipped :return: None \"\"\" zip_name = basename ( path ) + \".zip\" if not zip_name else zip_name data = { \"input_coll_path\" : path , \"output_zip_file_name\" : zip_name , \"remove_original_after_zip\" : remove_file } zip_path = urljoin ( self . _hsapi_path , \"functions\" , \"zip\" ) self . _hs_session . post ( zip_path , status_code = 200 , data = data ) @refresh def file_unzip ( self , path : str , overwrite : bool = True , ingest_metadata = True ) -> None : \"\"\" Unzips a file on HydroShare :param path: The path to the file to unzip :param overwrite: Defaults to True, set to False to unzip the files into a folder with the zip filename :param ingest_metadata: Defaults to True, set to False to not ingest HydroShare RDF metadata xml files :return: None \"\"\" if not path . endswith ( \".zip\" ): raise Exception ( \"File {} is not a zip, and cannot be unzipped\" . format ( path )) unzip_path = urljoin ( self . _hsapi_path , \"functions\" , \"unzip\" , \"data\" , \"contents\" , path ) self . _hs_session . post ( unzip_path , status_code = 200 , data = { \"overwrite\" : overwrite , \"ingest_metadata\" : ingest_metadata } ) def file_aggregate ( self , path : str , agg_type : AggregationType , refresh : bool = True ): \"\"\" Aggregate a file to a HydroShare aggregation type. Aggregating files allows you to specify metadata specific to the files associated with the aggregation. To set a FileSet aggregation, include the path to the folder or a file in the folder you would like to create a FileSet aggregation from. :param path: The path to the file to aggregate :param agg_type: The AggregationType to create :param refresh: Defaults True, toggles automatic refreshing of the updated resource in HydroShare :return: The newly created Aggregation object if refresh is True \"\"\" type_value = agg_type . value data = {} if agg_type == AggregationType . SingleFileAggregation : type_value = 'SingleFile' if agg_type == AggregationType . FileSetAggregation : if '/' in path : relative_path = dirname ( path ) else : relative_path = path data = { \"folder_path\" : relative_path } url = urljoin ( self . _hsapi_path , \"functions\" , \"set-file-type\" , path , type_value ) self . _hs_session . post ( url , status_code = 201 , data = data ) if refresh : # Only return the newly created aggregation if a refresh is requested self . refresh () return self . aggregation ( file__path = path ) @refresh def file_upload ( self , * files : str , destination_path : str = \"\" ) -> None : \"\"\" Uploads files to a folder in HydroShare :param *files: The local file paths to upload :param destination_path: The path on HydroShare to upload the files to, defaults to the root contents directory :return: None \"\"\" if len ( files ) == 1 : self . _upload ( files [ 0 ], destination_path = destination_path ) else : with tempfile . TemporaryDirectory () as tmpdir : zipped_file = os . path . join ( tmpdir , 'files.zip' ) with ZipFile ( zipped_file , 'w' ) as zipped : for file in files : zipped . write ( file , os . path . basename ( file )) self . _upload ( zipped_file , destination_path = destination_path ) unzip_path = urljoin ( self . _hsapi_path , \"functions\" , \"unzip\" , \"data\" , \"contents\" , destination_path , 'files.zip' ) self . _hs_session . post ( unzip_path , status_code = 200 , data = { \"overwrite\" : \"true\" , \"ingest_metadata\" : \"true\" } ) # TODO, return those files? # aggregation operations @refresh def aggregation_remove ( self , aggregation : Aggregation ) -> None : \"\"\" Removes an aggregation from HydroShare. This does not remove the files in the aggregation. :param aggregation: The aggregation object to remove :return: None \"\"\" path = urljoin ( aggregation . _hsapi_path , \"functions\" , \"remove-file-type\" , aggregation . metadata . type . value + \"LogicalFile\" , aggregation . main_file_path , ) aggregation . _hs_session . post ( path , status_code = 200 ) aggregation . refresh () @refresh def aggregation_move ( self , aggregation : Aggregation , dst_path : str = \"\" ) -> None : \"\"\" Moves an aggregation from its current location to another folder in HydroShare. :param aggregation: The aggregation object to move :param dst_path: The target file path to move the aggregation to - target folder must exist :return: None \"\"\" path = urljoin ( aggregation . _hsapi_path , aggregation . metadata . type . value + \"LogicalFile\" , aggregation . main_file_path , \"functions\" , \"move-file-type\" , dst_path , ) response = aggregation . _hs_session . post ( path , status_code = 200 ) json_response = response . json () task_id = json_response [ 'id' ] status = json_response [ 'status' ] if status in ( \"Not ready\" , \"progress\" ): while aggregation . _hs_session . check_task ( task_id ) != 'true' : time . sleep ( CHECK_TASK_PING_INTERVAL ) aggregation . refresh () @refresh def aggregation_delete ( self , aggregation : Aggregation ) -> None : \"\"\" Deletes an aggregation from HydroShare. This deletes the files and metadata in the aggregation. :param aggregation: The aggregation object to delete :return: None \"\"\" aggregation . delete () def aggregation_download ( self , aggregation : Aggregation , save_path : str = \"\" , unzip_to : str = None ) -> str : \"\"\" Download an aggregation from HydroShare :param aggregation: The aggregation to download :param save_path: The local path to save the aggregation to, defaults to the current directory :param unzip_to: If set, the resulting download will be unzipped to the specified path :return: None \"\"\" return aggregation . _download ( save_path = save_path , unzip_to = unzip_to ) access_permission property Retrieves the access permissions of the resource :return: JSON object metadata_file property The path to the metadata file resource_id : str property The resource id (guid) of the HydroShare resource aggregation_delete ( aggregation ) Deletes an aggregation from HydroShare. This deletes the files and metadata in the aggregation. :param aggregation: The aggregation object to delete :return: None Source code in hsclient\\hydroshare.py @refresh def aggregation_delete ( self , aggregation : Aggregation ) -> None : \"\"\" Deletes an aggregation from HydroShare. This deletes the files and metadata in the aggregation. :param aggregation: The aggregation object to delete :return: None \"\"\" aggregation . delete () aggregation_download ( aggregation , save_path = '' , unzip_to = None ) Download an aggregation from HydroShare :param aggregation: The aggregation to download :param save_path: The local path to save the aggregation to, defaults to the current directory :param unzip_to: If set, the resulting download will be unzipped to the specified path :return: None Source code in hsclient\\hydroshare.py def aggregation_download ( self , aggregation : Aggregation , save_path : str = \"\" , unzip_to : str = None ) -> str : \"\"\" Download an aggregation from HydroShare :param aggregation: The aggregation to download :param save_path: The local path to save the aggregation to, defaults to the current directory :param unzip_to: If set, the resulting download will be unzipped to the specified path :return: None \"\"\" return aggregation . _download ( save_path = save_path , unzip_to = unzip_to ) aggregation_move ( aggregation , dst_path = '' ) Moves an aggregation from its current location to another folder in HydroShare. :param aggregation: The aggregation object to move :param dst_path: The target file path to move the aggregation to - target folder must exist :return: None Source code in hsclient\\hydroshare.py @refresh def aggregation_move ( self , aggregation : Aggregation , dst_path : str = \"\" ) -> None : \"\"\" Moves an aggregation from its current location to another folder in HydroShare. :param aggregation: The aggregation object to move :param dst_path: The target file path to move the aggregation to - target folder must exist :return: None \"\"\" path = urljoin ( aggregation . _hsapi_path , aggregation . metadata . type . value + \"LogicalFile\" , aggregation . main_file_path , \"functions\" , \"move-file-type\" , dst_path , ) response = aggregation . _hs_session . post ( path , status_code = 200 ) json_response = response . json () task_id = json_response [ 'id' ] status = json_response [ 'status' ] if status in ( \"Not ready\" , \"progress\" ): while aggregation . _hs_session . check_task ( task_id ) != 'true' : time . sleep ( CHECK_TASK_PING_INTERVAL ) aggregation . refresh () aggregation_remove ( aggregation ) Removes an aggregation from HydroShare. This does not remove the files in the aggregation. :param aggregation: The aggregation object to remove :return: None Source code in hsclient\\hydroshare.py @refresh def aggregation_remove ( self , aggregation : Aggregation ) -> None : \"\"\" Removes an aggregation from HydroShare. This does not remove the files in the aggregation. :param aggregation: The aggregation object to remove :return: None \"\"\" path = urljoin ( aggregation . _hsapi_path , \"functions\" , \"remove-file-type\" , aggregation . metadata . type . value + \"LogicalFile\" , aggregation . main_file_path , ) aggregation . _hs_session . post ( path , status_code = 200 ) aggregation . refresh () copy () Copies this Resource into a new resource on HydroShare returns: A Resource object of the newly copied resource Source code in hsclient\\hydroshare.py def copy ( self ): \"\"\" Copies this Resource into a new resource on HydroShare returns: A Resource object of the newly copied resource \"\"\" path = urljoin ( self . _hsapi_path , \"copy\" ) response = self . _hs_session . post ( path , status_code = 202 ) resource_id = response . text return Resource ( \"/resource/ {} /data/resourcemap.xml\" . format ( resource_id ), self . _hs_session ) delete () Deletes the resource on HydroShare :return: None Source code in hsclient\\hydroshare.py @refresh def delete ( self ) -> None : \"\"\" Deletes the resource on HydroShare :return: None \"\"\" hsapi_path = self . _hsapi_path self . _hs_session . delete ( hsapi_path , status_code = 204 ) download ( save_path = '' ) Downloads a zipped bagit archive of the resource from HydroShare param save_path: A local path to save the bag to, defaults to the current working directory returns: The relative pathname of the download Source code in hsclient\\hydroshare.py def download ( self , save_path : str = \"\" ) -> str : \"\"\" Downloads a zipped bagit archive of the resource from HydroShare param save_path: A local path to save the bag to, defaults to the current working directory returns: The relative pathname of the download \"\"\" return self . _hs_session . retrieve_bag ( self . _hsapi_path , save_path = save_path ) file_aggregate ( path , agg_type , refresh = True ) Aggregate a file to a HydroShare aggregation type. Aggregating files allows you to specify metadata specific to the files associated with the aggregation. To set a FileSet aggregation, include the path to the folder or a file in the folder you would like to create a FileSet aggregation from. :param path: The path to the file to aggregate :param agg_type: The AggregationType to create :param refresh: Defaults True, toggles automatic refreshing of the updated resource in HydroShare :return: The newly created Aggregation object if refresh is True Source code in hsclient\\hydroshare.py def file_aggregate ( self , path : str , agg_type : AggregationType , refresh : bool = True ): \"\"\" Aggregate a file to a HydroShare aggregation type. Aggregating files allows you to specify metadata specific to the files associated with the aggregation. To set a FileSet aggregation, include the path to the folder or a file in the folder you would like to create a FileSet aggregation from. :param path: The path to the file to aggregate :param agg_type: The AggregationType to create :param refresh: Defaults True, toggles automatic refreshing of the updated resource in HydroShare :return: The newly created Aggregation object if refresh is True \"\"\" type_value = agg_type . value data = {} if agg_type == AggregationType . SingleFileAggregation : type_value = 'SingleFile' if agg_type == AggregationType . FileSetAggregation : if '/' in path : relative_path = dirname ( path ) else : relative_path = path data = { \"folder_path\" : relative_path } url = urljoin ( self . _hsapi_path , \"functions\" , \"set-file-type\" , path , type_value ) self . _hs_session . post ( url , status_code = 201 , data = data ) if refresh : # Only return the newly created aggregation if a refresh is requested self . refresh () return self . aggregation ( file__path = path ) file_delete ( path = None ) Delete a file on HydroShare :param path: The path to the file :return: None Source code in hsclient\\hydroshare.py @refresh def file_delete ( self , path : str = None ) -> None : \"\"\" Delete a file on HydroShare :param path: The path to the file :return: None \"\"\" self . _delete_file ( path ) file_download ( path , save_path = '' , zipped = False ) Downloads a file from HydroShare :param path: The path to the file :param save_path: The local path to save the file to :param zipped: Defaults to False, set to True to download the file zipped :return: The path to the downloaded file Source code in hsclient\\hydroshare.py def file_download ( self , path : str , save_path : str = \"\" , zipped : bool = False ): \"\"\" Downloads a file from HydroShare :param path: The path to the file :param save_path: The local path to save the file to :param zipped: Defaults to False, set to True to download the file zipped :return: The path to the downloaded file \"\"\" if zipped : return self . _hs_session . retrieve_zip ( urljoin ( self . _resource_path , \"data\" , \"contents\" , path ), save_path , params = { \"zipped\" : \"true\" } ) else : return self . _hs_session . retrieve_file ( urljoin ( self . _resource_path , \"data\" , \"contents\" , path ), save_path ) file_rename ( path , new_path ) Rename a file on HydroShare :param path: The path to the file :param new_path: the renamed path to the file :return: None Source code in hsclient\\hydroshare.py @refresh def file_rename ( self , path : str , new_path : str ) -> None : \"\"\" Rename a file on HydroShare :param path: The path to the file :param new_path: the renamed path to the file :return: None \"\"\" rename_path = urljoin ( self . _hsapi_path , \"functions\" , \"move-or-rename\" ) self . _hs_session . post ( rename_path , status_code = 200 , data = { \"source_path\" : path , \"target_path\" : new_path }) file_unzip ( path , overwrite = True , ingest_metadata = True ) Unzips a file on HydroShare :param path: The path to the file to unzip :param overwrite: Defaults to True, set to False to unzip the files into a folder with the zip filename :param ingest_metadata: Defaults to True, set to False to not ingest HydroShare RDF metadata xml files :return: None Source code in hsclient\\hydroshare.py @refresh def file_unzip ( self , path : str , overwrite : bool = True , ingest_metadata = True ) -> None : \"\"\" Unzips a file on HydroShare :param path: The path to the file to unzip :param overwrite: Defaults to True, set to False to unzip the files into a folder with the zip filename :param ingest_metadata: Defaults to True, set to False to not ingest HydroShare RDF metadata xml files :return: None \"\"\" if not path . endswith ( \".zip\" ): raise Exception ( \"File {} is not a zip, and cannot be unzipped\" . format ( path )) unzip_path = urljoin ( self . _hsapi_path , \"functions\" , \"unzip\" , \"data\" , \"contents\" , path ) self . _hs_session . post ( unzip_path , status_code = 200 , data = { \"overwrite\" : overwrite , \"ingest_metadata\" : ingest_metadata } ) file_upload ( * files , destination_path = '' ) Uploads files to a folder in HydroShare :param *files: The local file paths to upload :param destination_path: The path on HydroShare to upload the files to, defaults to the root contents directory :return: None Source code in hsclient\\hydroshare.py @refresh def file_upload ( self , * files : str , destination_path : str = \"\" ) -> None : \"\"\" Uploads files to a folder in HydroShare :param *files: The local file paths to upload :param destination_path: The path on HydroShare to upload the files to, defaults to the root contents directory :return: None \"\"\" if len ( files ) == 1 : self . _upload ( files [ 0 ], destination_path = destination_path ) else : with tempfile . TemporaryDirectory () as tmpdir : zipped_file = os . path . join ( tmpdir , 'files.zip' ) with ZipFile ( zipped_file , 'w' ) as zipped : for file in files : zipped . write ( file , os . path . basename ( file )) self . _upload ( zipped_file , destination_path = destination_path ) unzip_path = urljoin ( self . _hsapi_path , \"functions\" , \"unzip\" , \"data\" , \"contents\" , destination_path , 'files.zip' ) self . _hs_session . post ( unzip_path , status_code = 200 , data = { \"overwrite\" : \"true\" , \"ingest_metadata\" : \"true\" } ) file_zip ( path , zip_name = None , remove_file = True ) Zip a file on HydroShare :param path: The path to the file :param zip_name: The name of the zipped file :param remove_file: Defaults to True, set to False to not delete the file that was zipped :return: None Source code in hsclient\\hydroshare.py @refresh def file_zip ( self , path : str , zip_name : str = None , remove_file : bool = True ) -> None : \"\"\" Zip a file on HydroShare :param path: The path to the file :param zip_name: The name of the zipped file :param remove_file: Defaults to True, set to False to not delete the file that was zipped :return: None \"\"\" zip_name = basename ( path ) + \".zip\" if not zip_name else zip_name data = { \"input_coll_path\" : path , \"output_zip_file_name\" : zip_name , \"remove_original_after_zip\" : remove_file } zip_path = urljoin ( self . _hsapi_path , \"functions\" , \"zip\" ) self . _hs_session . post ( zip_path , status_code = 200 , data = data ) folder_create ( folder ) Creates a folder on HydroShare :param folder: the folder path to create :return: None Source code in hsclient\\hydroshare.py @refresh def folder_create ( self , folder : str ) -> None : \"\"\" Creates a folder on HydroShare :param folder: the folder path to create :return: None \"\"\" path = urljoin ( self . _hsapi_path , \"folders\" , folder ) self . _hs_session . put ( path , status_code = 201 ) folder_delete ( path = None ) Deletes a folder on HydroShare :param path: the path to the folder :return: None Source code in hsclient\\hydroshare.py @refresh def folder_delete ( self , path : str = None ) -> None : \"\"\" Deletes a folder on HydroShare :param path: the path to the folder :return: None \"\"\" self . _delete_file_folder ( path ) folder_download ( path , save_path = '' ) Downloads a folder from HydroShare :param path: The path to folder :param save_path: The local path to save the download to, defaults to the current directory :return: The path to the download zipped folder Source code in hsclient\\hydroshare.py def folder_download ( self , path : str , save_path : str = \"\" ): \"\"\" Downloads a folder from HydroShare :param path: The path to folder :param save_path: The local path to save the download to, defaults to the current directory :return: The path to the download zipped folder \"\"\" return self . _hs_session . retrieve_zip ( urljoin ( self . _resource_path , \"data\" , \"contents\" , path ), save_path , params = { \"zipped\" : \"true\" } ) folder_rename ( path , new_path ) Renames a folder on HydroShare :param path: the path to the folder to rename :param new_path: the new path folder name :return: None Source code in hsclient\\hydroshare.py @refresh def folder_rename ( self , path : str , new_path : str ) -> None : \"\"\" Renames a folder on HydroShare :param path: the path to the folder to rename :param new_path: the new path folder name :return: None \"\"\" self . file_rename ( path = path , new_path = new_path ) new_version () Creates a new version of the resource on HydroShare :return: A Resource object of the newly created resource version Source code in hsclient\\hydroshare.py def new_version ( self ): \"\"\" Creates a new version of the resource on HydroShare :return: A Resource object of the newly created resource version \"\"\" path = urljoin ( self . _hsapi_path , \"version\" ) response = self . _hs_session . post ( path , status_code = 202 ) resource_id = response . text return Resource ( \"/resource/ {} /data/resourcemap.xml\" . format ( resource_id ), self . _hs_session ) reference_create ( file_name , url , path = '' ) Creates a HydroShare reference object to reference content outside of the resource :param file_name: the file name of the resulting .url file :param url: the url of the referenced content :param path: the path to create the reference in :return: None Source code in hsclient\\hydroshare.py @refresh def reference_create ( self , file_name : str , url : str , path : str = '' ) -> None : \"\"\" Creates a HydroShare reference object to reference content outside of the resource :param file_name: the file name of the resulting .url file :param url: the url of the referenced content :param path: the path to create the reference in :return: None \"\"\" request_path = urljoin ( self . _hsapi_path . replace ( self . resource_id , \"\" ), \"data-store-add-reference\" ) self . _hs_session . post ( request_path , data = { \"res_id\" : self . resource_id , \"curr_path\" : path , \"ref_name\" : file_name , \"ref_url\" : url }, status_code = 200 , ) reference_update ( file_name , url , path = '' ) Updates a HydroShare reference object :param file_name: the file name for the .url file :param url: the url of the referenced content :param path: the path to the directory where the reference is located :return: None Source code in hsclient\\hydroshare.py @refresh def reference_update ( self , file_name : str , url : str , path : str = '' ) -> None : \"\"\" Updates a HydroShare reference object :param file_name: the file name for the .url file :param url: the url of the referenced content :param path: the path to the directory where the reference is located :return: None \"\"\" request_path = urljoin ( self . _hsapi_path . replace ( self . resource_id , \"\" ), \"data_store_edit_reference_url\" ) self . _hs_session . post ( request_path , data = { \"res_id\" : self . resource_id , \"curr_path\" : path , \"url_filename\" : file_name , \"new_ref_url\" : url }, status_code = 200 , ) save () Saves the metadata to HydroShare :return: None Source code in hsclient\\hydroshare.py @refresh def save ( self ) -> None : \"\"\" Saves the metadata to HydroShare :return: None \"\"\" metadata_string = rdf_string ( self . _retrieved_metadata , rdf_format = \"xml\" ) path = urljoin ( self . _hsapi_path , \"ingest_metadata\" ) self . _hs_session . upload_file ( path , files = { 'file' : ( 'resourcemetadata.xml' , metadata_string )}) set_sharing_status ( public ) Set the sharing status of the resource to public or private :param public: bool, set to True for public, False for private Source code in hsclient\\hydroshare.py def set_sharing_status ( self , public : bool ): \"\"\" Set the sharing status of the resource to public or private :param public: bool, set to True for public, False for private \"\"\" path = urljoin ( \"hsapi\" , \"resource\" , \"accessRules\" , self . resource_id ) data = { 'public' : public } self . _hs_session . put ( path , status_code = 200 , data = data ) system_metadata () The system metadata associated with the HydroShare resource returns: JSON object Source code in hsclient\\hydroshare.py def system_metadata ( self ): \"\"\" The system metadata associated with the HydroShare resource returns: JSON object \"\"\" hsapi_path = urljoin ( self . _hsapi_path , 'sysmeta' ) return self . _hs_session . get ( hsapi_path , status_code = 200 ) . json ()","title":"Resource"},{"location":"api/resource/#hsclient.hydroshare.Resource.access_permission","text":"Retrieves the access permissions of the resource :return: JSON object","title":"access_permission"},{"location":"api/resource/#hsclient.hydroshare.Resource.metadata_file","text":"The path to the metadata file","title":"metadata_file"},{"location":"api/resource/#hsclient.hydroshare.Resource.resource_id","text":"The resource id (guid) of the HydroShare resource","title":"resource_id"},{"location":"api/resource/#hsclient.hydroshare.Resource.aggregation_delete","text":"Deletes an aggregation from HydroShare. This deletes the files and metadata in the aggregation. :param aggregation: The aggregation object to delete :return: None Source code in hsclient\\hydroshare.py @refresh def aggregation_delete ( self , aggregation : Aggregation ) -> None : \"\"\" Deletes an aggregation from HydroShare. This deletes the files and metadata in the aggregation. :param aggregation: The aggregation object to delete :return: None \"\"\" aggregation . delete ()","title":"aggregation_delete"},{"location":"api/resource/#hsclient.hydroshare.Resource.aggregation_download","text":"Download an aggregation from HydroShare :param aggregation: The aggregation to download :param save_path: The local path to save the aggregation to, defaults to the current directory :param unzip_to: If set, the resulting download will be unzipped to the specified path :return: None Source code in hsclient\\hydroshare.py def aggregation_download ( self , aggregation : Aggregation , save_path : str = \"\" , unzip_to : str = None ) -> str : \"\"\" Download an aggregation from HydroShare :param aggregation: The aggregation to download :param save_path: The local path to save the aggregation to, defaults to the current directory :param unzip_to: If set, the resulting download will be unzipped to the specified path :return: None \"\"\" return aggregation . _download ( save_path = save_path , unzip_to = unzip_to )","title":"aggregation_download"},{"location":"api/resource/#hsclient.hydroshare.Resource.aggregation_move","text":"Moves an aggregation from its current location to another folder in HydroShare. :param aggregation: The aggregation object to move :param dst_path: The target file path to move the aggregation to - target folder must exist :return: None Source code in hsclient\\hydroshare.py @refresh def aggregation_move ( self , aggregation : Aggregation , dst_path : str = \"\" ) -> None : \"\"\" Moves an aggregation from its current location to another folder in HydroShare. :param aggregation: The aggregation object to move :param dst_path: The target file path to move the aggregation to - target folder must exist :return: None \"\"\" path = urljoin ( aggregation . _hsapi_path , aggregation . metadata . type . value + \"LogicalFile\" , aggregation . main_file_path , \"functions\" , \"move-file-type\" , dst_path , ) response = aggregation . _hs_session . post ( path , status_code = 200 ) json_response = response . json () task_id = json_response [ 'id' ] status = json_response [ 'status' ] if status in ( \"Not ready\" , \"progress\" ): while aggregation . _hs_session . check_task ( task_id ) != 'true' : time . sleep ( CHECK_TASK_PING_INTERVAL ) aggregation . refresh ()","title":"aggregation_move"},{"location":"api/resource/#hsclient.hydroshare.Resource.aggregation_remove","text":"Removes an aggregation from HydroShare. This does not remove the files in the aggregation. :param aggregation: The aggregation object to remove :return: None Source code in hsclient\\hydroshare.py @refresh def aggregation_remove ( self , aggregation : Aggregation ) -> None : \"\"\" Removes an aggregation from HydroShare. This does not remove the files in the aggregation. :param aggregation: The aggregation object to remove :return: None \"\"\" path = urljoin ( aggregation . _hsapi_path , \"functions\" , \"remove-file-type\" , aggregation . metadata . type . value + \"LogicalFile\" , aggregation . main_file_path , ) aggregation . _hs_session . post ( path , status_code = 200 ) aggregation . refresh ()","title":"aggregation_remove"},{"location":"api/resource/#hsclient.hydroshare.Resource.copy","text":"Copies this Resource into a new resource on HydroShare returns: A Resource object of the newly copied resource Source code in hsclient\\hydroshare.py def copy ( self ): \"\"\" Copies this Resource into a new resource on HydroShare returns: A Resource object of the newly copied resource \"\"\" path = urljoin ( self . _hsapi_path , \"copy\" ) response = self . _hs_session . post ( path , status_code = 202 ) resource_id = response . text return Resource ( \"/resource/ {} /data/resourcemap.xml\" . format ( resource_id ), self . _hs_session )","title":"copy"},{"location":"api/resource/#hsclient.hydroshare.Resource.delete","text":"Deletes the resource on HydroShare :return: None Source code in hsclient\\hydroshare.py @refresh def delete ( self ) -> None : \"\"\" Deletes the resource on HydroShare :return: None \"\"\" hsapi_path = self . _hsapi_path self . _hs_session . delete ( hsapi_path , status_code = 204 )","title":"delete"},{"location":"api/resource/#hsclient.hydroshare.Resource.download","text":"Downloads a zipped bagit archive of the resource from HydroShare param save_path: A local path to save the bag to, defaults to the current working directory returns: The relative pathname of the download Source code in hsclient\\hydroshare.py def download ( self , save_path : str = \"\" ) -> str : \"\"\" Downloads a zipped bagit archive of the resource from HydroShare param save_path: A local path to save the bag to, defaults to the current working directory returns: The relative pathname of the download \"\"\" return self . _hs_session . retrieve_bag ( self . _hsapi_path , save_path = save_path )","title":"download"},{"location":"api/resource/#hsclient.hydroshare.Resource.file_aggregate","text":"Aggregate a file to a HydroShare aggregation type. Aggregating files allows you to specify metadata specific to the files associated with the aggregation. To set a FileSet aggregation, include the path to the folder or a file in the folder you would like to create a FileSet aggregation from. :param path: The path to the file to aggregate :param agg_type: The AggregationType to create :param refresh: Defaults True, toggles automatic refreshing of the updated resource in HydroShare :return: The newly created Aggregation object if refresh is True Source code in hsclient\\hydroshare.py def file_aggregate ( self , path : str , agg_type : AggregationType , refresh : bool = True ): \"\"\" Aggregate a file to a HydroShare aggregation type. Aggregating files allows you to specify metadata specific to the files associated with the aggregation. To set a FileSet aggregation, include the path to the folder or a file in the folder you would like to create a FileSet aggregation from. :param path: The path to the file to aggregate :param agg_type: The AggregationType to create :param refresh: Defaults True, toggles automatic refreshing of the updated resource in HydroShare :return: The newly created Aggregation object if refresh is True \"\"\" type_value = agg_type . value data = {} if agg_type == AggregationType . SingleFileAggregation : type_value = 'SingleFile' if agg_type == AggregationType . FileSetAggregation : if '/' in path : relative_path = dirname ( path ) else : relative_path = path data = { \"folder_path\" : relative_path } url = urljoin ( self . _hsapi_path , \"functions\" , \"set-file-type\" , path , type_value ) self . _hs_session . post ( url , status_code = 201 , data = data ) if refresh : # Only return the newly created aggregation if a refresh is requested self . refresh () return self . aggregation ( file__path = path )","title":"file_aggregate"},{"location":"api/resource/#hsclient.hydroshare.Resource.file_delete","text":"Delete a file on HydroShare :param path: The path to the file :return: None Source code in hsclient\\hydroshare.py @refresh def file_delete ( self , path : str = None ) -> None : \"\"\" Delete a file on HydroShare :param path: The path to the file :return: None \"\"\" self . _delete_file ( path )","title":"file_delete"},{"location":"api/resource/#hsclient.hydroshare.Resource.file_download","text":"Downloads a file from HydroShare :param path: The path to the file :param save_path: The local path to save the file to :param zipped: Defaults to False, set to True to download the file zipped :return: The path to the downloaded file Source code in hsclient\\hydroshare.py def file_download ( self , path : str , save_path : str = \"\" , zipped : bool = False ): \"\"\" Downloads a file from HydroShare :param path: The path to the file :param save_path: The local path to save the file to :param zipped: Defaults to False, set to True to download the file zipped :return: The path to the downloaded file \"\"\" if zipped : return self . _hs_session . retrieve_zip ( urljoin ( self . _resource_path , \"data\" , \"contents\" , path ), save_path , params = { \"zipped\" : \"true\" } ) else : return self . _hs_session . retrieve_file ( urljoin ( self . _resource_path , \"data\" , \"contents\" , path ), save_path )","title":"file_download"},{"location":"api/resource/#hsclient.hydroshare.Resource.file_rename","text":"Rename a file on HydroShare :param path: The path to the file :param new_path: the renamed path to the file :return: None Source code in hsclient\\hydroshare.py @refresh def file_rename ( self , path : str , new_path : str ) -> None : \"\"\" Rename a file on HydroShare :param path: The path to the file :param new_path: the renamed path to the file :return: None \"\"\" rename_path = urljoin ( self . _hsapi_path , \"functions\" , \"move-or-rename\" ) self . _hs_session . post ( rename_path , status_code = 200 , data = { \"source_path\" : path , \"target_path\" : new_path })","title":"file_rename"},{"location":"api/resource/#hsclient.hydroshare.Resource.file_unzip","text":"Unzips a file on HydroShare :param path: The path to the file to unzip :param overwrite: Defaults to True, set to False to unzip the files into a folder with the zip filename :param ingest_metadata: Defaults to True, set to False to not ingest HydroShare RDF metadata xml files :return: None Source code in hsclient\\hydroshare.py @refresh def file_unzip ( self , path : str , overwrite : bool = True , ingest_metadata = True ) -> None : \"\"\" Unzips a file on HydroShare :param path: The path to the file to unzip :param overwrite: Defaults to True, set to False to unzip the files into a folder with the zip filename :param ingest_metadata: Defaults to True, set to False to not ingest HydroShare RDF metadata xml files :return: None \"\"\" if not path . endswith ( \".zip\" ): raise Exception ( \"File {} is not a zip, and cannot be unzipped\" . format ( path )) unzip_path = urljoin ( self . _hsapi_path , \"functions\" , \"unzip\" , \"data\" , \"contents\" , path ) self . _hs_session . post ( unzip_path , status_code = 200 , data = { \"overwrite\" : overwrite , \"ingest_metadata\" : ingest_metadata } )","title":"file_unzip"},{"location":"api/resource/#hsclient.hydroshare.Resource.file_upload","text":"Uploads files to a folder in HydroShare :param *files: The local file paths to upload :param destination_path: The path on HydroShare to upload the files to, defaults to the root contents directory :return: None Source code in hsclient\\hydroshare.py @refresh def file_upload ( self , * files : str , destination_path : str = \"\" ) -> None : \"\"\" Uploads files to a folder in HydroShare :param *files: The local file paths to upload :param destination_path: The path on HydroShare to upload the files to, defaults to the root contents directory :return: None \"\"\" if len ( files ) == 1 : self . _upload ( files [ 0 ], destination_path = destination_path ) else : with tempfile . TemporaryDirectory () as tmpdir : zipped_file = os . path . join ( tmpdir , 'files.zip' ) with ZipFile ( zipped_file , 'w' ) as zipped : for file in files : zipped . write ( file , os . path . basename ( file )) self . _upload ( zipped_file , destination_path = destination_path ) unzip_path = urljoin ( self . _hsapi_path , \"functions\" , \"unzip\" , \"data\" , \"contents\" , destination_path , 'files.zip' ) self . _hs_session . post ( unzip_path , status_code = 200 , data = { \"overwrite\" : \"true\" , \"ingest_metadata\" : \"true\" } )","title":"file_upload"},{"location":"api/resource/#hsclient.hydroshare.Resource.file_zip","text":"Zip a file on HydroShare :param path: The path to the file :param zip_name: The name of the zipped file :param remove_file: Defaults to True, set to False to not delete the file that was zipped :return: None Source code in hsclient\\hydroshare.py @refresh def file_zip ( self , path : str , zip_name : str = None , remove_file : bool = True ) -> None : \"\"\" Zip a file on HydroShare :param path: The path to the file :param zip_name: The name of the zipped file :param remove_file: Defaults to True, set to False to not delete the file that was zipped :return: None \"\"\" zip_name = basename ( path ) + \".zip\" if not zip_name else zip_name data = { \"input_coll_path\" : path , \"output_zip_file_name\" : zip_name , \"remove_original_after_zip\" : remove_file } zip_path = urljoin ( self . _hsapi_path , \"functions\" , \"zip\" ) self . _hs_session . post ( zip_path , status_code = 200 , data = data )","title":"file_zip"},{"location":"api/resource/#hsclient.hydroshare.Resource.folder_create","text":"Creates a folder on HydroShare :param folder: the folder path to create :return: None Source code in hsclient\\hydroshare.py @refresh def folder_create ( self , folder : str ) -> None : \"\"\" Creates a folder on HydroShare :param folder: the folder path to create :return: None \"\"\" path = urljoin ( self . _hsapi_path , \"folders\" , folder ) self . _hs_session . put ( path , status_code = 201 )","title":"folder_create"},{"location":"api/resource/#hsclient.hydroshare.Resource.folder_delete","text":"Deletes a folder on HydroShare :param path: the path to the folder :return: None Source code in hsclient\\hydroshare.py @refresh def folder_delete ( self , path : str = None ) -> None : \"\"\" Deletes a folder on HydroShare :param path: the path to the folder :return: None \"\"\" self . _delete_file_folder ( path )","title":"folder_delete"},{"location":"api/resource/#hsclient.hydroshare.Resource.folder_download","text":"Downloads a folder from HydroShare :param path: The path to folder :param save_path: The local path to save the download to, defaults to the current directory :return: The path to the download zipped folder Source code in hsclient\\hydroshare.py def folder_download ( self , path : str , save_path : str = \"\" ): \"\"\" Downloads a folder from HydroShare :param path: The path to folder :param save_path: The local path to save the download to, defaults to the current directory :return: The path to the download zipped folder \"\"\" return self . _hs_session . retrieve_zip ( urljoin ( self . _resource_path , \"data\" , \"contents\" , path ), save_path , params = { \"zipped\" : \"true\" } )","title":"folder_download"},{"location":"api/resource/#hsclient.hydroshare.Resource.folder_rename","text":"Renames a folder on HydroShare :param path: the path to the folder to rename :param new_path: the new path folder name :return: None Source code in hsclient\\hydroshare.py @refresh def folder_rename ( self , path : str , new_path : str ) -> None : \"\"\" Renames a folder on HydroShare :param path: the path to the folder to rename :param new_path: the new path folder name :return: None \"\"\" self . file_rename ( path = path , new_path = new_path )","title":"folder_rename"},{"location":"api/resource/#hsclient.hydroshare.Resource.new_version","text":"Creates a new version of the resource on HydroShare :return: A Resource object of the newly created resource version Source code in hsclient\\hydroshare.py def new_version ( self ): \"\"\" Creates a new version of the resource on HydroShare :return: A Resource object of the newly created resource version \"\"\" path = urljoin ( self . _hsapi_path , \"version\" ) response = self . _hs_session . post ( path , status_code = 202 ) resource_id = response . text return Resource ( \"/resource/ {} /data/resourcemap.xml\" . format ( resource_id ), self . _hs_session )","title":"new_version"},{"location":"api/resource/#hsclient.hydroshare.Resource.reference_create","text":"Creates a HydroShare reference object to reference content outside of the resource :param file_name: the file name of the resulting .url file :param url: the url of the referenced content :param path: the path to create the reference in :return: None Source code in hsclient\\hydroshare.py @refresh def reference_create ( self , file_name : str , url : str , path : str = '' ) -> None : \"\"\" Creates a HydroShare reference object to reference content outside of the resource :param file_name: the file name of the resulting .url file :param url: the url of the referenced content :param path: the path to create the reference in :return: None \"\"\" request_path = urljoin ( self . _hsapi_path . replace ( self . resource_id , \"\" ), \"data-store-add-reference\" ) self . _hs_session . post ( request_path , data = { \"res_id\" : self . resource_id , \"curr_path\" : path , \"ref_name\" : file_name , \"ref_url\" : url }, status_code = 200 , )","title":"reference_create"},{"location":"api/resource/#hsclient.hydroshare.Resource.reference_update","text":"Updates a HydroShare reference object :param file_name: the file name for the .url file :param url: the url of the referenced content :param path: the path to the directory where the reference is located :return: None Source code in hsclient\\hydroshare.py @refresh def reference_update ( self , file_name : str , url : str , path : str = '' ) -> None : \"\"\" Updates a HydroShare reference object :param file_name: the file name for the .url file :param url: the url of the referenced content :param path: the path to the directory where the reference is located :return: None \"\"\" request_path = urljoin ( self . _hsapi_path . replace ( self . resource_id , \"\" ), \"data_store_edit_reference_url\" ) self . _hs_session . post ( request_path , data = { \"res_id\" : self . resource_id , \"curr_path\" : path , \"url_filename\" : file_name , \"new_ref_url\" : url }, status_code = 200 , )","title":"reference_update"},{"location":"api/resource/#hsclient.hydroshare.Resource.save","text":"Saves the metadata to HydroShare :return: None Source code in hsclient\\hydroshare.py @refresh def save ( self ) -> None : \"\"\" Saves the metadata to HydroShare :return: None \"\"\" metadata_string = rdf_string ( self . _retrieved_metadata , rdf_format = \"xml\" ) path = urljoin ( self . _hsapi_path , \"ingest_metadata\" ) self . _hs_session . upload_file ( path , files = { 'file' : ( 'resourcemetadata.xml' , metadata_string )})","title":"save"},{"location":"api/resource/#hsclient.hydroshare.Resource.set_sharing_status","text":"Set the sharing status of the resource to public or private :param public: bool, set to True for public, False for private Source code in hsclient\\hydroshare.py def set_sharing_status ( self , public : bool ): \"\"\" Set the sharing status of the resource to public or private :param public: bool, set to True for public, False for private \"\"\" path = urljoin ( \"hsapi\" , \"resource\" , \"accessRules\" , self . resource_id ) data = { 'public' : public } self . _hs_session . put ( path , status_code = 200 , data = data )","title":"set_sharing_status"},{"location":"api/resource/#hsclient.hydroshare.Resource.system_metadata","text":"The system metadata associated with the HydroShare resource returns: JSON object Source code in hsclient\\hydroshare.py def system_metadata ( self ): \"\"\" The system metadata associated with the HydroShare resource returns: JSON object \"\"\" hsapi_path = urljoin ( self . _hsapi_path , 'sysmeta' ) return self . _hs_session . get ( hsapi_path , status_code = 200 ) . json ()","title":"system_metadata"},{"location":"api/time_series_aggregation/","text":"Bases: DataObjectSupportingAggregation Represents a Time Series Aggregation in HydroShare Source code in hsclient\\hydroshare.py class TimeseriesAggregation ( DataObjectSupportingAggregation ): \"\"\"Represents a Time Series Aggregation in HydroShare\"\"\" @classmethod def create ( cls , base_aggr ): return super () . create ( aggr_cls = cls , base_aggr = base_aggr ) def as_data_object ( self , agg_path : str , series_id : str = \"\" ) -> 'pandas.DataFrame' : \"\"\" Loads the Time Series aggregation to a pandas DataFrame object :param agg_path: the path to the Time Series aggregation :param series_id: the series id of the time series to retrieve :return: the Time Series aggregation as a pandas DataFrame object \"\"\" if pandas is None : raise Exception ( \"pandas package not found\" ) def to_series ( timeseries_file : str ): con = sqlite3 . connect ( timeseries_file ) return pandas . read_sql ( f 'SELECT * FROM TimeSeriesResultValues WHERE ResultID IN ' f '(SELECT ResultID FROM Results WHERE ResultUUID = \" { series_id } \");' , con , ) . squeeze () return self . _get_data_object ( agg_path = agg_path , func = to_series ) def save_data_object ( self , resource : 'Resource' , agg_path : str , as_new_aggr : bool = False , destination_path : str = \"\" ) -> 'Aggregation' : \"\"\" Saves the pandas DataFrame object to the Time Series aggregation :param resource: the resource containing the aggregation :param agg_path: the path to the Time Series aggregation :param as_new_aggr: Defaults False, set to True to create a new Time Series aggregation :param destination_path: the destination path in Hydroshare to save the new aggregation :return: the updated or new Time Series aggregation \"\"\" self . _validate_aggregation_for_update ( resource , AggregationType . TimeSeriesAggregation ) file_path = self . _validate_aggregation_path ( agg_path , for_save_data = True ) with closing ( sqlite3 . connect ( file_path )) as conn : # write the dataframe to a temp table self . _data_object . to_sql ( 'temp' , conn , if_exists = 'replace' , index = False ) # delete the matching records from the TimeSeriesResultValues table conn . execute ( \"DELETE FROM TimeSeriesResultValues WHERE ResultID IN (SELECT ResultID FROM temp)\" ) conn . execute ( \"INSERT INTO TimeSeriesResultValues SELECT * FROM temp\" ) # delete the temp table conn . execute ( \"DROP TABLE temp\" ) conn . commit () aggr_main_file_path = self . main_file_path data_object = self . _data_object if not as_new_aggr : # cache some of the metadata fields of the original aggregation to update the metadata of the # updated aggregation keywords = self . metadata . subjects additional_meta = self . metadata . additional_metadata title = self . metadata . title abstract = self . metadata . abstract # upload the updated aggregation files to the temp folder - to create the updated aggregation self . _update_aggregation ( resource , file_path ) # retrieve the updated aggregation aggr = resource . aggregation ( file__path = aggr_main_file_path ) # update metadata for kw in keywords : if kw not in aggr . metadata . subjects : aggr . metadata . subjects . append ( kw ) aggr . metadata . additional_metadata = additional_meta aggr . metadata . title = title aggr . metadata . abstract = abstract aggr . save () else : # creating a new aggregation by uploading the updated data files resource . file_upload ( file_path , destination_path = destination_path ) # retrieve the new aggregation agg_path = urljoin ( destination_path , os . path . basename ( aggr_main_file_path )) aggr = resource . aggregation ( file__path = agg_path ) data_object = None aggr . _data_object = data_object return aggr as_data_object ( agg_path , series_id = '' ) Loads the Time Series aggregation to a pandas DataFrame object :param agg_path: the path to the Time Series aggregation :param series_id: the series id of the time series to retrieve :return: the Time Series aggregation as a pandas DataFrame object Source code in hsclient\\hydroshare.py def as_data_object ( self , agg_path : str , series_id : str = \"\" ) -> 'pandas.DataFrame' : \"\"\" Loads the Time Series aggregation to a pandas DataFrame object :param agg_path: the path to the Time Series aggregation :param series_id: the series id of the time series to retrieve :return: the Time Series aggregation as a pandas DataFrame object \"\"\" if pandas is None : raise Exception ( \"pandas package not found\" ) def to_series ( timeseries_file : str ): con = sqlite3 . connect ( timeseries_file ) return pandas . read_sql ( f 'SELECT * FROM TimeSeriesResultValues WHERE ResultID IN ' f '(SELECT ResultID FROM Results WHERE ResultUUID = \" { series_id } \");' , con , ) . squeeze () return self . _get_data_object ( agg_path = agg_path , func = to_series ) save_data_object ( resource , agg_path , as_new_aggr = False , destination_path = '' ) Saves the pandas DataFrame object to the Time Series aggregation :param resource: the resource containing the aggregation :param agg_path: the path to the Time Series aggregation :param as_new_aggr: Defaults False, set to True to create a new Time Series aggregation :param destination_path: the destination path in Hydroshare to save the new aggregation :return: the updated or new Time Series aggregation Source code in hsclient\\hydroshare.py def save_data_object ( self , resource : 'Resource' , agg_path : str , as_new_aggr : bool = False , destination_path : str = \"\" ) -> 'Aggregation' : \"\"\" Saves the pandas DataFrame object to the Time Series aggregation :param resource: the resource containing the aggregation :param agg_path: the path to the Time Series aggregation :param as_new_aggr: Defaults False, set to True to create a new Time Series aggregation :param destination_path: the destination path in Hydroshare to save the new aggregation :return: the updated or new Time Series aggregation \"\"\" self . _validate_aggregation_for_update ( resource , AggregationType . TimeSeriesAggregation ) file_path = self . _validate_aggregation_path ( agg_path , for_save_data = True ) with closing ( sqlite3 . connect ( file_path )) as conn : # write the dataframe to a temp table self . _data_object . to_sql ( 'temp' , conn , if_exists = 'replace' , index = False ) # delete the matching records from the TimeSeriesResultValues table conn . execute ( \"DELETE FROM TimeSeriesResultValues WHERE ResultID IN (SELECT ResultID FROM temp)\" ) conn . execute ( \"INSERT INTO TimeSeriesResultValues SELECT * FROM temp\" ) # delete the temp table conn . execute ( \"DROP TABLE temp\" ) conn . commit () aggr_main_file_path = self . main_file_path data_object = self . _data_object if not as_new_aggr : # cache some of the metadata fields of the original aggregation to update the metadata of the # updated aggregation keywords = self . metadata . subjects additional_meta = self . metadata . additional_metadata title = self . metadata . title abstract = self . metadata . abstract # upload the updated aggregation files to the temp folder - to create the updated aggregation self . _update_aggregation ( resource , file_path ) # retrieve the updated aggregation aggr = resource . aggregation ( file__path = aggr_main_file_path ) # update metadata for kw in keywords : if kw not in aggr . metadata . subjects : aggr . metadata . subjects . append ( kw ) aggr . metadata . additional_metadata = additional_meta aggr . metadata . title = title aggr . metadata . abstract = abstract aggr . save () else : # creating a new aggregation by uploading the updated data files resource . file_upload ( file_path , destination_path = destination_path ) # retrieve the new aggregation agg_path = urljoin ( destination_path , os . path . basename ( aggr_main_file_path )) aggr = resource . aggregation ( file__path = agg_path ) data_object = None aggr . _data_object = data_object return aggr","title":"Time Series Aggregation"},{"location":"api/time_series_aggregation/#hsclient.hydroshare.TimeseriesAggregation.as_data_object","text":"Loads the Time Series aggregation to a pandas DataFrame object :param agg_path: the path to the Time Series aggregation :param series_id: the series id of the time series to retrieve :return: the Time Series aggregation as a pandas DataFrame object Source code in hsclient\\hydroshare.py def as_data_object ( self , agg_path : str , series_id : str = \"\" ) -> 'pandas.DataFrame' : \"\"\" Loads the Time Series aggregation to a pandas DataFrame object :param agg_path: the path to the Time Series aggregation :param series_id: the series id of the time series to retrieve :return: the Time Series aggregation as a pandas DataFrame object \"\"\" if pandas is None : raise Exception ( \"pandas package not found\" ) def to_series ( timeseries_file : str ): con = sqlite3 . connect ( timeseries_file ) return pandas . read_sql ( f 'SELECT * FROM TimeSeriesResultValues WHERE ResultID IN ' f '(SELECT ResultID FROM Results WHERE ResultUUID = \" { series_id } \");' , con , ) . squeeze () return self . _get_data_object ( agg_path = agg_path , func = to_series )","title":"as_data_object"},{"location":"api/time_series_aggregation/#hsclient.hydroshare.TimeseriesAggregation.save_data_object","text":"Saves the pandas DataFrame object to the Time Series aggregation :param resource: the resource containing the aggregation :param agg_path: the path to the Time Series aggregation :param as_new_aggr: Defaults False, set to True to create a new Time Series aggregation :param destination_path: the destination path in Hydroshare to save the new aggregation :return: the updated or new Time Series aggregation Source code in hsclient\\hydroshare.py def save_data_object ( self , resource : 'Resource' , agg_path : str , as_new_aggr : bool = False , destination_path : str = \"\" ) -> 'Aggregation' : \"\"\" Saves the pandas DataFrame object to the Time Series aggregation :param resource: the resource containing the aggregation :param agg_path: the path to the Time Series aggregation :param as_new_aggr: Defaults False, set to True to create a new Time Series aggregation :param destination_path: the destination path in Hydroshare to save the new aggregation :return: the updated or new Time Series aggregation \"\"\" self . _validate_aggregation_for_update ( resource , AggregationType . TimeSeriesAggregation ) file_path = self . _validate_aggregation_path ( agg_path , for_save_data = True ) with closing ( sqlite3 . connect ( file_path )) as conn : # write the dataframe to a temp table self . _data_object . to_sql ( 'temp' , conn , if_exists = 'replace' , index = False ) # delete the matching records from the TimeSeriesResultValues table conn . execute ( \"DELETE FROM TimeSeriesResultValues WHERE ResultID IN (SELECT ResultID FROM temp)\" ) conn . execute ( \"INSERT INTO TimeSeriesResultValues SELECT * FROM temp\" ) # delete the temp table conn . execute ( \"DROP TABLE temp\" ) conn . commit () aggr_main_file_path = self . main_file_path data_object = self . _data_object if not as_new_aggr : # cache some of the metadata fields of the original aggregation to update the metadata of the # updated aggregation keywords = self . metadata . subjects additional_meta = self . metadata . additional_metadata title = self . metadata . title abstract = self . metadata . abstract # upload the updated aggregation files to the temp folder - to create the updated aggregation self . _update_aggregation ( resource , file_path ) # retrieve the updated aggregation aggr = resource . aggregation ( file__path = aggr_main_file_path ) # update metadata for kw in keywords : if kw not in aggr . metadata . subjects : aggr . metadata . subjects . append ( kw ) aggr . metadata . additional_metadata = additional_meta aggr . metadata . title = title aggr . metadata . abstract = abstract aggr . save () else : # creating a new aggregation by uploading the updated data files resource . file_upload ( file_path , destination_path = destination_path ) # retrieve the new aggregation agg_path = urljoin ( destination_path , os . path . basename ( aggr_main_file_path )) aggr = resource . aggregation ( file__path = agg_path ) data_object = None aggr . _data_object = data_object return aggr","title":"save_data_object"},{"location":"examples/Aggregation_Data_Object_Operations/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); hsclient HydroShare Python Client Resource Aggregation Data Object Operation Examples The following code snippets show examples for how to use the hsclient HydroShare Python Client to load certain aggregation data types to relevant data processing objects to view data properties as well as be able to modify the data. The aggregation data object feature is available for the following HydroShare's content type aggregations: Time series Geographic feature Geographic raster Multidimensional NetCDF CSV Install the hsclient Python Client The hsclient Python Client for HydroShare may not be installed by default in your Python environment, so it has to be installed first before you can work with it. Use the following command to install hsclient via the Python Package Index (PyPi). This will install the hsclient as well as all the python packages to work with aggregation data as data processing objects. The following packages will be installed in addition to hsclient: pandas fiona rasterio xarray !pip install hsclient[all] Authenticating with HydroShare Before you start interacting with resources in HydroShare you will need to authenticate. import os from hsclient import HydroShare hs = HydroShare() hs.sign_in() Loading Resource Aggregation Data to Relevant Python Data Analysis Modules The python data analysis module used for each of the supported aggregation types is shown below: Time series : pandas.DataFrame Geographic feature : fiona.Collection Geographic raster : rasterio.DatasetReader Multidimensional NetCDF : xarray.Dataset CSV : pandas.DataFrame In the following code examples, we are assuming that we have a resource in HydroShare that contains the above five aggregation types. All these aggregations are at the root of the resource. The resource id used in the following code examples is \"a0e0c2e2e5e84e1e9b6b2b2b2b2b2b2b\". You will need to change this resource id to the id of your resource in HydroShare. # first we need to get the resource object from HydroShare using id of the resource resource_id = 'a0e0c2e2e5e84e1e9b6b2b2b2b2b2b2b' resource = hs.resource(resource_id) # show resource identifier print(f\"Resource ID:{resource.resource_id}\") Loading Time Series Data to pandas.DataFrame Here we are assuming the time series aggregation contains a sqlite file with name \"sample.sqlite\" # retrieve the time series aggregation file_path = \"sample.sqlite\" ts_aggr = resource.aggregation(file__path=file_path) # show the aggregation type print(f\"Aggregation Type:{ts_aggr.metadata.type}\") # display the time series results metadata to see the all available series # later we will use one of the series ids to retrieve the time series data print(ts_aggr.metadata.time_series_results) # download the time series aggregation - these directory paths must exist for hsclient to download and unzip the aggregation zip file # Note: These directory paths need to be changed based on where you want to download the aggregation base_working_dir = \"aggr_objects\" download_to = os.path.join(base_working_dir, \"timeseries_testing\") unzip_to = os.path.join(download_to, \"aggr_unzipped\") aggr_path = resource.aggregation_download(aggregation=ts_aggr, save_path=download_to, unzip_to=unzip_to) print(f\"Downloaded aggregation to:{aggr_path}\") # load a given time series of the aggregation as pandas.DataFrame from the downloaded location (aggr_path) # Note: Here we are assuming the series id used below is one of the ids we found when we printed the # time series results in the earlier coding step series_id = '51e31687-1ebc-11e6-aa6c-f45c8999816f' pd_dataframe = ts_aggr.as_data_object(series_id=series_id, agg_path=aggr_path) print(f\"Type of data processing object:{type(pd_dataframe)}\") # now we can use the pandas.DataFrame to do some data analysis # show time series column headings print(pd_dataframe.columns) # show time series data summary print(pd_dataframe.info) # show number of data points in time series print(pd_dataframe.size) # show first 5 records in time series print(pd_dataframe.head(5)) # editing time series aggregation data using the pandas.DataFrame print(f\"Data frame size before edit:{pd_dataframe.size}\") rows, columns = pd_dataframe.shape print(f\"Number of rows:{rows}\") print(f\"Number of columns:{columns}\") # delete 10 rows from the dataframe. This will result in deleting 10 records from the 'TimeSeriesResultValues' table when we save the dataframe. pd_dataframe.drop(pd_dataframe.index[0:10], axis=0, inplace=True) rows, columns = pd_dataframe.shape print(f\"Number of rows in dataframe after delete:{rows}\") print(f\"Number of columns in dataframe after delete:{columns}\") print(f\"Data frame size after delete:{pd_dataframe.size}\") expected_row_count = rows # save the updated dataframe object to the time series aggregation in HydroShare # Note this will update the data for the existing time series aggregation in HydroShare - this operation may take a while ts_aggr = ts_aggr.save_data_object(resource=resource, agg_path=aggr_path, as_new_aggr=False) print(f\"Updated time series aggregation ...\") # we can also create a new time series aggregation in HydroShare using the updated dataframe object # we will first create a new folder in which the new aggregation will be created aggr_folder = \"ts_folder\" resource.folder_create(folder=aggr_folder) # this operation may take a while ts_aggr = ts_aggr.save_data_object(resource=resource, agg_path=aggr_path, as_new_aggr=True, destination_path=aggr_folder) print(f\"Created a new time series aggregation ...\") # retrieve the updated time series aggregation to verify the data was updated # reload the new timeseries as pandas.DataFrame # need to first download this new aggregation aggr_path = resource.aggregation_download(aggregation=ts_aggr, save_path=download_to, unzip_to=unzip_to) print(f\"Downloaded aggregation to:{aggr_path}\") pd_dataframe = ts_aggr.as_data_object(series_id=series_id, agg_path=aggr_path) rows, columns = pd_dataframe.shape print(f\"Number of rows in the updated timeseries:{rows}\") print(f\"Number of columns in the updated timeseries:{columns}\") assert rows == expected_row_count Loading Geographic Feature Data to fiona.Collection Here we are assuming the geographic feature aggregation contains a shapefile with name \"sample.shp\" # retrieve the geographic feature aggregation file_path = \"sample.shp\" gf_aggr = resource.aggregation(file__path=file_path) # show the aggregation type print(f\"Aggregation Type:{gf_aggr.metadata.type}\") # download the geographic feature aggregation - these directory paths must exist for hsclient to download and unzip the aggregation zip file # Note: These directory paths need to be changed based on where you want to download the aggregation download_to = os.path.join(base_working_dir, \"geofeature_testing\") unzip_to = os.path.join(download_to, \"aggr_unzipped\") aggr_path = resource.aggregation_download(aggregation=gf_aggr, save_path=download_to, unzip_to=unzip_to) print(f\"Downloaded aggregation to:{aggr_path}\") # load the downloaded geo-feature aggregation as a fiona Collection object fiona_coll = gf_aggr.as_data_object(agg_path=aggr_path) print(f\"Type of data processing object:{type(fiona_coll)}\") # now we can use the fiona.Collection object to do some data analysis # show driver used to open the vector file print(fiona_coll.driver) # show feature collection coordinate reference system print(fiona_coll.crs) # show feature collection spatial coverage print(fiona_coll.bounds) # show number of features/bands print(len(list(fiona_coll))) # show feature field information print(fiona_coll.schema) # show data for a single feature in feature collection from fiona.model import to_dict feature = fiona_coll[1] to_dict(feature) # editing geographic feature aggregation data using the fiona.Collection object import fiona # location of the new output shp file # Note: The output shapefile directory path must exist. output_shp_file_dir_path = os.path.join(download_to, \"updated_aggr\") # name the output shape file same as the original shape file orig_shp_file_name = os.path.basename(gf_aggr.main_file_path) output_shp_file_path = os.path.join(output_shp_file_dir_path, orig_shp_file_name) # here we will remove one of the bands (where the state name is Alaska) and then write the updated data to a new shp file # Note: You have to use a different criteria for selecting bands depending on your feature dataset with fiona.open(output_shp_file_path, 'w', schema=fiona_coll.schema, driver=fiona_coll.driver, crs=fiona_coll.crs) as out_shp_file: for feature in fiona_coll: ft_dict = to_dict(feature) if ft_dict['properties']['STATE_NAME'] != \"Alaska\": out_shp_file.write(feature) else: print(\"&gt;&gt; Skipping feature for Alaska\") print(\"Done updating the shp file ...\") # we can now update the geographic feature aggregation in HydroShare using the updated shp file - this operation may take a while gf_aggr = gf_aggr.save_data_object(resource=resource, agg_path=output_shp_file_dir_path, as_new_aggr=False) print(\"Aggregation updated ...\") # we can also create a new geographic feature aggregation in HydroShare using the updated shp file # we will first create a new folder in which the new aggregation will be created in HydroShare aggr_folder = \"gf_folder\" resource.folder_create(folder=aggr_folder) # first retrieve the data object from the updated shp file - this step is not needed if your have not saved the object previously fiona_coll = gf_aggr.as_data_object(agg_path=output_shp_file_dir_path) # this operation may take a while gf_aggr = gf_aggr.save_data_object(resource=resource, agg_path=output_shp_file_dir_path, as_new_aggr=True, destination_path=aggr_folder) print(\"New aggregation created ...\") # retrieve the updated geographic feature aggregation to verify the data was updated # need to first download this updated/new aggregation aggr_path = resource.aggregation_download(aggregation=gf_aggr, save_path=download_to, unzip_to=unzip_to) fiona_coll = gf_aggr.as_data_object(agg_path=aggr_path) # check the number of bands in the updated aggregation print(len(list(fiona_coll))) Loading Multidimensional Data to xarray.Dataset Here we are assuming the multidimensional aggregation contains a netcdf file with name \"sample.nc\" # retrieve the multidimensional aggregation file_path = \"sample.nc\" md_aggr = resource.aggregation(file__path=file_path) print(f\"Aggregation Type:{md_aggr.metadata.type}\") # download the multidimensional aggregation - these directory paths must exist for hsclient to download and unzip the aggregation zip file # Note: These directory paths need to be changed based on where you want to download the aggregation download_to = os.path.join(base_working_dir, \"netcdf_testing\") unzip_to = os.path.join(download_to, \"aggr_unzipped\") aggr_path = resource.aggregation_download(aggregation=md_aggr, save_path=download_to, unzip_to=unzip_to) print(f\"Downloaded aggregation to:{aggr_path}\") # load the downloaded multidimensional aggregation as a xarray.Dataset object xarray_ds = md_aggr.as_data_object(agg_path=aggr_path) print(f\"Type of data processing object:{type(xarray_ds)}\") # now we can use the xarray.Dataset object to do some data analysis # show netcdf global attributes print(xarray_ds.attrs) # show netcdf dimensions print(xarray_ds.dims) # show coordinate variables of the netcdf dataset print(xarray_ds.coords) # editing multidimensional aggregation data using the xarray.Dataset object # here we will only change the title attribute of the dataset aggr_title = \"This is a modified title for this aggregation modified using hsclient\" xarray_ds.attrs[\"title\"] = aggr_title # we can update the multidimensional aggregation in HydroShare using the updated xarray.Dataset object - this operation may take a while md_aggr = md_aggr.save_data_object(resource=resource, agg_path=aggr_path, as_new_aggr=False) print(\"Aggregation updated ...\") # we can also create a new multidimensional aggregation in HydroShare using the updated xarray.Dataset object # we will first create a new folder in which the new aggregation will be created aggr_folder = \"md_folder\" resource.folder_create(folder=aggr_folder) # first retrieve the data object from the updated netcdf file - this step is not needed if your have not saved the object previously xarray_ds = md_aggr.as_data_object(agg_path=aggr_path) # this operation may take a while md_aggr = md_aggr.save_data_object(resource=resource, agg_path=aggr_path, as_new_aggr=True, destination_path=aggr_folder) print(\"New aggregation created ...\") # retrieve the updated multidimensional aggregation to verify the data was updated # need to first download this updated/new aggregation aggr_path = resource.aggregation_download(aggregation=md_aggr, save_path=download_to, unzip_to=unzip_to) xarray_ds = md_aggr.as_data_object(agg_path=aggr_path) # check the title attribute of the updated aggregation assert xarray_ds.attrs[\"title\"] == aggr_title Loading Geo Raster Data to rasterio.DatasetReader Here we are assuming the georaster aggregation contains a geotiff file with name \"sample.tif\" # retrieve the georaster aggregation file_path = \"sample.tif\" gr_aggr = resource.aggregation(file__path=file_path) print(f\"Aggregation Type:{gr_aggr.metadata.type}\") # download the georaster aggregation - these directory paths must exist for hsclient to download and unzip the aggregation zip file # Note: These directory paths need to be changed based on where you want to download the aggregation download_to = os.path.join(base_working_dir, \"georaster_testing\") unzip_to = os.path.join(download_to, \"aggr_unzipped\") aggr_path = resource.aggregation_download(aggregation=gr_aggr, save_path=download_to, unzip_to=unzip_to) print(f\"Downloaded aggregation to:{aggr_path}\") # load the downloaded georaster aggregation as a rasterio.DatasetReader object rasterio_ds = gr_aggr.as_data_object(agg_path=aggr_path) print(f\"Type of data processing object:{type(rasterio_ds)}\") # now we can use the rasterio.DatasetReader object to do some data analysis # show raster band count print(rasterio_ds.count) # show raster band dimensions print(rasterio_ds.width, rasterio_ds.height) # show raster coordinate reference system print(rasterio_ds.crs) # show raster bounds print(rasterio_ds.bounds) # show raster data data = rasterio_ds.read() print(data) # editing georaster aggregation data using the rasterio.DatasetReader object from rasterio.windows import Window import rasterio # here we will subset the raster data to a smaller extent print(\"raster dimensions before editing:\") print(f\"raster width :{rasterio_ds.width}\") print(f\"raster height:{rasterio_ds.height}\") new_width = rasterio_ds.width - 9 new_height = rasterio_ds.height - 10 subset_window = Window(0, 0, new_width, new_height) subset_band = rasterio_ds.read(1, window=subset_window) print(subset_band) # write the subset data to a new tif file - note the target directory must be empty # Note: The original raster aggregation may have more than one tif files. The following update will always result in an updated or new aggregation # with a single tif file. output_raster_dir_path = os.path.join(base_working_dir, \"georaster_testing\", \"updated_aggr\") output_raster_filename = \"out_sample.tif\" output_raster_file_path = os.path.join(output_raster_dir_path, output_raster_filename) profile = rasterio_ds.profile rasterio_ds.close() profile['driver'] = \"GTiff\" profile['width'] = new_width profile['height'] = new_height with rasterio.open(output_raster_file_path, \"w\", **profile) as dst: dst.write(subset_band, 1) print(f\"Saved subset raster to:{output_raster_file_path}\") # we can update the georaster aggregation in HydroShare using the updated rasterio.DatasetReader object - this operation may take a while gr_aggr = gr_aggr.save_data_object(resource=resource, agg_path=output_raster_dir_path, as_new_aggr=False) print(\"Aggregation updated ...\") # we can also create a new georaster aggregation in HydroShare using the updated rasterio.DatasetReader object # If you have already updated the aggregation as described in the previous cell, then you have to first download the updated aggregation and load the # rasterio.DatasetReader object from the downloaded location before you can save the updated raster to a new aggregation in HydroShare as shown below. Otherwise, you can execute the code in the next cell. download_to = os.path.join(base_working_dir, \"georaster_testing\") # note the unzip_to directory must exist and be empty unzip_to = os.path.join(download_to, \"updated_aggr_unzipped\") aggr_path = resource.aggregation_download(aggregation=gr_aggr, save_path=download_to, unzip_to=unzip_to) print(f\"Downloaded aggregation to:{aggr_path}\") # reload the updated raster as rasterio.DatasetReader rasterio_ds = gr_aggr.as_data_object(agg_path=aggr_path) # we can also create a new georaster aggregation in HydroShare using the updated rasterio.DatasetReader object # we will first create a new folder in which the new aggregation will be created aggr_folder = \"gr_folder\" resource.folder_create(folder=aggr_folder) # this operation may take a while gr_aggr = gr_aggr.save_data_object(resource=resource, agg_path=output_raster_dir_path, as_new_aggr=True, destination_path=aggr_folder) print(\"New aggregation created ...\") # retrieve the updated georaster aggregation to verify the data was updated # need to first download this updated/new aggregation download_to = os.path.join(base_working_dir, \"georaster_testing\") # note the unzip_to directory must exist and be empty unzip_to = os.path.join(download_to, \"aggr_unzipped\") aggr_path = resource.aggregation_download(aggregation=gr_aggr, save_path=download_to, unzip_to=unzip_to) rasterio_ds = gr_aggr.as_data_object(agg_path=aggr_path) # check the raster dimensions of the updated aggregation print(\"raster dimensions after editing:\") print(f\"raster width :{rasterio_ds.width}\") print(f\"raster height:{rasterio_ds.height}\") Loading CSV Data to pandas.DataFrame Here we are assuming the CSV aggregation contains a CSV file with name \"sample.csv\" # retrieve the CSV aggregation file_path = \"sample.csv\" csv_aggr = resource.aggregation(file__path=file_path) # show the aggregation type print(f\"Aggregation Type:{csv_aggr.metadata.type}\") # download the CSV aggregation - these directory paths must exist for hsclient to download and unzip the aggregation zip file # Note: These directory paths need to be changed based on where you want to download the aggregation download_to = os.path.join(base_working_dir, \"csv_testing\") unzip_to = os.path.join(download_to, \"aggr_unzipped\") aggr_path = resource.aggregation_download(aggregation=csv_aggr, save_path=download_to, unzip_to=unzip_to) print(f\"Downloaded aggregation to:{aggr_path}\") # load the CSV aggregation as pandas.DataFrame csv_df = csv_aggr.as_data_object(agg_path=aggr_path) # show number of rows and columns print(f\"Number of data rows:{len(csv_df)}\") print(f\"Number of data columns:{len(csv_df.columns)}\") # show the first 5 data rows print(csv_df.head(5)) # show the extracted CSV aggregation metadata (table schema) table_schema = csv_aggr.metadata.tableSchema table = table_schema.table print(f\"Number of data rows:{table_schema.rows}\") print(f\"Number of data columns:{len(table.columns)}\") print(f\"Delimiter:{table_schema.delimiter}\") # show data column properties for col in table.columns: print(f\"Column number:{col.column_number}\") print(f\"Column title:{col.title}\") print(f\"Column description:{col.description}\") print(f\"Column data type:{col.datatype}\") print(\"-\"*50) Editing CSV aggregation using pandas.DataFrame # drop the last data column - note all editing needs to be in 'inplace' mode csv_df.drop(csv_df.columns[-1], axis=1, inplace=True) # show the number of data columns after the edit print(f\"Number of data columns after edit:{len(csv_df.columns)}\") # save the updated CSV aggregation in Hydroshare # Note this will overwrite the original aggregation - this operation may take a while csv_aggr = csv_aggr.save_data_object(resource=resource, agg_path=aggr_path, as_new_aggr=False) print(\"Aggregation updated ...\") # we can also create a new CSV aggregation in HydroShare using the updated pandas.DataFrame object # we first create a new folder in which the new aggregation will be created aggr_folder = \"csv_folder\" resource.folder_create(folder=aggr_folder) # this operation may take a while csv_aggr = csv_aggr.save_data_object(resource=resource, agg_path=aggr_path, as_new_aggr=True, destination_path=aggr_folder) print(\"New CSV aggregation was created ...\") # retrieve the updated CSV aggregation to verify the data got updated download_to = os.path.join(base_working_dir, \"csv_testing\") # note the unzip_to directory must exist and be empty unzip_to = os.path.join(download_to, \"aggr_unzipped\") aggr_path = resource.aggregation_download(aggregation=csv_aggr, save_path=download_to, unzip_to=unzip_to) csv_df = csv_aggr.as_data_object(agg_path=aggr_path) # show the number of data rows and columns print(f\"Number of data rows:{len(csv_df)}\") print(f\"Number of data columns:{len(csv_df.columns)}\") # show the first 5 data rows print(csv_df.head(5))","title":"Aggregation Data Object Operations"},{"location":"examples/Aggregation_Data_Object_Operations/#hsclient-hydroshare-python-client-resource-aggregation-data-object-operation-examples","text":"The following code snippets show examples for how to use the hsclient HydroShare Python Client to load certain aggregation data types to relevant data processing objects to view data properties as well as be able to modify the data. The aggregation data object feature is available for the following HydroShare's content type aggregations: Time series Geographic feature Geographic raster Multidimensional NetCDF CSV","title":"hsclient HydroShare Python Client Resource Aggregation Data Object Operation Examples"},{"location":"examples/Aggregation_Data_Object_Operations/#install-the-hsclient-python-client","text":"The hsclient Python Client for HydroShare may not be installed by default in your Python environment, so it has to be installed first before you can work with it. Use the following command to install hsclient via the Python Package Index (PyPi). This will install the hsclient as well as all the python packages to work with aggregation data as data processing objects. The following packages will be installed in addition to hsclient: pandas fiona rasterio xarray !pip install hsclient[all]","title":"Install the hsclient Python Client"},{"location":"examples/Aggregation_Data_Object_Operations/#authenticating-with-hydroshare","text":"Before you start interacting with resources in HydroShare you will need to authenticate. import os from hsclient import HydroShare hs = HydroShare() hs.sign_in()","title":"Authenticating with HydroShare"},{"location":"examples/Aggregation_Data_Object_Operations/#loading-resource-aggregation-data-to-relevant-python-data-analysis-modules","text":"The python data analysis module used for each of the supported aggregation types is shown below: Time series : pandas.DataFrame Geographic feature : fiona.Collection Geographic raster : rasterio.DatasetReader Multidimensional NetCDF : xarray.Dataset CSV : pandas.DataFrame In the following code examples, we are assuming that we have a resource in HydroShare that contains the above five aggregation types. All these aggregations are at the root of the resource. The resource id used in the following code examples is \"a0e0c2e2e5e84e1e9b6b2b2b2b2b2b2b\". You will need to change this resource id to the id of your resource in HydroShare. # first we need to get the resource object from HydroShare using id of the resource resource_id = 'a0e0c2e2e5e84e1e9b6b2b2b2b2b2b2b' resource = hs.resource(resource_id) # show resource identifier print(f\"Resource ID:{resource.resource_id}\")","title":"Loading Resource Aggregation Data to Relevant Python Data Analysis Modules"},{"location":"examples/Aggregation_Data_Object_Operations/#loading-time-series-data-to-pandasdataframe","text":"Here we are assuming the time series aggregation contains a sqlite file with name \"sample.sqlite\" # retrieve the time series aggregation file_path = \"sample.sqlite\" ts_aggr = resource.aggregation(file__path=file_path) # show the aggregation type print(f\"Aggregation Type:{ts_aggr.metadata.type}\") # display the time series results metadata to see the all available series # later we will use one of the series ids to retrieve the time series data print(ts_aggr.metadata.time_series_results) # download the time series aggregation - these directory paths must exist for hsclient to download and unzip the aggregation zip file # Note: These directory paths need to be changed based on where you want to download the aggregation base_working_dir = \"aggr_objects\" download_to = os.path.join(base_working_dir, \"timeseries_testing\") unzip_to = os.path.join(download_to, \"aggr_unzipped\") aggr_path = resource.aggregation_download(aggregation=ts_aggr, save_path=download_to, unzip_to=unzip_to) print(f\"Downloaded aggregation to:{aggr_path}\") # load a given time series of the aggregation as pandas.DataFrame from the downloaded location (aggr_path) # Note: Here we are assuming the series id used below is one of the ids we found when we printed the # time series results in the earlier coding step series_id = '51e31687-1ebc-11e6-aa6c-f45c8999816f' pd_dataframe = ts_aggr.as_data_object(series_id=series_id, agg_path=aggr_path) print(f\"Type of data processing object:{type(pd_dataframe)}\") # now we can use the pandas.DataFrame to do some data analysis # show time series column headings print(pd_dataframe.columns) # show time series data summary print(pd_dataframe.info) # show number of data points in time series print(pd_dataframe.size) # show first 5 records in time series print(pd_dataframe.head(5)) # editing time series aggregation data using the pandas.DataFrame print(f\"Data frame size before edit:{pd_dataframe.size}\") rows, columns = pd_dataframe.shape print(f\"Number of rows:{rows}\") print(f\"Number of columns:{columns}\") # delete 10 rows from the dataframe. This will result in deleting 10 records from the 'TimeSeriesResultValues' table when we save the dataframe. pd_dataframe.drop(pd_dataframe.index[0:10], axis=0, inplace=True) rows, columns = pd_dataframe.shape print(f\"Number of rows in dataframe after delete:{rows}\") print(f\"Number of columns in dataframe after delete:{columns}\") print(f\"Data frame size after delete:{pd_dataframe.size}\") expected_row_count = rows # save the updated dataframe object to the time series aggregation in HydroShare # Note this will update the data for the existing time series aggregation in HydroShare - this operation may take a while ts_aggr = ts_aggr.save_data_object(resource=resource, agg_path=aggr_path, as_new_aggr=False) print(f\"Updated time series aggregation ...\") # we can also create a new time series aggregation in HydroShare using the updated dataframe object # we will first create a new folder in which the new aggregation will be created aggr_folder = \"ts_folder\" resource.folder_create(folder=aggr_folder) # this operation may take a while ts_aggr = ts_aggr.save_data_object(resource=resource, agg_path=aggr_path, as_new_aggr=True, destination_path=aggr_folder) print(f\"Created a new time series aggregation ...\") # retrieve the updated time series aggregation to verify the data was updated # reload the new timeseries as pandas.DataFrame # need to first download this new aggregation aggr_path = resource.aggregation_download(aggregation=ts_aggr, save_path=download_to, unzip_to=unzip_to) print(f\"Downloaded aggregation to:{aggr_path}\") pd_dataframe = ts_aggr.as_data_object(series_id=series_id, agg_path=aggr_path) rows, columns = pd_dataframe.shape print(f\"Number of rows in the updated timeseries:{rows}\") print(f\"Number of columns in the updated timeseries:{columns}\") assert rows == expected_row_count","title":"Loading Time Series Data to pandas.DataFrame"},{"location":"examples/Aggregation_Data_Object_Operations/#loading-geographic-feature-data-to-fionacollection","text":"Here we are assuming the geographic feature aggregation contains a shapefile with name \"sample.shp\" # retrieve the geographic feature aggregation file_path = \"sample.shp\" gf_aggr = resource.aggregation(file__path=file_path) # show the aggregation type print(f\"Aggregation Type:{gf_aggr.metadata.type}\") # download the geographic feature aggregation - these directory paths must exist for hsclient to download and unzip the aggregation zip file # Note: These directory paths need to be changed based on where you want to download the aggregation download_to = os.path.join(base_working_dir, \"geofeature_testing\") unzip_to = os.path.join(download_to, \"aggr_unzipped\") aggr_path = resource.aggregation_download(aggregation=gf_aggr, save_path=download_to, unzip_to=unzip_to) print(f\"Downloaded aggregation to:{aggr_path}\") # load the downloaded geo-feature aggregation as a fiona Collection object fiona_coll = gf_aggr.as_data_object(agg_path=aggr_path) print(f\"Type of data processing object:{type(fiona_coll)}\") # now we can use the fiona.Collection object to do some data analysis # show driver used to open the vector file print(fiona_coll.driver) # show feature collection coordinate reference system print(fiona_coll.crs) # show feature collection spatial coverage print(fiona_coll.bounds) # show number of features/bands print(len(list(fiona_coll))) # show feature field information print(fiona_coll.schema) # show data for a single feature in feature collection from fiona.model import to_dict feature = fiona_coll[1] to_dict(feature) # editing geographic feature aggregation data using the fiona.Collection object import fiona # location of the new output shp file # Note: The output shapefile directory path must exist. output_shp_file_dir_path = os.path.join(download_to, \"updated_aggr\") # name the output shape file same as the original shape file orig_shp_file_name = os.path.basename(gf_aggr.main_file_path) output_shp_file_path = os.path.join(output_shp_file_dir_path, orig_shp_file_name) # here we will remove one of the bands (where the state name is Alaska) and then write the updated data to a new shp file # Note: You have to use a different criteria for selecting bands depending on your feature dataset with fiona.open(output_shp_file_path, 'w', schema=fiona_coll.schema, driver=fiona_coll.driver, crs=fiona_coll.crs) as out_shp_file: for feature in fiona_coll: ft_dict = to_dict(feature) if ft_dict['properties']['STATE_NAME'] != \"Alaska\": out_shp_file.write(feature) else: print(\"&gt;&gt; Skipping feature for Alaska\") print(\"Done updating the shp file ...\") # we can now update the geographic feature aggregation in HydroShare using the updated shp file - this operation may take a while gf_aggr = gf_aggr.save_data_object(resource=resource, agg_path=output_shp_file_dir_path, as_new_aggr=False) print(\"Aggregation updated ...\") # we can also create a new geographic feature aggregation in HydroShare using the updated shp file # we will first create a new folder in which the new aggregation will be created in HydroShare aggr_folder = \"gf_folder\" resource.folder_create(folder=aggr_folder) # first retrieve the data object from the updated shp file - this step is not needed if your have not saved the object previously fiona_coll = gf_aggr.as_data_object(agg_path=output_shp_file_dir_path) # this operation may take a while gf_aggr = gf_aggr.save_data_object(resource=resource, agg_path=output_shp_file_dir_path, as_new_aggr=True, destination_path=aggr_folder) print(\"New aggregation created ...\") # retrieve the updated geographic feature aggregation to verify the data was updated # need to first download this updated/new aggregation aggr_path = resource.aggregation_download(aggregation=gf_aggr, save_path=download_to, unzip_to=unzip_to) fiona_coll = gf_aggr.as_data_object(agg_path=aggr_path) # check the number of bands in the updated aggregation print(len(list(fiona_coll)))","title":"Loading Geographic Feature Data to fiona.Collection"},{"location":"examples/Aggregation_Data_Object_Operations/#loading-multidimensional-data-to-xarraydataset","text":"Here we are assuming the multidimensional aggregation contains a netcdf file with name \"sample.nc\" # retrieve the multidimensional aggregation file_path = \"sample.nc\" md_aggr = resource.aggregation(file__path=file_path) print(f\"Aggregation Type:{md_aggr.metadata.type}\") # download the multidimensional aggregation - these directory paths must exist for hsclient to download and unzip the aggregation zip file # Note: These directory paths need to be changed based on where you want to download the aggregation download_to = os.path.join(base_working_dir, \"netcdf_testing\") unzip_to = os.path.join(download_to, \"aggr_unzipped\") aggr_path = resource.aggregation_download(aggregation=md_aggr, save_path=download_to, unzip_to=unzip_to) print(f\"Downloaded aggregation to:{aggr_path}\") # load the downloaded multidimensional aggregation as a xarray.Dataset object xarray_ds = md_aggr.as_data_object(agg_path=aggr_path) print(f\"Type of data processing object:{type(xarray_ds)}\") # now we can use the xarray.Dataset object to do some data analysis # show netcdf global attributes print(xarray_ds.attrs) # show netcdf dimensions print(xarray_ds.dims) # show coordinate variables of the netcdf dataset print(xarray_ds.coords) # editing multidimensional aggregation data using the xarray.Dataset object # here we will only change the title attribute of the dataset aggr_title = \"This is a modified title for this aggregation modified using hsclient\" xarray_ds.attrs[\"title\"] = aggr_title # we can update the multidimensional aggregation in HydroShare using the updated xarray.Dataset object - this operation may take a while md_aggr = md_aggr.save_data_object(resource=resource, agg_path=aggr_path, as_new_aggr=False) print(\"Aggregation updated ...\") # we can also create a new multidimensional aggregation in HydroShare using the updated xarray.Dataset object # we will first create a new folder in which the new aggregation will be created aggr_folder = \"md_folder\" resource.folder_create(folder=aggr_folder) # first retrieve the data object from the updated netcdf file - this step is not needed if your have not saved the object previously xarray_ds = md_aggr.as_data_object(agg_path=aggr_path) # this operation may take a while md_aggr = md_aggr.save_data_object(resource=resource, agg_path=aggr_path, as_new_aggr=True, destination_path=aggr_folder) print(\"New aggregation created ...\") # retrieve the updated multidimensional aggregation to verify the data was updated # need to first download this updated/new aggregation aggr_path = resource.aggregation_download(aggregation=md_aggr, save_path=download_to, unzip_to=unzip_to) xarray_ds = md_aggr.as_data_object(agg_path=aggr_path) # check the title attribute of the updated aggregation assert xarray_ds.attrs[\"title\"] == aggr_title","title":"Loading Multidimensional Data to xarray.Dataset"},{"location":"examples/Aggregation_Data_Object_Operations/#loading-geo-raster-data-to-rasteriodatasetreader","text":"Here we are assuming the georaster aggregation contains a geotiff file with name \"sample.tif\" # retrieve the georaster aggregation file_path = \"sample.tif\" gr_aggr = resource.aggregation(file__path=file_path) print(f\"Aggregation Type:{gr_aggr.metadata.type}\") # download the georaster aggregation - these directory paths must exist for hsclient to download and unzip the aggregation zip file # Note: These directory paths need to be changed based on where you want to download the aggregation download_to = os.path.join(base_working_dir, \"georaster_testing\") unzip_to = os.path.join(download_to, \"aggr_unzipped\") aggr_path = resource.aggregation_download(aggregation=gr_aggr, save_path=download_to, unzip_to=unzip_to) print(f\"Downloaded aggregation to:{aggr_path}\") # load the downloaded georaster aggregation as a rasterio.DatasetReader object rasterio_ds = gr_aggr.as_data_object(agg_path=aggr_path) print(f\"Type of data processing object:{type(rasterio_ds)}\") # now we can use the rasterio.DatasetReader object to do some data analysis # show raster band count print(rasterio_ds.count) # show raster band dimensions print(rasterio_ds.width, rasterio_ds.height) # show raster coordinate reference system print(rasterio_ds.crs) # show raster bounds print(rasterio_ds.bounds) # show raster data data = rasterio_ds.read() print(data) # editing georaster aggregation data using the rasterio.DatasetReader object from rasterio.windows import Window import rasterio # here we will subset the raster data to a smaller extent print(\"raster dimensions before editing:\") print(f\"raster width :{rasterio_ds.width}\") print(f\"raster height:{rasterio_ds.height}\") new_width = rasterio_ds.width - 9 new_height = rasterio_ds.height - 10 subset_window = Window(0, 0, new_width, new_height) subset_band = rasterio_ds.read(1, window=subset_window) print(subset_band) # write the subset data to a new tif file - note the target directory must be empty # Note: The original raster aggregation may have more than one tif files. The following update will always result in an updated or new aggregation # with a single tif file. output_raster_dir_path = os.path.join(base_working_dir, \"georaster_testing\", \"updated_aggr\") output_raster_filename = \"out_sample.tif\" output_raster_file_path = os.path.join(output_raster_dir_path, output_raster_filename) profile = rasterio_ds.profile rasterio_ds.close() profile['driver'] = \"GTiff\" profile['width'] = new_width profile['height'] = new_height with rasterio.open(output_raster_file_path, \"w\", **profile) as dst: dst.write(subset_band, 1) print(f\"Saved subset raster to:{output_raster_file_path}\") # we can update the georaster aggregation in HydroShare using the updated rasterio.DatasetReader object - this operation may take a while gr_aggr = gr_aggr.save_data_object(resource=resource, agg_path=output_raster_dir_path, as_new_aggr=False) print(\"Aggregation updated ...\") # we can also create a new georaster aggregation in HydroShare using the updated rasterio.DatasetReader object # If you have already updated the aggregation as described in the previous cell, then you have to first download the updated aggregation and load the # rasterio.DatasetReader object from the downloaded location before you can save the updated raster to a new aggregation in HydroShare as shown below. Otherwise, you can execute the code in the next cell. download_to = os.path.join(base_working_dir, \"georaster_testing\") # note the unzip_to directory must exist and be empty unzip_to = os.path.join(download_to, \"updated_aggr_unzipped\") aggr_path = resource.aggregation_download(aggregation=gr_aggr, save_path=download_to, unzip_to=unzip_to) print(f\"Downloaded aggregation to:{aggr_path}\") # reload the updated raster as rasterio.DatasetReader rasterio_ds = gr_aggr.as_data_object(agg_path=aggr_path) # we can also create a new georaster aggregation in HydroShare using the updated rasterio.DatasetReader object # we will first create a new folder in which the new aggregation will be created aggr_folder = \"gr_folder\" resource.folder_create(folder=aggr_folder) # this operation may take a while gr_aggr = gr_aggr.save_data_object(resource=resource, agg_path=output_raster_dir_path, as_new_aggr=True, destination_path=aggr_folder) print(\"New aggregation created ...\") # retrieve the updated georaster aggregation to verify the data was updated # need to first download this updated/new aggregation download_to = os.path.join(base_working_dir, \"georaster_testing\") # note the unzip_to directory must exist and be empty unzip_to = os.path.join(download_to, \"aggr_unzipped\") aggr_path = resource.aggregation_download(aggregation=gr_aggr, save_path=download_to, unzip_to=unzip_to) rasterio_ds = gr_aggr.as_data_object(agg_path=aggr_path) # check the raster dimensions of the updated aggregation print(\"raster dimensions after editing:\") print(f\"raster width :{rasterio_ds.width}\") print(f\"raster height:{rasterio_ds.height}\")","title":"Loading Geo Raster Data to rasterio.DatasetReader"},{"location":"examples/Aggregation_Data_Object_Operations/#loading-csv-data-to-pandasdataframe","text":"Here we are assuming the CSV aggregation contains a CSV file with name \"sample.csv\" # retrieve the CSV aggregation file_path = \"sample.csv\" csv_aggr = resource.aggregation(file__path=file_path) # show the aggregation type print(f\"Aggregation Type:{csv_aggr.metadata.type}\") # download the CSV aggregation - these directory paths must exist for hsclient to download and unzip the aggregation zip file # Note: These directory paths need to be changed based on where you want to download the aggregation download_to = os.path.join(base_working_dir, \"csv_testing\") unzip_to = os.path.join(download_to, \"aggr_unzipped\") aggr_path = resource.aggregation_download(aggregation=csv_aggr, save_path=download_to, unzip_to=unzip_to) print(f\"Downloaded aggregation to:{aggr_path}\") # load the CSV aggregation as pandas.DataFrame csv_df = csv_aggr.as_data_object(agg_path=aggr_path) # show number of rows and columns print(f\"Number of data rows:{len(csv_df)}\") print(f\"Number of data columns:{len(csv_df.columns)}\") # show the first 5 data rows print(csv_df.head(5)) # show the extracted CSV aggregation metadata (table schema) table_schema = csv_aggr.metadata.tableSchema table = table_schema.table print(f\"Number of data rows:{table_schema.rows}\") print(f\"Number of data columns:{len(table.columns)}\") print(f\"Delimiter:{table_schema.delimiter}\") # show data column properties for col in table.columns: print(f\"Column number:{col.column_number}\") print(f\"Column title:{col.title}\") print(f\"Column description:{col.description}\") print(f\"Column data type:{col.datatype}\") print(\"-\"*50) Editing CSV aggregation using pandas.DataFrame # drop the last data column - note all editing needs to be in 'inplace' mode csv_df.drop(csv_df.columns[-1], axis=1, inplace=True) # show the number of data columns after the edit print(f\"Number of data columns after edit:{len(csv_df.columns)}\") # save the updated CSV aggregation in Hydroshare # Note this will overwrite the original aggregation - this operation may take a while csv_aggr = csv_aggr.save_data_object(resource=resource, agg_path=aggr_path, as_new_aggr=False) print(\"Aggregation updated ...\") # we can also create a new CSV aggregation in HydroShare using the updated pandas.DataFrame object # we first create a new folder in which the new aggregation will be created aggr_folder = \"csv_folder\" resource.folder_create(folder=aggr_folder) # this operation may take a while csv_aggr = csv_aggr.save_data_object(resource=resource, agg_path=aggr_path, as_new_aggr=True, destination_path=aggr_folder) print(\"New CSV aggregation was created ...\") # retrieve the updated CSV aggregation to verify the data got updated download_to = os.path.join(base_working_dir, \"csv_testing\") # note the unzip_to directory must exist and be empty unzip_to = os.path.join(download_to, \"aggr_unzipped\") aggr_path = resource.aggregation_download(aggregation=csv_aggr, save_path=download_to, unzip_to=unzip_to) csv_df = csv_aggr.as_data_object(agg_path=aggr_path) # show the number of data rows and columns print(f\"Number of data rows:{len(csv_df)}\") print(f\"Number of data columns:{len(csv_df.columns)}\") # show the first 5 data rows print(csv_df.head(5))","title":"Loading CSV Data to pandas.DataFrame"},{"location":"examples/Aggregation_Operations/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); hsclient HydroShare Python Client Resource Aggregation Operation Examples The following code snippets show examples for how to use the hsclient HydroShare Python Client to manipulate aggregations of known content types in HydroShare. HydroShare's content type aggregations include individual file, fileset, time series, geographic feature, geographic raster, and multidimensional NetCDF. Install the hsclient Python Client The hsclient Python Client for HydroShare may not be installed by default in your Python environment, so it has to be installed first before you can work with it. Use the following command to install hsclient via the Python Package Index (PyPi). !pip install hsclient Authenticating with HydroShare Before you start interacting with resources in HydroShare you will need to authenticate. from hsclient import HydroShare hs = HydroShare() hs.sign_in() Create a New Empty Resource A \"resource\" is a container for your content in HydroShare. Think of it as a \"working directory\" into which you are going to organize the code and/or data you are using and want to share. The following code can be used to create a new, empty resource within which you can create content and metadata. This code creates a new resource in HydroShare. It also creates an in-memory object representation of that resource in your local environment that you can then manipulate with further code. # Create the new, empty resource new_resource = hs.create() # Get the HydroShare identifier for the new resource res_identifier = new_resource.resource_id print(f'The HydroShare Identifier for your new resource is: {res_identifier}') # Construct a hyperlink for the new resource print(f'Your new resource is available at: {new_resource.metadata.url}') The HydroShare Identifier for your new resource is: 570ff33346fc4a849a134c558bb8dcab Your new resource is available at: http://localhost:8000/resource/570ff33346fc4a849a134c558bb8dcab Resource Aggregation Handling HydroShare allows you to create and manage aggregations of content files within resources that have specific types and associated metadata. These known content types include: Time series Geographic feature Geographic raster Multidimensional NetCDF Single file File set CSV The general process for creating an aggregation within a resource requires adding files to the resource and then applying the appropriate aggregation type. For some of the aggregation types, some of the aggregation metadata fields will be automatically extracted from the files you upload. You can then set the values of the other aggregation-level metadata elements. Create a Single File Aggregation A single file aggregation in a HydroShare is any individual file to which you want to add extra metadata. # Import the aggregation types from hsmodels.schemas.enums import AggregationType # Upload a single content file to the resource. This is a generic text file. new_resource.file_upload('Example_Files/Data_File1.txt') # Specify the file you want to add the aggregation to file = new_resource.file(path='Data_File1.txt') # Create a single file aggregation on the file and refresh the resource agg = new_resource.file_aggregate(file, AggregationType.SingleFileAggregation) # Print the title for the aggregation that was added to the resource print(f'The following aggregation was added to the resource: {agg.metadata.title}') print(f'Aggregation type: {agg.metadata.type}') The following aggregation was added to the resource: Data_File1 Aggregation type: Generic Add Metadata to the Aggregation Once you have created an aggregation, you can edit and add metadata elements. For a single file aggregation, you can add a title, subject keywords, extended metadata as key-value pairs, and spatial and temporal coverage. All of the metadata edits are stored locally until you call the save() function on the aggregation to write the edits you have made to HydroShare. Title and Keywords The title of an aggregation is a string. Subject keywords are handled as a list of strings. # Set the title and subject keywords for the aggregation agg.metadata.title = 'A Single File Aggregation' agg.metadata.subjects = ['Aggregation', 'Single File', 'Text'] # Print the title and keywords for the aggregation print(f'Aggregation Title: {agg.metadata.title}') print(f'Aggregation Keywords: {\", \".join(agg.metadata.subjects)}') # Save the aggregation to write the metadata to HydroShare agg.save() Extended Metadata Elements Extended metadata elements for an aggregation are handled using a Python dictionary. You can add new elements using key-value pairs. # Add an extended metadata element to the aggregation as a key-value pair agg.metadata.additional_metadata['New Element Key'] = 'Text value of new element.' # Remove an individual key-value pair from the aggregation using its key del agg.metadata.additional_metadata['New Element Key'] # Or, you can clear out all extended metadata elements that might exist agg.metadata.additional_metadata.clear() # Add multiple key-value pairs to the aggregation at once using a Python dictionary agg.metadata.additional_metadata = { 'Observed Variable': 'Water use', 'Site Location': 'Valley View Tower Dormitory on Utah State University\\'s Campus in Logan, UT' } # Print the extended metadata elements print('The extended metadata elements for the aggregation include:') for key, value in agg.metadata.additional_metadata.items(): print(key + ':', value) # Save the aggregation to write the metadata to HydroShare agg.save() Spatial and Temporal Coverage Spatial and temporal coverage for an aggregation are handled in the same way they are handled for resource level metadata. Initially the spatial and temporal coverage for an aggregation are empty. To set them, you have to create a coverage object of the right type and set the spatial or temporal coverage to that object. # Import the required metadata classes for coverage objects from hsmodels.schemas.fields import BoxCoverage, PointCoverage, PeriodCoverage from datetime import datetime # Set the spatial coverage of the aggregation to a BoxCoverage object agg.metadata.spatial_coverage = BoxCoverage(name='Logan, Utah', northlimit=41.7910, eastlimit=-111.7664, southlimit=41.6732, westlimit=-111.9079, projection='WGS 84 EPSG:4326', type='box', units='Decimal degrees') # You can remove the spatial coverage element by setting it to None agg.metadata.spatial_coverage = None # If you want to set the spatial coverage to a PointCoverage instead agg.metadata.spatial_coverage = PointCoverage(name='Logan, Utah', north=41.7371, east=-111.8351, projection='WGS 84 EPSG:4326', type='point', units='Decimal degrees') # Create a beginning and ending date for a time period beginDate = datetime.strptime('2020-12-01T00:00:00Z', '%Y-%m-%dT%H:%M:%S%fZ') endDate = datetime.strptime('2020-12-31T00:00:00Z', '%Y-%m-%dT%H:%M:%S%fZ') # Set the temporal coverage of the aggregation to a PeriodCoverage object agg.metadata.period_coverage = PeriodCoverage(start=beginDate, end=endDate) # Print the temporal coverage information print('Temporal Coverage:') print(agg.metadata.period_coverage) # Print the spatial coverage information print('\\nSpatial Coverage:') print(agg.metadata.spatial_coverage) # Save the aggregation to write the metadata to HydroShare agg.save() Creating Other Aggregation Types Geographic Feature Aggregation Geographic feature aggregations are created in HydroShare from the set of files that make up an ESRI Shapefile. You need to upload the shapefile and then HydroShare will automatically set the aggregation on the set of files you upload. You can then retrieve the aggregation using its title or by searching for one of the files it contains. # Create a list of the files that make up the shapefile to be uploaded file_list = ['Example_Files/watersheds.cpg', 'Example_Files/watersheds.dbf', 'Example_Files/watersheds.prj', 'Example_Files/watersheds.sbn', 'Example_Files/watersheds.sbx', 'Example_Files/watersheds.shp', 'Example_Files/watersheds.shx', 'Example_Files/watersheds.shp.xml'] # Upload the files to the resource all at the same time new_resource.file_upload(*file_list) print('Files uploaded!') If you upload all of the files of a shapefile together as shown above, HydroShare automatically recognizes the files as a shapefile and auto-aggregates the files into a geographic feature aggregation for you. So, you then just need to get the aggregation that was created if you want to further operate on it - e.g., to modify the aggregation-level metadata. Metadata for a geographic feature aggregation includes a title, subject keywords, extended key-value pairs, temporal coverage, spatial coverage, geometry information, spatial reference, and attribute field information. When HydroShare creates the aggregation on the shapefile, the spatial coverage, geometry information, spatial reference, and attribute field information metadata will be automatically set for you. You can then set all of the other metadata elements as shown above for the single file aggregation if you need to. # Get the aggregation that was just created # You can get the aggregation by searching for a file that is inside of it agg = new_resource.aggregation(file__name='watersheds.shp') # Or, you can get the aggregation by searching for its title, which is initially # set to the name of the shapefile agg = new_resource.aggregation(title='watersheds') # Print the title for the aggregation that was added to the resource print(f'The following aggregation was added to the resource: {agg.metadata.title}') print(f'Aggregation type: {agg.metadata.type}') Geographic Raster Aggregation Geographic raster aggregations are created in HydroShare from one or more raster data files that make up a raster dataset. HydroShare uses GeoTiff files for raster datasets. Like the geographic feature aggregation, when you upload all of the files for a geographic raster dataset (all .tif and a .vrt file) at once, HydroShare will automatically create the aggregation for you. You can then get the aggregation and set the other metadata elements as shown above for the single file aggregation. HydroShare initially sets the title of the geographic raster aggregation to the first .tif file that appears in the .vrt file. The spatial coverage, spatial reference, and cell information are set automatically based on information extracted from the dataset. # Upload the files making up the raster dataset to the resource file_list = ['Example_Files/logan1.tif', 'Example_Files/logan2.tif', 'Example_Files/logan.vrt'] new_resource.file_upload(*file_list) # Get the aggregation that was just created - initially the title will be \"logan1\" # based on the name of the first .tif file that appears in the .vrt file agg = new_resource.aggregation(title='logan1') # Print the title for the aggregation that was added to the resource print(f'The following aggregation was added to the resource: {agg.metadata.title}') print(f'Aggregation type: {agg.metadata.type}') Multidimensional NetCDF Aggregation Multidimensional aggregations are created in HydroShare from a NetCDF file. Like the other aggregation types, you can upload the NetCDF file and HydroShare will automatically create the aggregation for you. HydroShare also automatically extracts metadata from the NetCDF file to populate the aggregation metadata. Some of this metadata may get propagated to the resource level if you haven't set things like the title and keywords. You can then get the aggregation and set the other metadata elements as shown above for the single file aggregation. # Upload the NetCDF file to the resource new_resource.file_upload('Example_Files/SWE_time.nc') # Get the aggregation by searching for the NetCDF file that is inside of it agg = new_resource.aggregation(file__name='SWE_time.nc') # Print the title for the aggregation that was added to the resource print(f'The following aggregation was added to the resource: {agg.metadata.title}') print(f'Aggregation type: {agg.metadata.type}') Time Series Aggregation Time series aggregations are created in HydroShare from an ODM2 SQLite database file. The ODM2 SQLite database contain one or more time series # Upload the SQLite file to the resource new_resource.file_upload('Example_Files/ODM2.sqlite') # Get the aggregation by searching for the SQLite file that is inside of it agg = new_resource.aggregation(file__name='ODM2.sqlite') # Print the title for the aggregation that was added to the resource print(f'The following aggregation was added to the resource: {agg.metadata.title}') print(f'Aggregation type: {agg.metadata.type}') File Set Aggregation A file set aggregation is any folder within a resource to which you want to add metadata. If you want to create a file set aggregation, you first have to create a folder, then upload files to it. After that, you can set the aggregation on the folder. # Create a new folder for the file set aggregation new_resource.folder_create('Fileset_Aggregation') # Add some files to the folder new_resource.file_upload('Example_Files/Data_File1.txt', 'Example_Files/Data_File2.txt', destination_path='Fileset_Aggregation') # set the folder to fileset aggregation new_resource.file_aggregate(path='Fileset_Aggregation', agg_type=AggregationType.FileSetAggregation) fs_agg = new_resource.aggregation(type='FileSet') print(f\"Aggregation Type: {fs_agg.metadata.type}\") Aggregation Type: FileSet CSV Aggregation CSV aggregations are created in HydroShare from a CSV file. When you upload a csv file, HydroShare automatically creates a CSV aggregation and extracts metadata from the uploaded CSV file. # Upload a CSV file to the resource new_resource.file_upload('Example_Files/Data_File1.csv') # Get the aggregation by searching for the CSV file agg = new_resource.aggregation(file__name='Data_File1.csv') # Print the title for the aggregation that was added to the resource print(f\"The following aggregation was added to the resource: {agg.metadata.title}\") print(f\"Aggregation type: {agg.metadata.type}\") Get Aggregation Properties Each aggregation in a resource has metadata properties associated with it. You can query/retrieve those properties for display. The following shows an example for the time series aggregation that was created above. # Get the time series aggregation that was created above agg = new_resource.aggregation(type='TimeSeries') # Print the metadata associated with the aggregation print(f'Aggregation Title: {agg.metadata.title}') print(f'Aggregation Type: {agg.metadata.type}') print(f'Aggregation Keywords: {\", \".join(agg.metadata.subjects)}') print(f'Aggregation Temporal Coverage: {agg.metadata.period_coverage}') print(f'Aggregation Spatial Coverage: {agg.metadata.spatial_coverage}') # Print the list of files in the aggregation file_list = agg.files() print('List of files contained within the aggregation:') print(*file_list, sep='\\n') Example of editing extracted metadata for CSV aggregation # Get the CSV aggregation you created above agg = new_resource.aggregation(type=\"CSV\") # we can edit any extracted column properties (like 'title', 'description', 'datatype') table = agg.metadata.tableSchema.table # here is an example of editing the 'title' property of the 1st column table.columns[0].title = \"Date of Observation\" # here is an example of editing the 'description' of the 7th column table.columns[6].description = \"Total Volume over time\" # save the updated metadata agg.save() Searching for Aggregations within a Resource If you need to find/get one or more aggregations within a resource so you can download or remove it from the resource, there are several filters available that allow you to return a list of aggregations that meet your search criteria. # Get the list of all aggregations in the resource aggregations = new_resource.aggregations() # Get a list of all aggregations of a particular type aggregations = new_resource.aggregations(type=\"TimeSeries\") # Get a list of aggregations with extended metadata searching by key aggregations = new_resource.aggregations(additional_metadata__key=\"Observed Variable\") # Get a list of aggregations with extended metadata searching by value aggregations = new_resource.aggregations(additional_metadata__value=\"Water Use\") # Get a list of aggregations with a subject keyword searching by value aggregations = new_resource.aggregations(subjects__contains=\"Temperature\") # Get a list of aggregations searching by title (or any metadata attribute) aggregations = new_resource.aggregations(title=\"watersheds\") # Get a list of aggregations searching by a nested metadata attribute (__) aggregations = new_resource.aggregations(period_coverage__name=\"period_coverage name\") # Get a list of aggregations by combining field searching, filtered with \"AND\" aggregations = new_resource.aggregations(period_coverage__name=\"period_coverage name\", title=\"watersheds\") You can also search for individual aggregations within a resource. # Search for an aggregation of type time series aggregation = new_resource.aggregation(type=\"TimeSeries\") # Search for an aggregation with a specific title aggregation = new_resource.aggregation(title=\"watersheds\") # Search for an aggregation that contains a particular file name aggregation = new_resource.aggregation(file__name=\"ODM2.sqlite\") Downloading an Aggregation When working with a resource, you may want to download one of the aggregations contained within the resource. If you want to download it to a particular location on your disk, you can pass a path to the location where you want the aggregation to be saved to the download() function as a string. Aggregations are downloaded as a zipped file containing the aggregation content and metadata files. # Get the geographic feature aggregation that was created above agg = new_resource.aggregation(title=\"watersheds\") # Download the aggregation new_resource.aggregation_download(agg) Clean up the zippled aggregation file that was just downloaded. !rm 'watersheds.shp.zip' Remove and Delete an Aggregation You may wish to remove an aggregation from a resource. There are two functions you can use to do this. The difference between the two is whether the aggregation's content files are preserved in the resource or deleted. To remove the aggregation-specific metadata and associations while maintaining the content files, call the remove() function on the aggregation. # Get the geographic raster aggregation that was created above agg = new_resource.aggregation(title=\"logan1\") # Remove the aggregation and delete its metadata, but leave the file(s) new_resource.aggregation_remove(agg) If you want to delete the aggregation, including its metadata and the associated content files, you can call the delete() function on the aggregation. Once you have called the remove() function on an aggregation, the delete() function will no longer work and you will have to delete the files individually. # Get the multidimensional NetCDF aggregation that was created above agg = new_resource.aggregation(type=\"NetCDF\") # Delete the aggregation and metadata along with files within aggregation new_resource.aggregation_delete(agg)","title":"Aggregation Operations"},{"location":"examples/Aggregation_Operations/#hsclient-hydroshare-python-client-resource-aggregation-operation-examples","text":"The following code snippets show examples for how to use the hsclient HydroShare Python Client to manipulate aggregations of known content types in HydroShare. HydroShare's content type aggregations include individual file, fileset, time series, geographic feature, geographic raster, and multidimensional NetCDF.","title":"hsclient HydroShare Python Client Resource Aggregation Operation Examples"},{"location":"examples/Aggregation_Operations/#install-the-hsclient-python-client","text":"The hsclient Python Client for HydroShare may not be installed by default in your Python environment, so it has to be installed first before you can work with it. Use the following command to install hsclient via the Python Package Index (PyPi). !pip install hsclient","title":"Install the hsclient Python Client"},{"location":"examples/Aggregation_Operations/#authenticating-with-hydroshare","text":"Before you start interacting with resources in HydroShare you will need to authenticate. from hsclient import HydroShare hs = HydroShare() hs.sign_in()","title":"Authenticating with HydroShare"},{"location":"examples/Aggregation_Operations/#create-a-new-empty-resource","text":"A \"resource\" is a container for your content in HydroShare. Think of it as a \"working directory\" into which you are going to organize the code and/or data you are using and want to share. The following code can be used to create a new, empty resource within which you can create content and metadata. This code creates a new resource in HydroShare. It also creates an in-memory object representation of that resource in your local environment that you can then manipulate with further code. # Create the new, empty resource new_resource = hs.create() # Get the HydroShare identifier for the new resource res_identifier = new_resource.resource_id print(f'The HydroShare Identifier for your new resource is: {res_identifier}') # Construct a hyperlink for the new resource print(f'Your new resource is available at: {new_resource.metadata.url}') The HydroShare Identifier for your new resource is: 570ff33346fc4a849a134c558bb8dcab Your new resource is available at: http://localhost:8000/resource/570ff33346fc4a849a134c558bb8dcab","title":"Create a New Empty Resource"},{"location":"examples/Aggregation_Operations/#resource-aggregation-handling","text":"HydroShare allows you to create and manage aggregations of content files within resources that have specific types and associated metadata. These known content types include: Time series Geographic feature Geographic raster Multidimensional NetCDF Single file File set CSV The general process for creating an aggregation within a resource requires adding files to the resource and then applying the appropriate aggregation type. For some of the aggregation types, some of the aggregation metadata fields will be automatically extracted from the files you upload. You can then set the values of the other aggregation-level metadata elements.","title":"Resource Aggregation Handling"},{"location":"examples/Aggregation_Operations/#create-a-single-file-aggregation","text":"A single file aggregation in a HydroShare is any individual file to which you want to add extra metadata. # Import the aggregation types from hsmodels.schemas.enums import AggregationType # Upload a single content file to the resource. This is a generic text file. new_resource.file_upload('Example_Files/Data_File1.txt') # Specify the file you want to add the aggregation to file = new_resource.file(path='Data_File1.txt') # Create a single file aggregation on the file and refresh the resource agg = new_resource.file_aggregate(file, AggregationType.SingleFileAggregation) # Print the title for the aggregation that was added to the resource print(f'The following aggregation was added to the resource: {agg.metadata.title}') print(f'Aggregation type: {agg.metadata.type}') The following aggregation was added to the resource: Data_File1 Aggregation type: Generic","title":"Create a Single File Aggregation"},{"location":"examples/Aggregation_Operations/#add-metadata-to-the-aggregation","text":"Once you have created an aggregation, you can edit and add metadata elements. For a single file aggregation, you can add a title, subject keywords, extended metadata as key-value pairs, and spatial and temporal coverage. All of the metadata edits are stored locally until you call the save() function on the aggregation to write the edits you have made to HydroShare.","title":"Add Metadata to the Aggregation"},{"location":"examples/Aggregation_Operations/#title-and-keywords","text":"The title of an aggregation is a string. Subject keywords are handled as a list of strings. # Set the title and subject keywords for the aggregation agg.metadata.title = 'A Single File Aggregation' agg.metadata.subjects = ['Aggregation', 'Single File', 'Text'] # Print the title and keywords for the aggregation print(f'Aggregation Title: {agg.metadata.title}') print(f'Aggregation Keywords: {\", \".join(agg.metadata.subjects)}') # Save the aggregation to write the metadata to HydroShare agg.save()","title":"Title and Keywords"},{"location":"examples/Aggregation_Operations/#extended-metadata-elements","text":"Extended metadata elements for an aggregation are handled using a Python dictionary. You can add new elements using key-value pairs. # Add an extended metadata element to the aggregation as a key-value pair agg.metadata.additional_metadata['New Element Key'] = 'Text value of new element.' # Remove an individual key-value pair from the aggregation using its key del agg.metadata.additional_metadata['New Element Key'] # Or, you can clear out all extended metadata elements that might exist agg.metadata.additional_metadata.clear() # Add multiple key-value pairs to the aggregation at once using a Python dictionary agg.metadata.additional_metadata = { 'Observed Variable': 'Water use', 'Site Location': 'Valley View Tower Dormitory on Utah State University\\'s Campus in Logan, UT' } # Print the extended metadata elements print('The extended metadata elements for the aggregation include:') for key, value in agg.metadata.additional_metadata.items(): print(key + ':', value) # Save the aggregation to write the metadata to HydroShare agg.save()","title":"Extended Metadata Elements"},{"location":"examples/Aggregation_Operations/#spatial-and-temporal-coverage","text":"Spatial and temporal coverage for an aggregation are handled in the same way they are handled for resource level metadata. Initially the spatial and temporal coverage for an aggregation are empty. To set them, you have to create a coverage object of the right type and set the spatial or temporal coverage to that object. # Import the required metadata classes for coverage objects from hsmodels.schemas.fields import BoxCoverage, PointCoverage, PeriodCoverage from datetime import datetime # Set the spatial coverage of the aggregation to a BoxCoverage object agg.metadata.spatial_coverage = BoxCoverage(name='Logan, Utah', northlimit=41.7910, eastlimit=-111.7664, southlimit=41.6732, westlimit=-111.9079, projection='WGS 84 EPSG:4326', type='box', units='Decimal degrees') # You can remove the spatial coverage element by setting it to None agg.metadata.spatial_coverage = None # If you want to set the spatial coverage to a PointCoverage instead agg.metadata.spatial_coverage = PointCoverage(name='Logan, Utah', north=41.7371, east=-111.8351, projection='WGS 84 EPSG:4326', type='point', units='Decimal degrees') # Create a beginning and ending date for a time period beginDate = datetime.strptime('2020-12-01T00:00:00Z', '%Y-%m-%dT%H:%M:%S%fZ') endDate = datetime.strptime('2020-12-31T00:00:00Z', '%Y-%m-%dT%H:%M:%S%fZ') # Set the temporal coverage of the aggregation to a PeriodCoverage object agg.metadata.period_coverage = PeriodCoverage(start=beginDate, end=endDate) # Print the temporal coverage information print('Temporal Coverage:') print(agg.metadata.period_coverage) # Print the spatial coverage information print('\\nSpatial Coverage:') print(agg.metadata.spatial_coverage) # Save the aggregation to write the metadata to HydroShare agg.save()","title":"Spatial and Temporal Coverage"},{"location":"examples/Aggregation_Operations/#creating-other-aggregation-types","text":"","title":"Creating Other Aggregation Types"},{"location":"examples/Aggregation_Operations/#geographic-feature-aggregation","text":"Geographic feature aggregations are created in HydroShare from the set of files that make up an ESRI Shapefile. You need to upload the shapefile and then HydroShare will automatically set the aggregation on the set of files you upload. You can then retrieve the aggregation using its title or by searching for one of the files it contains. # Create a list of the files that make up the shapefile to be uploaded file_list = ['Example_Files/watersheds.cpg', 'Example_Files/watersheds.dbf', 'Example_Files/watersheds.prj', 'Example_Files/watersheds.sbn', 'Example_Files/watersheds.sbx', 'Example_Files/watersheds.shp', 'Example_Files/watersheds.shx', 'Example_Files/watersheds.shp.xml'] # Upload the files to the resource all at the same time new_resource.file_upload(*file_list) print('Files uploaded!') If you upload all of the files of a shapefile together as shown above, HydroShare automatically recognizes the files as a shapefile and auto-aggregates the files into a geographic feature aggregation for you. So, you then just need to get the aggregation that was created if you want to further operate on it - e.g., to modify the aggregation-level metadata. Metadata for a geographic feature aggregation includes a title, subject keywords, extended key-value pairs, temporal coverage, spatial coverage, geometry information, spatial reference, and attribute field information. When HydroShare creates the aggregation on the shapefile, the spatial coverage, geometry information, spatial reference, and attribute field information metadata will be automatically set for you. You can then set all of the other metadata elements as shown above for the single file aggregation if you need to. # Get the aggregation that was just created # You can get the aggregation by searching for a file that is inside of it agg = new_resource.aggregation(file__name='watersheds.shp') # Or, you can get the aggregation by searching for its title, which is initially # set to the name of the shapefile agg = new_resource.aggregation(title='watersheds') # Print the title for the aggregation that was added to the resource print(f'The following aggregation was added to the resource: {agg.metadata.title}') print(f'Aggregation type: {agg.metadata.type}')","title":"Geographic Feature Aggregation"},{"location":"examples/Aggregation_Operations/#geographic-raster-aggregation","text":"Geographic raster aggregations are created in HydroShare from one or more raster data files that make up a raster dataset. HydroShare uses GeoTiff files for raster datasets. Like the geographic feature aggregation, when you upload all of the files for a geographic raster dataset (all .tif and a .vrt file) at once, HydroShare will automatically create the aggregation for you. You can then get the aggregation and set the other metadata elements as shown above for the single file aggregation. HydroShare initially sets the title of the geographic raster aggregation to the first .tif file that appears in the .vrt file. The spatial coverage, spatial reference, and cell information are set automatically based on information extracted from the dataset. # Upload the files making up the raster dataset to the resource file_list = ['Example_Files/logan1.tif', 'Example_Files/logan2.tif', 'Example_Files/logan.vrt'] new_resource.file_upload(*file_list) # Get the aggregation that was just created - initially the title will be \"logan1\" # based on the name of the first .tif file that appears in the .vrt file agg = new_resource.aggregation(title='logan1') # Print the title for the aggregation that was added to the resource print(f'The following aggregation was added to the resource: {agg.metadata.title}') print(f'Aggregation type: {agg.metadata.type}')","title":"Geographic Raster Aggregation"},{"location":"examples/Aggregation_Operations/#multidimensional-netcdf-aggregation","text":"Multidimensional aggregations are created in HydroShare from a NetCDF file. Like the other aggregation types, you can upload the NetCDF file and HydroShare will automatically create the aggregation for you. HydroShare also automatically extracts metadata from the NetCDF file to populate the aggregation metadata. Some of this metadata may get propagated to the resource level if you haven't set things like the title and keywords. You can then get the aggregation and set the other metadata elements as shown above for the single file aggregation. # Upload the NetCDF file to the resource new_resource.file_upload('Example_Files/SWE_time.nc') # Get the aggregation by searching for the NetCDF file that is inside of it agg = new_resource.aggregation(file__name='SWE_time.nc') # Print the title for the aggregation that was added to the resource print(f'The following aggregation was added to the resource: {agg.metadata.title}') print(f'Aggregation type: {agg.metadata.type}')","title":"Multidimensional NetCDF Aggregation"},{"location":"examples/Aggregation_Operations/#time-series-aggregation","text":"Time series aggregations are created in HydroShare from an ODM2 SQLite database file. The ODM2 SQLite database contain one or more time series # Upload the SQLite file to the resource new_resource.file_upload('Example_Files/ODM2.sqlite') # Get the aggregation by searching for the SQLite file that is inside of it agg = new_resource.aggregation(file__name='ODM2.sqlite') # Print the title for the aggregation that was added to the resource print(f'The following aggregation was added to the resource: {agg.metadata.title}') print(f'Aggregation type: {agg.metadata.type}')","title":"Time Series Aggregation"},{"location":"examples/Aggregation_Operations/#file-set-aggregation","text":"A file set aggregation is any folder within a resource to which you want to add metadata. If you want to create a file set aggregation, you first have to create a folder, then upload files to it. After that, you can set the aggregation on the folder. # Create a new folder for the file set aggregation new_resource.folder_create('Fileset_Aggregation') # Add some files to the folder new_resource.file_upload('Example_Files/Data_File1.txt', 'Example_Files/Data_File2.txt', destination_path='Fileset_Aggregation') # set the folder to fileset aggregation new_resource.file_aggregate(path='Fileset_Aggregation', agg_type=AggregationType.FileSetAggregation) fs_agg = new_resource.aggregation(type='FileSet') print(f\"Aggregation Type: {fs_agg.metadata.type}\") Aggregation Type: FileSet","title":"File Set Aggregation"},{"location":"examples/Aggregation_Operations/#csv-aggregation","text":"CSV aggregations are created in HydroShare from a CSV file. When you upload a csv file, HydroShare automatically creates a CSV aggregation and extracts metadata from the uploaded CSV file. # Upload a CSV file to the resource new_resource.file_upload('Example_Files/Data_File1.csv') # Get the aggregation by searching for the CSV file agg = new_resource.aggregation(file__name='Data_File1.csv') # Print the title for the aggregation that was added to the resource print(f\"The following aggregation was added to the resource: {agg.metadata.title}\") print(f\"Aggregation type: {agg.metadata.type}\")","title":"CSV Aggregation"},{"location":"examples/Aggregation_Operations/#get-aggregation-properties","text":"Each aggregation in a resource has metadata properties associated with it. You can query/retrieve those properties for display. The following shows an example for the time series aggregation that was created above. # Get the time series aggregation that was created above agg = new_resource.aggregation(type='TimeSeries') # Print the metadata associated with the aggregation print(f'Aggregation Title: {agg.metadata.title}') print(f'Aggregation Type: {agg.metadata.type}') print(f'Aggregation Keywords: {\", \".join(agg.metadata.subjects)}') print(f'Aggregation Temporal Coverage: {agg.metadata.period_coverage}') print(f'Aggregation Spatial Coverage: {agg.metadata.spatial_coverage}') # Print the list of files in the aggregation file_list = agg.files() print('List of files contained within the aggregation:') print(*file_list, sep='\\n') Example of editing extracted metadata for CSV aggregation # Get the CSV aggregation you created above agg = new_resource.aggregation(type=\"CSV\") # we can edit any extracted column properties (like 'title', 'description', 'datatype') table = agg.metadata.tableSchema.table # here is an example of editing the 'title' property of the 1st column table.columns[0].title = \"Date of Observation\" # here is an example of editing the 'description' of the 7th column table.columns[6].description = \"Total Volume over time\" # save the updated metadata agg.save()","title":"Get Aggregation Properties"},{"location":"examples/Aggregation_Operations/#searching-for-aggregations-within-a-resource","text":"If you need to find/get one or more aggregations within a resource so you can download or remove it from the resource, there are several filters available that allow you to return a list of aggregations that meet your search criteria. # Get the list of all aggregations in the resource aggregations = new_resource.aggregations() # Get a list of all aggregations of a particular type aggregations = new_resource.aggregations(type=\"TimeSeries\") # Get a list of aggregations with extended metadata searching by key aggregations = new_resource.aggregations(additional_metadata__key=\"Observed Variable\") # Get a list of aggregations with extended metadata searching by value aggregations = new_resource.aggregations(additional_metadata__value=\"Water Use\") # Get a list of aggregations with a subject keyword searching by value aggregations = new_resource.aggregations(subjects__contains=\"Temperature\") # Get a list of aggregations searching by title (or any metadata attribute) aggregations = new_resource.aggregations(title=\"watersheds\") # Get a list of aggregations searching by a nested metadata attribute (__) aggregations = new_resource.aggregations(period_coverage__name=\"period_coverage name\") # Get a list of aggregations by combining field searching, filtered with \"AND\" aggregations = new_resource.aggregations(period_coverage__name=\"period_coverage name\", title=\"watersheds\") You can also search for individual aggregations within a resource. # Search for an aggregation of type time series aggregation = new_resource.aggregation(type=\"TimeSeries\") # Search for an aggregation with a specific title aggregation = new_resource.aggregation(title=\"watersheds\") # Search for an aggregation that contains a particular file name aggregation = new_resource.aggregation(file__name=\"ODM2.sqlite\")","title":"Searching for Aggregations within a Resource"},{"location":"examples/Aggregation_Operations/#downloading-an-aggregation","text":"When working with a resource, you may want to download one of the aggregations contained within the resource. If you want to download it to a particular location on your disk, you can pass a path to the location where you want the aggregation to be saved to the download() function as a string. Aggregations are downloaded as a zipped file containing the aggregation content and metadata files. # Get the geographic feature aggregation that was created above agg = new_resource.aggregation(title=\"watersheds\") # Download the aggregation new_resource.aggregation_download(agg) Clean up the zippled aggregation file that was just downloaded. !rm 'watersheds.shp.zip'","title":"Downloading an Aggregation"},{"location":"examples/Aggregation_Operations/#remove-and-delete-an-aggregation","text":"You may wish to remove an aggregation from a resource. There are two functions you can use to do this. The difference between the two is whether the aggregation's content files are preserved in the resource or deleted. To remove the aggregation-specific metadata and associations while maintaining the content files, call the remove() function on the aggregation. # Get the geographic raster aggregation that was created above agg = new_resource.aggregation(title=\"logan1\") # Remove the aggregation and delete its metadata, but leave the file(s) new_resource.aggregation_remove(agg) If you want to delete the aggregation, including its metadata and the associated content files, you can call the delete() function on the aggregation. Once you have called the remove() function on an aggregation, the delete() function will no longer work and you will have to delete the files individually. # Get the multidimensional NetCDF aggregation that was created above agg = new_resource.aggregation(type=\"NetCDF\") # Delete the aggregation and metadata along with files within aggregation new_resource.aggregation_delete(agg)","title":"Remove and Delete an Aggregation"},{"location":"examples/Basic_Operations/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); hsclient HydroShare Python Client Basic Resource Operation Examples The following code snippets show examples for how to use the hsclient HydroShare Python Client for performing basic resource operations. Install the hsclient Python Client The hsclient Python Client for HydroShare may not be installed by default in your Python environment, so it has to be installed first before you can work with it. Use the following command to install hsclient via the Python Package Index (PyPi). !pip install hsclient Authenticating with HydroShare Before you start interacting with resources in HydroShare you will need to authenticate. To authenticate with HydroShare, you can either specify your username and password or you can call the sign_in() function, which will prompt you to input your username and password. from hsclient import HydroShare username = 'username' password = 'password' hs = HydroShare(username, password) In most cases you will not want anyone to see your username and password, so you can also call the sign_in() function to be prompted for your username and password. This is better to use if you are sharing a Jupyter Notebook. from hsclient import HydroShare hs = HydroShare() hs.sign_in() Basic Resource Operations Create a New Empty Resource A \"resource\" is a container for your content in HydroShare. Think of it as a \"working directory\" into which you are going to organize the code and/or data you are using and want to share. The following code can be used to create a new, empty resource within which you can create content and metadata. This code creates a new resource in HydroShare. It also creates an in-memory object representation of that resource in your local environmment that you can then manipulate with further code. # Create the new, empty resource new_resource = hs.create() # Get the HydroShare identifier for the new resource res_identifier = new_resource.resource_id print(f'The HydroShare Identifier for your new resources is: {res_identifier}') # Construct a hyperlink to access the HydroShare landing page for the new resource print(f'Your new resource is available at: {new_resource.metadata.url}') Retrieving an Existing Resource If you want to work on an existing resource rather than creating a new one, you can retrieve an existing resource using its HydroShare identifier. The resource identifier is passed as a string. The resource's metadata is retrieved and loaded into memory. # Get an existing resource using its identifier existing_resource = hs.resource(res_identifier) print(f'Just retrieved the resource with ID: {res_identifier}') Deleting a Resource If you want to delete a resource you are currently working with, you can just call the delete() function on that resource. This will delete your local copy of the resource and the resource in HydroShare. new_resource.delete() Alternatively, if you know the HydroShare identifier of the resource you want to delete, you can use it to delete the resource. # Delete the resource using its identifier hs.resource(res_identifier).delete() print(f'Deleted resource with ID: {res_identifier}') Download an Entire Resource HydroShare allows you to download an entire resource as a zipped file that uses the BagIt packaging standard. You can identify the resource you want to download using its HydroShare identifier. When you call the download() function on the resource, you can pass a path where you want to save the zipped file. Leaving the path blank downloads the files to the directory. This example downloads the HydroShare resource containing these example Jupyter Notebooks. # Get the resource you want to download using its identifier res_identifier = '7561aa12fd824ebb8edbee05af19b910' res = hs.resource(res_identifier) # Download the resource as a zipped Bagit file # Pass in a file path if you want to download to a particular location res.download()","title":"Basic Operations"},{"location":"examples/Basic_Operations/#hsclient-hydroshare-python-client-basic-resource-operation-examples","text":"The following code snippets show examples for how to use the hsclient HydroShare Python Client for performing basic resource operations.","title":"hsclient HydroShare Python Client Basic Resource Operation Examples"},{"location":"examples/Basic_Operations/#install-the-hsclient-python-client","text":"The hsclient Python Client for HydroShare may not be installed by default in your Python environment, so it has to be installed first before you can work with it. Use the following command to install hsclient via the Python Package Index (PyPi). !pip install hsclient","title":"Install the hsclient Python Client"},{"location":"examples/Basic_Operations/#authenticating-with-hydroshare","text":"Before you start interacting with resources in HydroShare you will need to authenticate. To authenticate with HydroShare, you can either specify your username and password or you can call the sign_in() function, which will prompt you to input your username and password. from hsclient import HydroShare username = 'username' password = 'password' hs = HydroShare(username, password) In most cases you will not want anyone to see your username and password, so you can also call the sign_in() function to be prompted for your username and password. This is better to use if you are sharing a Jupyter Notebook. from hsclient import HydroShare hs = HydroShare() hs.sign_in()","title":"Authenticating with HydroShare"},{"location":"examples/Basic_Operations/#basic-resource-operations","text":"","title":"Basic Resource Operations"},{"location":"examples/Basic_Operations/#create-a-new-empty-resource","text":"A \"resource\" is a container for your content in HydroShare. Think of it as a \"working directory\" into which you are going to organize the code and/or data you are using and want to share. The following code can be used to create a new, empty resource within which you can create content and metadata. This code creates a new resource in HydroShare. It also creates an in-memory object representation of that resource in your local environmment that you can then manipulate with further code. # Create the new, empty resource new_resource = hs.create() # Get the HydroShare identifier for the new resource res_identifier = new_resource.resource_id print(f'The HydroShare Identifier for your new resources is: {res_identifier}') # Construct a hyperlink to access the HydroShare landing page for the new resource print(f'Your new resource is available at: {new_resource.metadata.url}')","title":"Create a New Empty Resource"},{"location":"examples/Basic_Operations/#retrieving-an-existing-resource","text":"If you want to work on an existing resource rather than creating a new one, you can retrieve an existing resource using its HydroShare identifier. The resource identifier is passed as a string. The resource's metadata is retrieved and loaded into memory. # Get an existing resource using its identifier existing_resource = hs.resource(res_identifier) print(f'Just retrieved the resource with ID: {res_identifier}')","title":"Retrieving an Existing Resource"},{"location":"examples/Basic_Operations/#deleting-a-resource","text":"If you want to delete a resource you are currently working with, you can just call the delete() function on that resource. This will delete your local copy of the resource and the resource in HydroShare. new_resource.delete() Alternatively, if you know the HydroShare identifier of the resource you want to delete, you can use it to delete the resource. # Delete the resource using its identifier hs.resource(res_identifier).delete() print(f'Deleted resource with ID: {res_identifier}')","title":"Deleting a Resource"},{"location":"examples/Basic_Operations/#download-an-entire-resource","text":"HydroShare allows you to download an entire resource as a zipped file that uses the BagIt packaging standard. You can identify the resource you want to download using its HydroShare identifier. When you call the download() function on the resource, you can pass a path where you want to save the zipped file. Leaving the path blank downloads the files to the directory. This example downloads the HydroShare resource containing these example Jupyter Notebooks. # Get the resource you want to download using its identifier res_identifier = '7561aa12fd824ebb8edbee05af19b910' res = hs.resource(res_identifier) # Download the resource as a zipped Bagit file # Pass in a file path if you want to download to a particular location res.download()","title":"Download an Entire Resource"},{"location":"examples/File_Operations/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); hsclient HydroShare Python Client Resource File Operation Examples The following code snippets show examples for how to use the hsclient HydroShare Python Client to manipulate files within a HydroShare Resource. Install the hsclient Python Client The hsclient Python Client for HydroShare may not be installed by default in your Python environment, so it has to be installed first before you can work with it. Use the following command to install hsclient via the Python Package Index (PyPi). !pip install hsclient Authenticating with HydroShare Before you start interacting with resources in HydroShare you will need to authenticate. from hsclient import HydroShare hs = HydroShare() hs.sign_in() Create a New Empty Resource A \"resource\" is a container for your content in HydroShare. Think of it as a \"working directory\" into which you are going to organize the code and/or data you are using and want to share. The following code can be used to create a new, empty resource within which you can create content and metadata. This code creates a new resource in HydroShare. It also creates an in-memory object representation of that resource in your local environmment that you can then manipulate with further code. # Create the new, empty resource new_resource = hs.create() # Get the HydroShare identifier for the new resource res_identifier = new_resource.resource_id print(f'The HydroShare Identifier for your new resource is: {res_identifier}') # Construct a hyperlink for the new resource print(f'Your new resource is available at: {new_resource.metadata.url}') Resource File Handling HydroShare resources can have any number of files within them organized within a file/directory structure. File handing operations allow you to manage the content files within a resource. First, show the list of files within the resource, which is initially empty. The search_aggregations argument tells the client whether you want to look at all of the files in the resource ( search_aggregations=True ) or if you want to want to only look at files that do not belong to a content aggregation ( search_aggregations=False ). # Print the title of the resource and the list of files it contains print(f'Working on: {new_resource.metadata.title}') print('File list:') for file in new_resource.files(search_aggregations=True): print(file.name) Adding Files to a Resource You may need to add content files to your resource. The examples here upload files from the Example_Files folder that is included in the same folder that contains these Jupyter Notebook examples. If you are running in your own local Python environment and want to load files from your local machine, you would specify the path to the file(s) on your hard drive. If you want to upload multiple files at once, you can pass multiple file paths separated by commas to the upload() function. Note that if you upload files that already exist, those files will be overwritten. # Upload one or more files to your resource new_resource.file_upload('Example_Files/Data_File1.txt', 'Example_Files/Data_File2.txt') # Print the names of the files in the resource print('Updated file list after adding a file: ') for file in new_resource.files(search_aggregations=True): print(file.path) HydroShare also allows you to create a folder hierarchy within your resource. You can use this functionality to keep your content organized, just as you would on your own computer. You can upload files to specific folders within the resource. Paths to folders are specified relative to the \"content\" directory of the resource. # First create a new folder new_resource.folder_create('New_Folder') # Upload one or more files to a specific folder within a resource new_resource.file_upload('Example_Files/Data_File2.txt', destination_path='New_Folder') # Print the names of the files in the resource print('Updated file list after adding a file: ') for file in new_resource.files(search_aggregations=True): print(file.path) Searching for Files within a Resource If you need to find/get one or more files within a resource so you can download or remove it from the resource, there are several filters available that allow you to return a list of files that meet your search criteria or a single file. Get a List of Files Execute a filter to return a list of files within the resource that meet the search critera. # Get a list of the files in the resource that are not part of an aggregation file_list = new_resource.files() print('All files that are not part of an aggregation:') print(*file_list, sep='\\n') print('\\n') # Get a list of the files in the resource inclusive of files that are inside # content type aggregations file_list = new_resource.files(search_aggregations=True) print('All files in the resource:') print(*file_list, sep='\\n') print('\\n') # Get a list of the files within a folder in the resource # Note that you have to pass the full relative path to the folder you are searching # because there may be multiple folders within a resource with the same name. # To get files in the root folder, pass an empty string (folder=\"\") file_list = new_resource.files(folder='New_Folder') print('All files within a specific folder:') print(*file_list, sep='\\n') print('\\n') # Get a list of all files that have a specific extension. This searches all folders file_list = new_resource.files(extension='.txt') print('All files with a .txt file extension:') print(*file_list, sep='\\n') print('\\n') # Filters can be combined # Get a list of all files in a particular folder that have a specific extension file_list = new_resource.files(folder='New_Folder', extension='.txt') print('All files with a .txt file extension in a particular folder:') print(*file_list, sep='\\n') Search for a Single File Execute a filter to look for a single file in the resource that meets the search criteria. # Get a single file using its path relative to the resource content directory file = new_resource.file(path='New_Folder/Data_File2.txt') print('File retrieved using path:') print(file) print('\\n') # Get a single file using its name # Note that if you have multiple files in your resource with the same name, but in different # folders, you should search for a particular file using the path parameter to ensure that # you get the right file file = new_resource.file(name='Data_File2.txt') print('File retrieved using name:') print(file) Get the Properties of a File When you use the filters to return a file from a resource, you get back a file object that holds properties of the file. # Search for a file within a resource file = new_resource.file(path='New_Folder/Data_File2.txt') # Print the properties of the file print(f'File name: {file.name}') print(f'File extension: {file.extension}') print(f'File folder name: {file.folder}') print(f'File path: {file.path}') print(f'File url_path: {file.url}') print(f'File checksum: {file.checksum}') Renaming and Moving Files You may need to rename or move files once they have been added to a resource. First get the file object and then rename or move it. # Get a file to rename - use the relative path to the file to make sure you have the right one file = new_resource.file(path='Data_File2.txt') # Rename the file to whatever you want new_resource.file_rename(file, 'Data_File2_Renamed.txt') # Print the names of the files in the resource print('Updated file list after renaming a file: ') for file in new_resource.files(search_aggregations=True): print(file.path) Moving files is similar to renaming. Instead of just changing the file name, change the relative path of the file to move it to the new location within the resource. # Get a file to move file = new_resource.file(path='Data_File1.txt') # Move the file to a different folder new_resource.file_rename(file, 'New_Folder/Data_File1.txt') # Print the names of the files in the resource print('Updated file list after renaming a file: ') for file in new_resource.files(search_aggregations=True): print(file.path) Downloading Files from a Resource You can download individual files from an existing HydroShare resource. You can use the filters shown above to specify which file(s) you want to download. When you call the file_download() function on an individual file, you can pass a path where you want to save the file as a string. Leaving the path blank downloads the files to the same directory as your Jupyter Notebook. # Download a single file from a resource # Note that if you have multiple files within the same resource that have the same name, # and you want a particular file, you need to specify the relative path to the specific file file = new_resource.file(path='New_Folder/Data_File1.txt') new_resource.file_download(file) If you want to, you can clean up the file that was just downloaded by deleting it using a terminal command. !rm 'Data_File1.txt' Unzipping a File in a Resource You can unzip a file in a HydroShare resource. # Upload a zipped file to the resource new_resource.file_upload('Example_Files/test.zip') # Specify the file you want to unzip new_resource.file_unzip(path='test.zip') # Print the names of the files in the resource print('Updated file list after unzipping a file: ') for file in new_resource.files(search_aggregations=True): print(file.path) Removing Files from a Resource You can also delete files from a resource. In this example, I remove one of the files I added to the resource above. You have to delete each individual file. Make sure you call delete using the path parameter to make sure you are deleting the right file. # Specify the file you want to delete file = new_resource.file(path='New_Folder/Data_File2.txt') new_resource.file_delete(file) # Print the names of the files in the resource print('Updated file list after removing file: ') for file in new_resource.files(search_aggregations=True): print(file.path) Deleting Folders from a Resource You can delete folders from a HydroShare resource. You can delete a folder and all of the files within it. # Specify the folder you want to delete new_resource.folder_delete('New_Folder') # Print the names of the files in the resource print('Updated file list after deleting folder: ') for file in new_resource.files(search_aggregations=True): print(file.path) Moving a Folder in a Resource You can move a folder in a HydroShare resource. You can move a folder and all of the files within it to a different folder in that resource. Moving folders is similar to renaming. Instead of just changing the folder name, change the relative path of the folder to move it to the new location within the resource. # First create a new folder new_resource.folder_create('New_Folder_1') # Upload one or more files to a specific folder within a resource new_resource.file_upload('Example_Files/Data_File1.txt', destination_path='New_Folder_1') # Print the names of the files in the resource print('Updated file list after uploading file to folder: ') for file in new_resource.files(search_aggregations=True): print(file.path) # Create a 2nd folder new_resource.folder_create('New_Folder_2') # Upload one or more files to a specific folder within a resource new_resource.file_upload('Example_Files/Data_File2.txt', destination_path='New_Folder_2') # Print the names of the files in the resource print('Updated file list after uploading file to folder: ') for file in new_resource.files(search_aggregations=True): print(file.path) # Now move the folder 'New_Folder_2' to 'New_Folder_1' - this will make 'New_Folder_2' a subfolder of 'New_Folder_1' new_resource.folder_rename('New_Folder_2', 'New_Folder_1/New_Folder_2') # Print the names of the files in the resource print('Updated file list after moving folder: ') for file in new_resource.files(search_aggregations=True): print(file.path) Renaming a Folder in a Resource You can rename a folder in a HydroShare resource. # Specify the folder you want to rename new_resource.folder_rename('New_Folder_1', 'New_Folder_1_Renamed') # Print the names of the files in the resource print('Updated file list after renaming folder: ') for file in new_resource.files(search_aggregations=True): print(file.path) Zipping a Folder in a Resource You can zip a folder in a HydroShare resource. By default, the name of the generated zip file will be based on the name of the folder being zipped. You can optionally provide a name for the generated zip file using the 'zip_name' parameter to the file_zip() function. The zip file will be created at the same location where the folder being zipped exists. # Specify the folder you want to zip - optionally provide a name for the zip file using the parameter 'zip_name' new_resource.file_zip('New_Folder_1_Renamed/New_Folder_2') # Print the names of the files in the resource print('Updated file list after zipping folder: ') for file in new_resource.files(search_aggregations=True): print(file.path) Downloading a Folder in a Resource You can download a folder in a HydroShare resource as a zipped file. You can pass a path using the 'save_path' parameter where you want to save the folder zipped file as a string to the file_download() function. Leaving the path blank downloads the folder to the same directory as your Jupyter Notebook. # Specify the folder you want to download - optionally use the parameter 'save_path` to specify where you want to save the zipped file new_resource.file_download('New_Folder_1_Renamed', zipped=True)","title":"File Operations"},{"location":"examples/File_Operations/#hsclient-hydroshare-python-client-resource-file-operation-examples","text":"The following code snippets show examples for how to use the hsclient HydroShare Python Client to manipulate files within a HydroShare Resource.","title":"hsclient HydroShare Python Client Resource File Operation Examples"},{"location":"examples/File_Operations/#install-the-hsclient-python-client","text":"The hsclient Python Client for HydroShare may not be installed by default in your Python environment, so it has to be installed first before you can work with it. Use the following command to install hsclient via the Python Package Index (PyPi). !pip install hsclient","title":"Install the hsclient Python Client"},{"location":"examples/File_Operations/#authenticating-with-hydroshare","text":"Before you start interacting with resources in HydroShare you will need to authenticate. from hsclient import HydroShare hs = HydroShare() hs.sign_in()","title":"Authenticating with HydroShare"},{"location":"examples/File_Operations/#create-a-new-empty-resource","text":"A \"resource\" is a container for your content in HydroShare. Think of it as a \"working directory\" into which you are going to organize the code and/or data you are using and want to share. The following code can be used to create a new, empty resource within which you can create content and metadata. This code creates a new resource in HydroShare. It also creates an in-memory object representation of that resource in your local environmment that you can then manipulate with further code. # Create the new, empty resource new_resource = hs.create() # Get the HydroShare identifier for the new resource res_identifier = new_resource.resource_id print(f'The HydroShare Identifier for your new resource is: {res_identifier}') # Construct a hyperlink for the new resource print(f'Your new resource is available at: {new_resource.metadata.url}')","title":"Create a New Empty Resource"},{"location":"examples/File_Operations/#resource-file-handling","text":"HydroShare resources can have any number of files within them organized within a file/directory structure. File handing operations allow you to manage the content files within a resource. First, show the list of files within the resource, which is initially empty. The search_aggregations argument tells the client whether you want to look at all of the files in the resource ( search_aggregations=True ) or if you want to want to only look at files that do not belong to a content aggregation ( search_aggregations=False ). # Print the title of the resource and the list of files it contains print(f'Working on: {new_resource.metadata.title}') print('File list:') for file in new_resource.files(search_aggregations=True): print(file.name)","title":"Resource File Handling"},{"location":"examples/File_Operations/#adding-files-to-a-resource","text":"You may need to add content files to your resource. The examples here upload files from the Example_Files folder that is included in the same folder that contains these Jupyter Notebook examples. If you are running in your own local Python environment and want to load files from your local machine, you would specify the path to the file(s) on your hard drive. If you want to upload multiple files at once, you can pass multiple file paths separated by commas to the upload() function. Note that if you upload files that already exist, those files will be overwritten. # Upload one or more files to your resource new_resource.file_upload('Example_Files/Data_File1.txt', 'Example_Files/Data_File2.txt') # Print the names of the files in the resource print('Updated file list after adding a file: ') for file in new_resource.files(search_aggregations=True): print(file.path) HydroShare also allows you to create a folder hierarchy within your resource. You can use this functionality to keep your content organized, just as you would on your own computer. You can upload files to specific folders within the resource. Paths to folders are specified relative to the \"content\" directory of the resource. # First create a new folder new_resource.folder_create('New_Folder') # Upload one or more files to a specific folder within a resource new_resource.file_upload('Example_Files/Data_File2.txt', destination_path='New_Folder') # Print the names of the files in the resource print('Updated file list after adding a file: ') for file in new_resource.files(search_aggregations=True): print(file.path)","title":"Adding Files to a Resource"},{"location":"examples/File_Operations/#searching-for-files-within-a-resource","text":"If you need to find/get one or more files within a resource so you can download or remove it from the resource, there are several filters available that allow you to return a list of files that meet your search criteria or a single file.","title":"Searching for Files within a Resource"},{"location":"examples/File_Operations/#get-a-list-of-files","text":"Execute a filter to return a list of files within the resource that meet the search critera. # Get a list of the files in the resource that are not part of an aggregation file_list = new_resource.files() print('All files that are not part of an aggregation:') print(*file_list, sep='\\n') print('\\n') # Get a list of the files in the resource inclusive of files that are inside # content type aggregations file_list = new_resource.files(search_aggregations=True) print('All files in the resource:') print(*file_list, sep='\\n') print('\\n') # Get a list of the files within a folder in the resource # Note that you have to pass the full relative path to the folder you are searching # because there may be multiple folders within a resource with the same name. # To get files in the root folder, pass an empty string (folder=\"\") file_list = new_resource.files(folder='New_Folder') print('All files within a specific folder:') print(*file_list, sep='\\n') print('\\n') # Get a list of all files that have a specific extension. This searches all folders file_list = new_resource.files(extension='.txt') print('All files with a .txt file extension:') print(*file_list, sep='\\n') print('\\n') # Filters can be combined # Get a list of all files in a particular folder that have a specific extension file_list = new_resource.files(folder='New_Folder', extension='.txt') print('All files with a .txt file extension in a particular folder:') print(*file_list, sep='\\n')","title":"Get a List of Files"},{"location":"examples/File_Operations/#search-for-a-single-file","text":"Execute a filter to look for a single file in the resource that meets the search criteria. # Get a single file using its path relative to the resource content directory file = new_resource.file(path='New_Folder/Data_File2.txt') print('File retrieved using path:') print(file) print('\\n') # Get a single file using its name # Note that if you have multiple files in your resource with the same name, but in different # folders, you should search for a particular file using the path parameter to ensure that # you get the right file file = new_resource.file(name='Data_File2.txt') print('File retrieved using name:') print(file)","title":"Search for a Single File"},{"location":"examples/File_Operations/#get-the-properties-of-a-file","text":"When you use the filters to return a file from a resource, you get back a file object that holds properties of the file. # Search for a file within a resource file = new_resource.file(path='New_Folder/Data_File2.txt') # Print the properties of the file print(f'File name: {file.name}') print(f'File extension: {file.extension}') print(f'File folder name: {file.folder}') print(f'File path: {file.path}') print(f'File url_path: {file.url}') print(f'File checksum: {file.checksum}')","title":"Get the Properties of a File"},{"location":"examples/File_Operations/#renaming-and-moving-files","text":"You may need to rename or move files once they have been added to a resource. First get the file object and then rename or move it. # Get a file to rename - use the relative path to the file to make sure you have the right one file = new_resource.file(path='Data_File2.txt') # Rename the file to whatever you want new_resource.file_rename(file, 'Data_File2_Renamed.txt') # Print the names of the files in the resource print('Updated file list after renaming a file: ') for file in new_resource.files(search_aggregations=True): print(file.path) Moving files is similar to renaming. Instead of just changing the file name, change the relative path of the file to move it to the new location within the resource. # Get a file to move file = new_resource.file(path='Data_File1.txt') # Move the file to a different folder new_resource.file_rename(file, 'New_Folder/Data_File1.txt') # Print the names of the files in the resource print('Updated file list after renaming a file: ') for file in new_resource.files(search_aggregations=True): print(file.path)","title":"Renaming and Moving Files"},{"location":"examples/File_Operations/#downloading-files-from-a-resource","text":"You can download individual files from an existing HydroShare resource. You can use the filters shown above to specify which file(s) you want to download. When you call the file_download() function on an individual file, you can pass a path where you want to save the file as a string. Leaving the path blank downloads the files to the same directory as your Jupyter Notebook. # Download a single file from a resource # Note that if you have multiple files within the same resource that have the same name, # and you want a particular file, you need to specify the relative path to the specific file file = new_resource.file(path='New_Folder/Data_File1.txt') new_resource.file_download(file) If you want to, you can clean up the file that was just downloaded by deleting it using a terminal command. !rm 'Data_File1.txt'","title":"Downloading Files from a Resource"},{"location":"examples/File_Operations/#unzipping-a-file-in-a-resource","text":"You can unzip a file in a HydroShare resource. # Upload a zipped file to the resource new_resource.file_upload('Example_Files/test.zip') # Specify the file you want to unzip new_resource.file_unzip(path='test.zip') # Print the names of the files in the resource print('Updated file list after unzipping a file: ') for file in new_resource.files(search_aggregations=True): print(file.path)","title":"Unzipping a File in a Resource"},{"location":"examples/File_Operations/#removing-files-from-a-resource","text":"You can also delete files from a resource. In this example, I remove one of the files I added to the resource above. You have to delete each individual file. Make sure you call delete using the path parameter to make sure you are deleting the right file. # Specify the file you want to delete file = new_resource.file(path='New_Folder/Data_File2.txt') new_resource.file_delete(file) # Print the names of the files in the resource print('Updated file list after removing file: ') for file in new_resource.files(search_aggregations=True): print(file.path)","title":"Removing Files from a Resource"},{"location":"examples/File_Operations/#deleting-folders-from-a-resource","text":"You can delete folders from a HydroShare resource. You can delete a folder and all of the files within it. # Specify the folder you want to delete new_resource.folder_delete('New_Folder') # Print the names of the files in the resource print('Updated file list after deleting folder: ') for file in new_resource.files(search_aggregations=True): print(file.path)","title":"Deleting Folders from a Resource"},{"location":"examples/File_Operations/#moving-a-folder-in-a-resource","text":"You can move a folder in a HydroShare resource. You can move a folder and all of the files within it to a different folder in that resource. Moving folders is similar to renaming. Instead of just changing the folder name, change the relative path of the folder to move it to the new location within the resource. # First create a new folder new_resource.folder_create('New_Folder_1') # Upload one or more files to a specific folder within a resource new_resource.file_upload('Example_Files/Data_File1.txt', destination_path='New_Folder_1') # Print the names of the files in the resource print('Updated file list after uploading file to folder: ') for file in new_resource.files(search_aggregations=True): print(file.path) # Create a 2nd folder new_resource.folder_create('New_Folder_2') # Upload one or more files to a specific folder within a resource new_resource.file_upload('Example_Files/Data_File2.txt', destination_path='New_Folder_2') # Print the names of the files in the resource print('Updated file list after uploading file to folder: ') for file in new_resource.files(search_aggregations=True): print(file.path) # Now move the folder 'New_Folder_2' to 'New_Folder_1' - this will make 'New_Folder_2' a subfolder of 'New_Folder_1' new_resource.folder_rename('New_Folder_2', 'New_Folder_1/New_Folder_2') # Print the names of the files in the resource print('Updated file list after moving folder: ') for file in new_resource.files(search_aggregations=True): print(file.path)","title":"Moving a Folder in a Resource"},{"location":"examples/File_Operations/#renaming-a-folder-in-a-resource","text":"You can rename a folder in a HydroShare resource. # Specify the folder you want to rename new_resource.folder_rename('New_Folder_1', 'New_Folder_1_Renamed') # Print the names of the files in the resource print('Updated file list after renaming folder: ') for file in new_resource.files(search_aggregations=True): print(file.path)","title":"Renaming a Folder in a Resource"},{"location":"examples/File_Operations/#zipping-a-folder-in-a-resource","text":"You can zip a folder in a HydroShare resource. By default, the name of the generated zip file will be based on the name of the folder being zipped. You can optionally provide a name for the generated zip file using the 'zip_name' parameter to the file_zip() function. The zip file will be created at the same location where the folder being zipped exists. # Specify the folder you want to zip - optionally provide a name for the zip file using the parameter 'zip_name' new_resource.file_zip('New_Folder_1_Renamed/New_Folder_2') # Print the names of the files in the resource print('Updated file list after zipping folder: ') for file in new_resource.files(search_aggregations=True): print(file.path)","title":"Zipping a Folder in a Resource"},{"location":"examples/File_Operations/#downloading-a-folder-in-a-resource","text":"You can download a folder in a HydroShare resource as a zipped file. You can pass a path using the 'save_path' parameter where you want to save the folder zipped file as a string to the file_download() function. Leaving the path blank downloads the folder to the same directory as your Jupyter Notebook. # Specify the folder you want to download - optionally use the parameter 'save_path` to specify where you want to save the zipped file new_resource.file_download('New_Folder_1_Renamed', zipped=True)","title":"Downloading a Folder in a Resource"},{"location":"examples/Metadata_Operations/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); hsclient HydroShare Python Client Resource Metadata Editing Examples The following code snippets show examples for how to use the hsclient HydroShare Python Client for creating and editing resource level metadata for a HydroShare resource. Install the hsclient HydroShare Python Client The hsclient Python Client for HydroShare may not be installed by default in your Python environment, so it has to be installed first before you can work with it. Use the following command to install hsclient via the Python Package Index (PyPi). !pip install hsclient Authenticate with HydroShare Before you start interacting with resources in HydroShare you will need to authenticate. from hsclient import HydroShare hs = HydroShare() hs.sign_in() Create a New Empty Resource A \"resource\" is a container for your content in HydroShare. Think of it as a \"working directory\" into which you are going to organize the code and/or data you are using and want to share. The following code can be used to create a new, empty resource within which you can create content and metadata. This code creates a new resource in HydroShare. It also creates an in-memory object representation of that resource in your local environmment that you can then manipulate with further code. # Create the new, empty resource new_resource = hs.create() # Get the HydroShare identifier for the new resource res_identifier = new_resource.resource_id print(f'The HydroShare Identifier for your new resource is: {res_identifier}') # Construct a hyperlink to access the HydroShare landing page for the new resource print(f'Your new resource is available at: {new_resource.metadata.url}') Creating and Editing Resource Metadata Elements Editing metadata elements for a resource can be done in an object oriented way. You can specify all of the metadata elements in code, which will set their values in memory in your local environment. Values of metadata elements can be edited, removed, or replaced by setting them to a new value, appending new values (in the case where the metadata element accepts a list), or by removing the value entirely. When you are ready to save edits to metadata elements from your local environment to the resource in HydroShare, you can call the save() function on your resource and all of the new metadata values you created/edited will be saved to the resource in HydroShare. Resource Title and Abstract The Title and Abstract metadata elements can be specified as text strings. To modify the Title or Abstract after it has been set, just set them to a different value. # Set the Title for the resource new_resource.metadata.title = 'Resource for Testing the hsclient HydroShare Python Client' # Set the Abstract text for the resource new_resource.metadata.abstract = ( 'This resource was created as a demonstration of using the hsclient ' 'Python Client for HydroShare. Once you have completed all of the ' 'steps in this notebook, you will have a fully populated HydroShare ' 'Resource.' ) # Call the save function to save the metadata edits to HydroShare new_resource.save() # Print the title just added to the resource print(f'Title: {new_resource.metadata.title}') print(f'Abstract: {new_resource.metadata.abstract}') Subject Keywords Subject keywords can be specified as a Python list of strings. Keywords can be added by creating a list, appending new keywords to the existing list, or by overriding the existing list with a new one. # Create subject keywords for the resource using a list of strings new_resource.metadata.subjects = ['hsclient', 'Python', 'HydroShare', 'Another Keyword'] # New keywords can be appended to the existing list new_resource.metadata.subjects.append('Hydroinformatics') # Keywords can be removed by removing them from the list new_resource.metadata.subjects.remove('Another Keyword') # Save the changes to the resource in HydroShare new_resource.save() # Print the keywords for the resource print('The list of keywords for the resource includes:') for keyword in new_resource.metadata.subjects: print(keyword) Spatial and Temporal Coverage Initially the spatial and temporal coverage for a resource are empty. To set them, you have to create a coverage object of the right type and set the spatial or temporal coverage to that object. # Import the required metadata classes for coverage objects from hsmodels.schemas.fields import BoxCoverage, PointCoverage, PeriodCoverage from datetime import datetime # Set the spatial coverage to a BoxCoverage object new_resource.metadata.spatial_coverage = BoxCoverage(name='Logan, Utah', northlimit=41.7910, eastlimit=-111.7664, southlimit=41.6732, westlimit=-111.9079, projection='WGS 84 EPSG:4326', type='box', units='Decimal degrees') # You can remove the spatial coverage element by setting it to None new_resource.metadata.spatial_coverage = None # If you want to set the spatial coverage to a PointCoverage instead new_resource.metadata.spatial_coverage = PointCoverage(name='Logan, Utah', north=41.7371, east=-111.8351, projection='WGS 84 EPSG:4326', type='point', units='Decimal degrees') # Create a beginning and ending date for a time period beginDate = datetime.strptime('2020-12-01T00:00:00Z', '%Y-%m-%dT%H:%M:%S%fZ') endDate = datetime.strptime('2020-12-31T00:00:00Z', '%Y-%m-%dT%H:%M:%S%fZ') # Set the temporal coverage of the resource to a PeriodCoverage object new_resource.metadata.period_coverage = PeriodCoverage(start=beginDate, end=endDate) # Save the changes to the resource in HydroShare new_resource.save() # Print the temporal coverage information print('Temporal Coverage:') print(new_resource.metadata.period_coverage) # Print the spatial coverage information print('\\nSpatial Coverage:') print(new_resource.metadata.spatial_coverage) Additional/Extended Metadata HydroShare allows you to create new, extended metadata elements for a HydroShare resource as key-value pairs. You can add new elements, edit existing elements, or remove these elements. Extended metadata elements are stored in the resource as a Python dictionary. # Add an extended metadata element as a key-value pair new_resource.metadata.additional_metadata['New Element Key'] = 'Text value of new element key.' # Remove an individual key-value pair using its key del new_resource.metadata.additional_metadata['New Element Key'] # Or, you can clear out all additional metadata elements that might exist new_resource.metadata.additional_metadata.clear() # Add multiple key-value pairs at once using a Python dictionary new_resource.metadata.additional_metadata = { 'Observed Variable': 'Oxygen, dissolved', 'Site Location': 'Located on downstream side of river bridge', 'Observation Depth': '1 meter' } # Save the changes to the resource in HydroShare new_resource.save() # Print the extended metadata elements for the resource print('The extended metadata elements for the resource include:') for key, value in new_resource.metadata.additional_metadata.items(): print(f'{key}: {value}') Related Resources Related Resources are specified using a string that encodes the citation for the Related Resource along with a relationship type. Because of this, Related Resources are stored as a list of Relation objects. To create a new Related Resource, you have to first instantiate a Relation object and then add it to the list of Related Resources. # Import the required metadata class for a Relation object from hsmodels.schemas.fields import Relation from hsmodels.schemas.enums import RelationType # If you have existing Related Resources, you can remove all of them # by clearing the local list and then saving the resource new_resource.metadata.relations.clear() new_resource.save() # Create a new relation object new_relation = Relation(type=RelationType.isReferencedBy, value=('Bastidas Pacheco, C. J., Horsburgh, J. S., Tracy, ' 'R. J. (2020). A low-cost, open source monitoring ' 'system for collecting high-resolution water use ' 'data on magnetically-driven residential water ' 'meters, Sensors, 20(13), 3655, ' 'https://doi.org/10.3390/s20133655.')) # Append the new Related Resource to the list of Related Resources new_resource.metadata.relations.append(new_relation) # Add another related resource with a different relationship type new_relation = Relation(type=RelationType.references, value=('Mihalevich, B. A., Horsburgh, J. S., Melcher, A. A. (2017). ' 'High-frequency measurements reveal spatial and temporal patterns ' 'of dissolved organic matter in an urban water conveyance, ' 'Environmental Monitoring and Assessment, ' 'https://doi.org/10.1007/s10661-017-6310-y.')) new_resource.metadata.relations.append(new_relation) # Save the changes to the resource in HydroShare new_resource.save() # Print the list of Related Resources print('The list of Related Resources includes:') for relatedResource in new_resource.metadata.relations: print(f'{relatedResource.type.value}: {relatedResource.value}') Funding Agency Credits Funding agency information contains multiple attributes when you add a funding agency to a HydroShare resource. You can create multiple funding agency entries for a resource, which get stored as a Python list. # Import the required metadata class for an AwardInfo object from hsmodels.schemas.fields import AwardInfo # If you have existing funding agency information, you can remove all of them # by clearing the local list and then saving the resource new_resource.metadata.awards.clear() new_resource.save() # Create a new AwardInfo object newAwardInfo = AwardInfo(funding_agency_name='National Science Foundation', title=('Collaborative Research: Elements: Advancing Data Science ' 'and Analytics for Water (DSAW)'), number='OAC 1931297', funding_agency_url='https://www.nsf.gov/awardsearch/showAward?AWD_ID=1931297') # Append the new AwardInfo object to the list of funding agencies new_resource.metadata.awards.append(newAwardInfo) # Save the changes to the resource in HydroShare new_resource.save() # Print the AwardInfo print('Funding sources added: ') for award in new_resource.metadata.awards: print(f'Award Title: {award.title}') Authors In HydroShare, an \"Author\" is the same as the Dublin Core metadata \"Creator\" element. The Creator element is a list of creators for the resource. However, the order of the Creators matters. When setting Creator information for the resource, you need to edit the local list of creators so that it reflects the order you want. When you call the save() function on the resource, the Creator information in HydroShare will be updated to match what you set locally. To add a new Creator to the list of Creators, you must first instantiate a Creator object and then add it to the list of Creators for the resource. Creator objects can be created by supplying all of the Creator metadata or by copying from a HydroShare user's profile. # Import the required metadata class for a Creator object from hsmodels.schemas.fields import Creator # Instantiate a new Creator object for a Creator that is a HydroShare user newCreator1 = Creator(name='Jones, Amber Spackman', organization='Utah State University', email='amber.jones@usu.edu', hydroshare_user_id=510) # Append the new Creator to the resource's list of Creators new_resource.metadata.creators.append(newCreator1) # Instantiate a new Creator object for a Creator that is not a HydroShare user newCreator2 = Creator(name='Doe, John A.', organization='Utah Water Research Laboratory', email='john.doe@usu.edu', address='8200 Old Main Hill, Logan, UT 84322-8200', phone='123-456-7890') # Append the new Creator to the resource's list of Creators new_resource.metadata.creators.append(newCreator2) # Instantiate a new Creator object for a Creator that is an organization newCreator3 = Creator(organization='Utah Water Research Laboratory', email='uwrl.receptionist@usu.edu', address='8200 Old Main Hill, Logan, UT 84322-8200', homepage='http://uwrl.usu.edu', phone='435-797-3168 ') # Append the new Creator to the resource's list of Creators new_resource.metadata.creators.append(newCreator3) # Instantiate a new Creator object using a HydroShare user object # First, retrieve HydroShare user object tony = hs.user(11) # Generate a Creator object from a HydroShare user object and append # the new Creator to the resource's list of Creators newCreator4 = Creator.from_user(tony) new_resource.metadata.creators.append(newCreator4) # Save the changes to the resource in HydroShare new_resource.save() # Print the Creator names print('The list of Creators includes: ') for creator in new_resource.metadata.creators: if creator.name is None: print(creator.organization) else: print(creator.name) The previous step leaves the resource with a list of 5 Creators. The order in which Creators appear in the metadata and on the Resource Landing Page is controlled by the order in which they appear in the the Creator list. To update the Creator order, update the order of the Creator list and then save the resource. # Change the order of the Creators in the list creatorOrder = [3, 2, 0, 1, 4] new_resource.metadata.creators = [new_resource.metadata.creators[i] for i in creatorOrder] # Save the changes to the resource in HydroShare new_resource.save() # Print the modified order of the Creator names print('The list of Creators includes: ') for creator in new_resource.metadata.creators: if creator.name is None: print(creator.organization) else: print(creator.name) Creators can be removed by removing them from the local list of creators and then calling the save() function on the resource. Note that there must always be at least one creator. # Example of removing all but the first creator del new_resource.metadata.creators[1:] new_resource.save() print(f'Number of remaining creators: {len(new_resource.metadata.creators)}') Contributors Contributors can be existing HydroShare users or others who do not have HydroShare accounts. Creating and removing contributors is similar to how Creators are handled. Contributors do not have a designated order. # Import the required metadata class for a Contributor object from hsmodels.schemas.fields import Contributor # Instantiate a new Contributor object for a Contributor that is not a HydroShare user newContributor1 = Contributor(name='Horsburgh, Jeffery S.', organization='Utah State University', email='jeff.horsburgh@usu.edu', phone='(435) 797-2946', ORCID='https://orcid.org/0000-0002-0768-3196', address='Utah, US', google_scholar_id='https://scholar.google.com/citations?user=mu4k534AAAAJ&amp;hl=en', homepage='http://jeffh.usu.edu', research_gate_id='https://www.researchgate.net/profile/Jeffery_Horsburgh') # Append the new Contributor to the resource's list of Contributors new_resource.metadata.contributors.append(newContributor1) # Instantiate a new Contributor object for a Contributor that is not a HydroShare user # Not all of the available metadata for a contributor have to be filled out newContributor2 = Contributor(name='Doe, John A.', organization='Utah State University', email='john.doe@usu.edu') # Append the new Contributor to the resource's list of Contributors new_resource.metadata.contributors.append(newContributor2) # Instantiate a new Contributor object using a HydroShare user object # First, retrieve HydroShare user object tony = hs.user(11) # Generate a Contributor object from the HydroShare user object newContributor3 = Contributor.from_user(tony) new_resource.metadata.contributors.append(newContributor3) # Save the changes to the resource in HydroShare new_resource.save() # Print the Contributor names print('The list of Contributors includes: ') for Contributor in new_resource.metadata.contributors: print(Contributor.name) Similar to other elements, if you want to remove Contributors, you can modify the local list of Creators and then call the save() function on the resource to save the changes in HydroShare. # Clear the list of Contributors and save to HydroShare new_resource.metadata.contributors.clear() new_resource.save() print(f'Number of remaining Contributors: {len(new_resource.metadata.contributors)}') License and Rights Statement The license under which a Resource is shared can be modified. HydroShare defaults to one of the Creative Commons licenses, but you can change it to a license that meets your needs. The license consists of a rights statement stored as as string and a URL that is a link to a description of the license on the Internet. # Import the required metadata class for a Rights object from hsmodels.schemas.fields import Rights # Set the rights statement and the URL that points to its description new_resource.metadata.rights.statement = ( 'This resource is shared under the Creative Commons ' 'Attribution-NonCommercial-NoDerivatives 4.0 International' '(CC BY-NC-ND 4.0).' ) new_resource.metadata.rights.url = 'https://creativecommons.org/licenses/by-nc-nd/4.0/' # Save the changes to the resource in HydroShare new_resource.save() # Print the rights statement: print(new_resource.metadata.rights.statement) print(new_resource.metadata.rights.url) # You can also use one of the available, pre-generated Rights Statements # available in HydroShare new_resource.metadata.rights = Rights.Creative_Commons_Attribution_CC_BY() new_resource.save() # Print the rights statement: print(new_resource.metadata.rights.statement) print(new_resource.metadata.rights.url) # TODO: Related geospatial features is not implemented yet","title":"Metadata Operations"},{"location":"examples/Metadata_Operations/#hsclient-hydroshare-python-client-resource-metadata-editing-examples","text":"The following code snippets show examples for how to use the hsclient HydroShare Python Client for creating and editing resource level metadata for a HydroShare resource.","title":"hsclient HydroShare Python Client Resource Metadata Editing Examples"},{"location":"examples/Metadata_Operations/#install-the-hsclient-hydroshare-python-client","text":"The hsclient Python Client for HydroShare may not be installed by default in your Python environment, so it has to be installed first before you can work with it. Use the following command to install hsclient via the Python Package Index (PyPi). !pip install hsclient","title":"Install the hsclient HydroShare Python Client"},{"location":"examples/Metadata_Operations/#authenticate-with-hydroshare","text":"Before you start interacting with resources in HydroShare you will need to authenticate. from hsclient import HydroShare hs = HydroShare() hs.sign_in()","title":"Authenticate with HydroShare"},{"location":"examples/Metadata_Operations/#create-a-new-empty-resource","text":"A \"resource\" is a container for your content in HydroShare. Think of it as a \"working directory\" into which you are going to organize the code and/or data you are using and want to share. The following code can be used to create a new, empty resource within which you can create content and metadata. This code creates a new resource in HydroShare. It also creates an in-memory object representation of that resource in your local environmment that you can then manipulate with further code. # Create the new, empty resource new_resource = hs.create() # Get the HydroShare identifier for the new resource res_identifier = new_resource.resource_id print(f'The HydroShare Identifier for your new resource is: {res_identifier}') # Construct a hyperlink to access the HydroShare landing page for the new resource print(f'Your new resource is available at: {new_resource.metadata.url}')","title":"Create a New Empty Resource"},{"location":"examples/Metadata_Operations/#creating-and-editing-resource-metadata-elements","text":"Editing metadata elements for a resource can be done in an object oriented way. You can specify all of the metadata elements in code, which will set their values in memory in your local environment. Values of metadata elements can be edited, removed, or replaced by setting them to a new value, appending new values (in the case where the metadata element accepts a list), or by removing the value entirely. When you are ready to save edits to metadata elements from your local environment to the resource in HydroShare, you can call the save() function on your resource and all of the new metadata values you created/edited will be saved to the resource in HydroShare.","title":"Creating and Editing Resource Metadata Elements"},{"location":"examples/Metadata_Operations/#resource-title-and-abstract","text":"The Title and Abstract metadata elements can be specified as text strings. To modify the Title or Abstract after it has been set, just set them to a different value. # Set the Title for the resource new_resource.metadata.title = 'Resource for Testing the hsclient HydroShare Python Client' # Set the Abstract text for the resource new_resource.metadata.abstract = ( 'This resource was created as a demonstration of using the hsclient ' 'Python Client for HydroShare. Once you have completed all of the ' 'steps in this notebook, you will have a fully populated HydroShare ' 'Resource.' ) # Call the save function to save the metadata edits to HydroShare new_resource.save() # Print the title just added to the resource print(f'Title: {new_resource.metadata.title}') print(f'Abstract: {new_resource.metadata.abstract}')","title":"Resource Title and Abstract"},{"location":"examples/Metadata_Operations/#subject-keywords","text":"Subject keywords can be specified as a Python list of strings. Keywords can be added by creating a list, appending new keywords to the existing list, or by overriding the existing list with a new one. # Create subject keywords for the resource using a list of strings new_resource.metadata.subjects = ['hsclient', 'Python', 'HydroShare', 'Another Keyword'] # New keywords can be appended to the existing list new_resource.metadata.subjects.append('Hydroinformatics') # Keywords can be removed by removing them from the list new_resource.metadata.subjects.remove('Another Keyword') # Save the changes to the resource in HydroShare new_resource.save() # Print the keywords for the resource print('The list of keywords for the resource includes:') for keyword in new_resource.metadata.subjects: print(keyword)","title":"Subject Keywords"},{"location":"examples/Metadata_Operations/#spatial-and-temporal-coverage","text":"Initially the spatial and temporal coverage for a resource are empty. To set them, you have to create a coverage object of the right type and set the spatial or temporal coverage to that object. # Import the required metadata classes for coverage objects from hsmodels.schemas.fields import BoxCoverage, PointCoverage, PeriodCoverage from datetime import datetime # Set the spatial coverage to a BoxCoverage object new_resource.metadata.spatial_coverage = BoxCoverage(name='Logan, Utah', northlimit=41.7910, eastlimit=-111.7664, southlimit=41.6732, westlimit=-111.9079, projection='WGS 84 EPSG:4326', type='box', units='Decimal degrees') # You can remove the spatial coverage element by setting it to None new_resource.metadata.spatial_coverage = None # If you want to set the spatial coverage to a PointCoverage instead new_resource.metadata.spatial_coverage = PointCoverage(name='Logan, Utah', north=41.7371, east=-111.8351, projection='WGS 84 EPSG:4326', type='point', units='Decimal degrees') # Create a beginning and ending date for a time period beginDate = datetime.strptime('2020-12-01T00:00:00Z', '%Y-%m-%dT%H:%M:%S%fZ') endDate = datetime.strptime('2020-12-31T00:00:00Z', '%Y-%m-%dT%H:%M:%S%fZ') # Set the temporal coverage of the resource to a PeriodCoverage object new_resource.metadata.period_coverage = PeriodCoverage(start=beginDate, end=endDate) # Save the changes to the resource in HydroShare new_resource.save() # Print the temporal coverage information print('Temporal Coverage:') print(new_resource.metadata.period_coverage) # Print the spatial coverage information print('\\nSpatial Coverage:') print(new_resource.metadata.spatial_coverage)","title":"Spatial and Temporal Coverage"},{"location":"examples/Metadata_Operations/#additionalextended-metadata","text":"HydroShare allows you to create new, extended metadata elements for a HydroShare resource as key-value pairs. You can add new elements, edit existing elements, or remove these elements. Extended metadata elements are stored in the resource as a Python dictionary. # Add an extended metadata element as a key-value pair new_resource.metadata.additional_metadata['New Element Key'] = 'Text value of new element key.' # Remove an individual key-value pair using its key del new_resource.metadata.additional_metadata['New Element Key'] # Or, you can clear out all additional metadata elements that might exist new_resource.metadata.additional_metadata.clear() # Add multiple key-value pairs at once using a Python dictionary new_resource.metadata.additional_metadata = { 'Observed Variable': 'Oxygen, dissolved', 'Site Location': 'Located on downstream side of river bridge', 'Observation Depth': '1 meter' } # Save the changes to the resource in HydroShare new_resource.save() # Print the extended metadata elements for the resource print('The extended metadata elements for the resource include:') for key, value in new_resource.metadata.additional_metadata.items(): print(f'{key}: {value}')","title":"Additional/Extended Metadata"},{"location":"examples/Metadata_Operations/#related-resources","text":"Related Resources are specified using a string that encodes the citation for the Related Resource along with a relationship type. Because of this, Related Resources are stored as a list of Relation objects. To create a new Related Resource, you have to first instantiate a Relation object and then add it to the list of Related Resources. # Import the required metadata class for a Relation object from hsmodels.schemas.fields import Relation from hsmodels.schemas.enums import RelationType # If you have existing Related Resources, you can remove all of them # by clearing the local list and then saving the resource new_resource.metadata.relations.clear() new_resource.save() # Create a new relation object new_relation = Relation(type=RelationType.isReferencedBy, value=('Bastidas Pacheco, C. J., Horsburgh, J. S., Tracy, ' 'R. J. (2020). A low-cost, open source monitoring ' 'system for collecting high-resolution water use ' 'data on magnetically-driven residential water ' 'meters, Sensors, 20(13), 3655, ' 'https://doi.org/10.3390/s20133655.')) # Append the new Related Resource to the list of Related Resources new_resource.metadata.relations.append(new_relation) # Add another related resource with a different relationship type new_relation = Relation(type=RelationType.references, value=('Mihalevich, B. A., Horsburgh, J. S., Melcher, A. A. (2017). ' 'High-frequency measurements reveal spatial and temporal patterns ' 'of dissolved organic matter in an urban water conveyance, ' 'Environmental Monitoring and Assessment, ' 'https://doi.org/10.1007/s10661-017-6310-y.')) new_resource.metadata.relations.append(new_relation) # Save the changes to the resource in HydroShare new_resource.save() # Print the list of Related Resources print('The list of Related Resources includes:') for relatedResource in new_resource.metadata.relations: print(f'{relatedResource.type.value}: {relatedResource.value}')","title":"Related Resources"},{"location":"examples/Metadata_Operations/#funding-agency-credits","text":"Funding agency information contains multiple attributes when you add a funding agency to a HydroShare resource. You can create multiple funding agency entries for a resource, which get stored as a Python list. # Import the required metadata class for an AwardInfo object from hsmodels.schemas.fields import AwardInfo # If you have existing funding agency information, you can remove all of them # by clearing the local list and then saving the resource new_resource.metadata.awards.clear() new_resource.save() # Create a new AwardInfo object newAwardInfo = AwardInfo(funding_agency_name='National Science Foundation', title=('Collaborative Research: Elements: Advancing Data Science ' 'and Analytics for Water (DSAW)'), number='OAC 1931297', funding_agency_url='https://www.nsf.gov/awardsearch/showAward?AWD_ID=1931297') # Append the new AwardInfo object to the list of funding agencies new_resource.metadata.awards.append(newAwardInfo) # Save the changes to the resource in HydroShare new_resource.save() # Print the AwardInfo print('Funding sources added: ') for award in new_resource.metadata.awards: print(f'Award Title: {award.title}')","title":"Funding Agency Credits"},{"location":"examples/Metadata_Operations/#authors","text":"In HydroShare, an \"Author\" is the same as the Dublin Core metadata \"Creator\" element. The Creator element is a list of creators for the resource. However, the order of the Creators matters. When setting Creator information for the resource, you need to edit the local list of creators so that it reflects the order you want. When you call the save() function on the resource, the Creator information in HydroShare will be updated to match what you set locally. To add a new Creator to the list of Creators, you must first instantiate a Creator object and then add it to the list of Creators for the resource. Creator objects can be created by supplying all of the Creator metadata or by copying from a HydroShare user's profile. # Import the required metadata class for a Creator object from hsmodels.schemas.fields import Creator # Instantiate a new Creator object for a Creator that is a HydroShare user newCreator1 = Creator(name='Jones, Amber Spackman', organization='Utah State University', email='amber.jones@usu.edu', hydroshare_user_id=510) # Append the new Creator to the resource's list of Creators new_resource.metadata.creators.append(newCreator1) # Instantiate a new Creator object for a Creator that is not a HydroShare user newCreator2 = Creator(name='Doe, John A.', organization='Utah Water Research Laboratory', email='john.doe@usu.edu', address='8200 Old Main Hill, Logan, UT 84322-8200', phone='123-456-7890') # Append the new Creator to the resource's list of Creators new_resource.metadata.creators.append(newCreator2) # Instantiate a new Creator object for a Creator that is an organization newCreator3 = Creator(organization='Utah Water Research Laboratory', email='uwrl.receptionist@usu.edu', address='8200 Old Main Hill, Logan, UT 84322-8200', homepage='http://uwrl.usu.edu', phone='435-797-3168 ') # Append the new Creator to the resource's list of Creators new_resource.metadata.creators.append(newCreator3) # Instantiate a new Creator object using a HydroShare user object # First, retrieve HydroShare user object tony = hs.user(11) # Generate a Creator object from a HydroShare user object and append # the new Creator to the resource's list of Creators newCreator4 = Creator.from_user(tony) new_resource.metadata.creators.append(newCreator4) # Save the changes to the resource in HydroShare new_resource.save() # Print the Creator names print('The list of Creators includes: ') for creator in new_resource.metadata.creators: if creator.name is None: print(creator.organization) else: print(creator.name) The previous step leaves the resource with a list of 5 Creators. The order in which Creators appear in the metadata and on the Resource Landing Page is controlled by the order in which they appear in the the Creator list. To update the Creator order, update the order of the Creator list and then save the resource. # Change the order of the Creators in the list creatorOrder = [3, 2, 0, 1, 4] new_resource.metadata.creators = [new_resource.metadata.creators[i] for i in creatorOrder] # Save the changes to the resource in HydroShare new_resource.save() # Print the modified order of the Creator names print('The list of Creators includes: ') for creator in new_resource.metadata.creators: if creator.name is None: print(creator.organization) else: print(creator.name) Creators can be removed by removing them from the local list of creators and then calling the save() function on the resource. Note that there must always be at least one creator. # Example of removing all but the first creator del new_resource.metadata.creators[1:] new_resource.save() print(f'Number of remaining creators: {len(new_resource.metadata.creators)}')","title":"Authors"},{"location":"examples/Metadata_Operations/#contributors","text":"Contributors can be existing HydroShare users or others who do not have HydroShare accounts. Creating and removing contributors is similar to how Creators are handled. Contributors do not have a designated order. # Import the required metadata class for a Contributor object from hsmodels.schemas.fields import Contributor # Instantiate a new Contributor object for a Contributor that is not a HydroShare user newContributor1 = Contributor(name='Horsburgh, Jeffery S.', organization='Utah State University', email='jeff.horsburgh@usu.edu', phone='(435) 797-2946', ORCID='https://orcid.org/0000-0002-0768-3196', address='Utah, US', google_scholar_id='https://scholar.google.com/citations?user=mu4k534AAAAJ&amp;hl=en', homepage='http://jeffh.usu.edu', research_gate_id='https://www.researchgate.net/profile/Jeffery_Horsburgh') # Append the new Contributor to the resource's list of Contributors new_resource.metadata.contributors.append(newContributor1) # Instantiate a new Contributor object for a Contributor that is not a HydroShare user # Not all of the available metadata for a contributor have to be filled out newContributor2 = Contributor(name='Doe, John A.', organization='Utah State University', email='john.doe@usu.edu') # Append the new Contributor to the resource's list of Contributors new_resource.metadata.contributors.append(newContributor2) # Instantiate a new Contributor object using a HydroShare user object # First, retrieve HydroShare user object tony = hs.user(11) # Generate a Contributor object from the HydroShare user object newContributor3 = Contributor.from_user(tony) new_resource.metadata.contributors.append(newContributor3) # Save the changes to the resource in HydroShare new_resource.save() # Print the Contributor names print('The list of Contributors includes: ') for Contributor in new_resource.metadata.contributors: print(Contributor.name) Similar to other elements, if you want to remove Contributors, you can modify the local list of Creators and then call the save() function on the resource to save the changes in HydroShare. # Clear the list of Contributors and save to HydroShare new_resource.metadata.contributors.clear() new_resource.save() print(f'Number of remaining Contributors: {len(new_resource.metadata.contributors)}')","title":"Contributors"},{"location":"examples/Metadata_Operations/#license-and-rights-statement","text":"The license under which a Resource is shared can be modified. HydroShare defaults to one of the Creative Commons licenses, but you can change it to a license that meets your needs. The license consists of a rights statement stored as as string and a URL that is a link to a description of the license on the Internet. # Import the required metadata class for a Rights object from hsmodels.schemas.fields import Rights # Set the rights statement and the URL that points to its description new_resource.metadata.rights.statement = ( 'This resource is shared under the Creative Commons ' 'Attribution-NonCommercial-NoDerivatives 4.0 International' '(CC BY-NC-ND 4.0).' ) new_resource.metadata.rights.url = 'https://creativecommons.org/licenses/by-nc-nd/4.0/' # Save the changes to the resource in HydroShare new_resource.save() # Print the rights statement: print(new_resource.metadata.rights.statement) print(new_resource.metadata.rights.url) # You can also use one of the available, pre-generated Rights Statements # available in HydroShare new_resource.metadata.rights = Rights.Creative_Commons_Attribution_CC_BY() new_resource.save() # Print the rights statement: print(new_resource.metadata.rights.statement) print(new_resource.metadata.rights.url) # TODO: Related geospatial features is not implemented yet","title":"License and Rights Statement"},{"location":"metadata/CSVFileMetadata/","text":"CSV File Aggregation Metadata Properties title (string) : A string containing a descriptive title for the aggregation. Default: null . subjects (array) : A list of keyword strings expressing the topic of the aggregation. Default: [] . Items (string) language (string) : The 3-character string for the language in which the metadata and content are expressed. Default: \"eng\" . additional_metadata (array) : A dictionary of additional metadata elements expressed as key-value pairs. Items (object) : A key-value pair. Default: [] . key (string) value (string) spatial_coverage : An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point. Default: null . Any of : Refer to #/definitions/PointCoverage . : Refer to #/definitions/BoxCoverage . null period_coverage : An object containing the temporal coverage for a aggregation expressed as a date range. Default: null . Any of : Refer to #/definitions/PeriodCoverage . null tableSchema : An object containing metadata for the CSV file content type. All of : Refer to #/definitions/CSVTableSchema . type : A string expressing the aggregation type from the list of HydroShare aggregation types. Default: \"CSV\" . All of : Refer to #/definitions/AggregationType . url (string, format: uri, required) : An object containing the URL of the aggregation. rights : An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared. Default: null . Any of : Refer to #/definitions/Rights . null Definitions AggregationType (string) : Must be one of: [\"Generic\", \"FileSet\", \"GeoRaster\", \"NetCDF\", \"GeoFeature\", \"RefTimeseries\", \"TimeSeries\", \"ModelProgram\", \"ModelInstance\", \"CSV\"] . BoxCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a latitude-longitude bounding box. type (string) : A string containing the type of geographic coverage. Must be one of: [\"box\"] . Must be: \"box\" . Default: \"box\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . northlimit (number, required) : A floating point value containing the constant coordinate for the northernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . eastlimit (number, required) : A floating point value containing the constant coordinate for the easternmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . southlimit (number, required) : A floating point value containing the constant coordinate for the southernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . westlimit (number, required) : A floating point value containing the constant coordinate for the westernmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . units (string, required) : A string containing the units applying to the unlabelled numeric values of northlimit, eastlimit, southlimit, and westlimit. projection (string) : A string containing the name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Default: null . CSVColumnSchema (object) : A class used to represent the metadata associated with a CSV column. column_number (integer, required) : The column number of a column in the CSV file. Exclusive minimum: 0 . title : The title of of a column in the CSV file. Default: null . Any of string null description : The description of a column in the CSV file. Default: null . Any of string null datatype (string, required) : The datatype of a column in the CSV file. Must be one of: [\"string\", \"number\", \"datetime\", \"boolean\"] . CSVColumnsSchema (object) : A class used to represent the metadata associated with all columns of a CSV file. columns (array, required) : A list of objects containing metadata for each of the columns in the CSV file. Items : Refer to #/definitions/CSVColumnSchema . CSVTableSchema (object) : A class used to represent the metadata associated with a CSV file. rows (integer, required) : The number of data rows in the CSV file. Exclusive minimum: 0 . delimiter (string, required) : The delimiter used in the CSV file. Must be one of: [\",\", \";\", \"\\t\"] . table : An object containing metadata for all columns in the CSV file. All of : Refer to #/definitions/CSVColumnsSchema . PeriodCoverage (object) : A class used to represent temporal coverage metadata for a resource or aggregation. name (string) : A string containing a name for the time interval. Default: null . start (string, format: date-time, required) : A datetime object containing the instant corresponding to the commencement of the time interval. end (string, format: date-time, required) : A datetime object containing the instant corresponding to the termination of the time interval. PointCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a point location. type (string) : A string containing the type of geographic coverage. Must be one of: [\"point\"] . Must be: \"point\" . Default: \"point\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . east (number, required) : The coordinate of the point location measured in the east direction. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . north (number, required) : The coordinate of the point location measured in the north direction. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . units (string, required) : The units applying to the unlabelled numeric values of north and east. projection (string, required) : The name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Rights (object) : A class used to represent the rights statement metadata associated with a resource. statement (string, required) : A string containing the text of the license or rights statement. url (string, format: uri, required) : An object containing the URL pointing to a description of the license or rights statement.","title":"CSV"},{"location":"metadata/CSVFileMetadata/#csv-file-aggregation-metadata","text":"","title":"CSV File Aggregation Metadata"},{"location":"metadata/CSVFileMetadata/#properties","text":"title (string) : A string containing a descriptive title for the aggregation. Default: null . subjects (array) : A list of keyword strings expressing the topic of the aggregation. Default: [] . Items (string) language (string) : The 3-character string for the language in which the metadata and content are expressed. Default: \"eng\" . additional_metadata (array) : A dictionary of additional metadata elements expressed as key-value pairs. Items (object) : A key-value pair. Default: [] . key (string) value (string) spatial_coverage : An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point. Default: null . Any of : Refer to #/definitions/PointCoverage . : Refer to #/definitions/BoxCoverage . null period_coverage : An object containing the temporal coverage for a aggregation expressed as a date range. Default: null . Any of : Refer to #/definitions/PeriodCoverage . null tableSchema : An object containing metadata for the CSV file content type. All of : Refer to #/definitions/CSVTableSchema . type : A string expressing the aggregation type from the list of HydroShare aggregation types. Default: \"CSV\" . All of : Refer to #/definitions/AggregationType . url (string, format: uri, required) : An object containing the URL of the aggregation. rights : An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared. Default: null . Any of : Refer to #/definitions/Rights . null","title":"Properties"},{"location":"metadata/CSVFileMetadata/#definitions","text":"AggregationType (string) : Must be one of: [\"Generic\", \"FileSet\", \"GeoRaster\", \"NetCDF\", \"GeoFeature\", \"RefTimeseries\", \"TimeSeries\", \"ModelProgram\", \"ModelInstance\", \"CSV\"] . BoxCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a latitude-longitude bounding box. type (string) : A string containing the type of geographic coverage. Must be one of: [\"box\"] . Must be: \"box\" . Default: \"box\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . northlimit (number, required) : A floating point value containing the constant coordinate for the northernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . eastlimit (number, required) : A floating point value containing the constant coordinate for the easternmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . southlimit (number, required) : A floating point value containing the constant coordinate for the southernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . westlimit (number, required) : A floating point value containing the constant coordinate for the westernmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . units (string, required) : A string containing the units applying to the unlabelled numeric values of northlimit, eastlimit, southlimit, and westlimit. projection (string) : A string containing the name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Default: null . CSVColumnSchema (object) : A class used to represent the metadata associated with a CSV column. column_number (integer, required) : The column number of a column in the CSV file. Exclusive minimum: 0 . title : The title of of a column in the CSV file. Default: null . Any of string null description : The description of a column in the CSV file. Default: null . Any of string null datatype (string, required) : The datatype of a column in the CSV file. Must be one of: [\"string\", \"number\", \"datetime\", \"boolean\"] . CSVColumnsSchema (object) : A class used to represent the metadata associated with all columns of a CSV file. columns (array, required) : A list of objects containing metadata for each of the columns in the CSV file. Items : Refer to #/definitions/CSVColumnSchema . CSVTableSchema (object) : A class used to represent the metadata associated with a CSV file. rows (integer, required) : The number of data rows in the CSV file. Exclusive minimum: 0 . delimiter (string, required) : The delimiter used in the CSV file. Must be one of: [\",\", \";\", \"\\t\"] . table : An object containing metadata for all columns in the CSV file. All of : Refer to #/definitions/CSVColumnsSchema . PeriodCoverage (object) : A class used to represent temporal coverage metadata for a resource or aggregation. name (string) : A string containing a name for the time interval. Default: null . start (string, format: date-time, required) : A datetime object containing the instant corresponding to the commencement of the time interval. end (string, format: date-time, required) : A datetime object containing the instant corresponding to the termination of the time interval. PointCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a point location. type (string) : A string containing the type of geographic coverage. Must be one of: [\"point\"] . Must be: \"point\" . Default: \"point\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . east (number, required) : The coordinate of the point location measured in the east direction. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . north (number, required) : The coordinate of the point location measured in the north direction. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . units (string, required) : The units applying to the unlabelled numeric values of north and east. projection (string, required) : The name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Rights (object) : A class used to represent the rights statement metadata associated with a resource. statement (string, required) : A string containing the text of the license or rights statement. url (string, format: uri, required) : An object containing the URL pointing to a description of the license or rights statement.","title":"Definitions"},{"location":"metadata/FileSetMetadata/","text":"File Set Aggregation Metadata Properties title (string) : A string containing a descriptive title for the aggregation. Default: null . subjects (array) : A list of keyword strings expressing the topic of the aggregation. Default: [] . Items (string) language (string) : The 3-character string for the language in which the metadata and content are expressed. Default: \"eng\" . additional_metadata (array) : A dictionary of additional metadata elements expressed as key-value pairs. Items (object) : A key-value pair. Default: [] . key (string) value (string) spatial_coverage : An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point. Default: null . Any of : Refer to #/definitions/PointCoverage . : Refer to #/definitions/BoxCoverage . null period_coverage : An object containing the temporal coverage for a aggregation expressed as a date range. Default: null . Any of : Refer to #/definitions/PeriodCoverage . null type : A string expressing the aggregation type from the list of HydroShare aggregation types. Default: \"FileSet\" . All of : Refer to #/definitions/AggregationType . url (string, format: uri, required) : An object containing the URL of the aggregation. rights : An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared. Default: null . Any of : Refer to #/definitions/Rights . null Definitions AggregationType (string) : Must be one of: [\"Generic\", \"FileSet\", \"GeoRaster\", \"NetCDF\", \"GeoFeature\", \"RefTimeseries\", \"TimeSeries\", \"ModelProgram\", \"ModelInstance\", \"CSV\"] . BoxCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a latitude-longitude bounding box. type (string) : A string containing the type of geographic coverage. Must be one of: [\"box\"] . Must be: \"box\" . Default: \"box\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . northlimit (number, required) : A floating point value containing the constant coordinate for the northernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . eastlimit (number, required) : A floating point value containing the constant coordinate for the easternmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . southlimit (number, required) : A floating point value containing the constant coordinate for the southernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . westlimit (number, required) : A floating point value containing the constant coordinate for the westernmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . units (string, required) : A string containing the units applying to the unlabelled numeric values of northlimit, eastlimit, southlimit, and westlimit. projection (string) : A string containing the name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Default: null . PeriodCoverage (object) : A class used to represent temporal coverage metadata for a resource or aggregation. name (string) : A string containing a name for the time interval. Default: null . start (string, format: date-time, required) : A datetime object containing the instant corresponding to the commencement of the time interval. end (string, format: date-time, required) : A datetime object containing the instant corresponding to the termination of the time interval. PointCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a point location. type (string) : A string containing the type of geographic coverage. Must be one of: [\"point\"] . Must be: \"point\" . Default: \"point\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . east (number, required) : The coordinate of the point location measured in the east direction. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . north (number, required) : The coordinate of the point location measured in the north direction. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . units (string, required) : The units applying to the unlabelled numeric values of north and east. projection (string, required) : The name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Rights (object) : A class used to represent the rights statement metadata associated with a resource. statement (string, required) : A string containing the text of the license or rights statement. url (string, format: uri, required) : An object containing the URL pointing to a description of the license or rights statement.","title":"File Set"},{"location":"metadata/FileSetMetadata/#file-set-aggregation-metadata","text":"","title":"File Set Aggregation Metadata"},{"location":"metadata/FileSetMetadata/#properties","text":"title (string) : A string containing a descriptive title for the aggregation. Default: null . subjects (array) : A list of keyword strings expressing the topic of the aggregation. Default: [] . Items (string) language (string) : The 3-character string for the language in which the metadata and content are expressed. Default: \"eng\" . additional_metadata (array) : A dictionary of additional metadata elements expressed as key-value pairs. Items (object) : A key-value pair. Default: [] . key (string) value (string) spatial_coverage : An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point. Default: null . Any of : Refer to #/definitions/PointCoverage . : Refer to #/definitions/BoxCoverage . null period_coverage : An object containing the temporal coverage for a aggregation expressed as a date range. Default: null . Any of : Refer to #/definitions/PeriodCoverage . null type : A string expressing the aggregation type from the list of HydroShare aggregation types. Default: \"FileSet\" . All of : Refer to #/definitions/AggregationType . url (string, format: uri, required) : An object containing the URL of the aggregation. rights : An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared. Default: null . Any of : Refer to #/definitions/Rights . null","title":"Properties"},{"location":"metadata/FileSetMetadata/#definitions","text":"AggregationType (string) : Must be one of: [\"Generic\", \"FileSet\", \"GeoRaster\", \"NetCDF\", \"GeoFeature\", \"RefTimeseries\", \"TimeSeries\", \"ModelProgram\", \"ModelInstance\", \"CSV\"] . BoxCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a latitude-longitude bounding box. type (string) : A string containing the type of geographic coverage. Must be one of: [\"box\"] . Must be: \"box\" . Default: \"box\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . northlimit (number, required) : A floating point value containing the constant coordinate for the northernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . eastlimit (number, required) : A floating point value containing the constant coordinate for the easternmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . southlimit (number, required) : A floating point value containing the constant coordinate for the southernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . westlimit (number, required) : A floating point value containing the constant coordinate for the westernmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . units (string, required) : A string containing the units applying to the unlabelled numeric values of northlimit, eastlimit, southlimit, and westlimit. projection (string) : A string containing the name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Default: null . PeriodCoverage (object) : A class used to represent temporal coverage metadata for a resource or aggregation. name (string) : A string containing a name for the time interval. Default: null . start (string, format: date-time, required) : A datetime object containing the instant corresponding to the commencement of the time interval. end (string, format: date-time, required) : A datetime object containing the instant corresponding to the termination of the time interval. PointCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a point location. type (string) : A string containing the type of geographic coverage. Must be one of: [\"point\"] . Must be: \"point\" . Default: \"point\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . east (number, required) : The coordinate of the point location measured in the east direction. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . north (number, required) : The coordinate of the point location measured in the north direction. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . units (string, required) : The units applying to the unlabelled numeric values of north and east. projection (string, required) : The name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Rights (object) : A class used to represent the rights statement metadata associated with a resource. statement (string, required) : A string containing the text of the license or rights statement. url (string, format: uri, required) : An object containing the URL pointing to a description of the license or rights statement.","title":"Definitions"},{"location":"metadata/GeographicFeatureMetadata/","text":"Geographic Feature Aggregation Metadata Properties title (string) : A string containing a descriptive title for the aggregation. Default: null . subjects (array) : A list of keyword strings expressing the topic of the aggregation. Default: [] . Items (string) language (string) : The 3-character string for the language in which the metadata and content are expressed. Default: \"eng\" . additional_metadata (array) : A dictionary of additional metadata elements expressed as key-value pairs. Items (object) : A key-value pair. Default: [] . key (string) value (string) spatial_coverage : An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point. Default: null . Any of : Refer to #/definitions/PointCoverage . : Refer to #/definitions/BoxCoverage . period_coverage : An object containing the temporal coverage for a aggregation expressed as a date range. Default: null . Any of : Refer to #/definitions/PeriodCoverage . null field_information (array) : A list of objects containing information about the fields in the dataset attribute table. Default: [] . Items : Refer to #/definitions/FieldInformation . geometry_information : An object containing information about the geometry of the features in the dataset. All of : Refer to #/definitions/GeometryInformation . spatial_reference : An object containing spatial reference information for the dataset. Default: null . Any of : Refer to #/definitions/BoxSpatialReference . : Refer to #/definitions/PointSpatialReference . type : A string expressing the aggregation type from the list of HydroShare aggregation types. Default: \"GeoFeature\" . All of : Refer to #/definitions/AggregationType . url (string, format: uri, required) : An object containing the URL of the aggregation. rights : An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared. Default: null . Any of : Refer to #/definitions/Rights . null Definitions AggregationType (string) : Must be one of: [\"Generic\", \"FileSet\", \"GeoRaster\", \"NetCDF\", \"GeoFeature\", \"RefTimeseries\", \"TimeSeries\", \"ModelProgram\", \"ModelInstance\", \"CSV\"] . BoxCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a latitude-longitude bounding box. type (string) : A string containing the type of geographic coverage. Must be one of: [\"box\"] . Must be: \"box\" . Default: \"box\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . northlimit (number, required) : A floating point value containing the constant coordinate for the northernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . eastlimit (number, required) : A floating point value containing the constant coordinate for the easternmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . southlimit (number, required) : A floating point value containing the constant coordinate for the southernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . westlimit (number, required) : A floating point value containing the constant coordinate for the westernmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . units (string, required) : A string containing the units applying to the unlabelled numeric values of northlimit, eastlimit, southlimit, and westlimit. projection (string) : A string containing the name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Default: null . BoxSpatialReference (object) : A class used to represent the metadata associated with the spatial reference of a geographic feature or raster aggregation expressed as a bounding box. type (string) : A string containing the type of spatial reference. Must be one of: [\"box\"] . Must be: \"box\" . Default: \"box\" . name (string) : A string containing a name for the place associated with the spatial reference. Default: null . northlimit (number, required) : A floating point value containing the constant coordinate for the northernmost face or edge of the bounding box. eastlimit (number, required) : A floating point value containing the constant coordinate for the easternmost face or edge of the bounding box. southlimit (number, required) : A floating point value containing the constant coordinate for the southernmost face or edge of the bounding box. westlimit (number, required) : A floating point value containing the constant coordinate for the westernmost face or edge of the bounding box. units (string, required) : A string containing the units applying to the unlabelled numeric values of northlimit, eastlimit, southlimit, and westlimit. projection (string) : A string containing the name of the coordinate system used by the spatial reference. Default: null . projection_string (string, required) : A string containing an encoding of the coordinate system parameters. projection_string_type (string) : A string containing a description of the type of encoding for the projection string. Default: null . datum (string) : A string containing the name of the datum used by the coordinate system. Default: null . projection_name (string) : A string containing the name of the coordinate system. Default: null . FieldInformation (object) : A class used to represent the metadata associated with a field in the attribute table for a geographic feature aggregation. field_name (string, required) : A string containing the name of the attribute table field. field_type (string, required) : A string containing the data type of the values in the field. field_type_code : A string value containing a code that indicates the field type. Default: null . Any of string null field_width : An integer value containing the width of the attribute field. Default: null . Any of integer null field_precision : An integer value containing the precision of the attribute field. Default: null . Any of integer null GeometryInformation (object) : A class used to represent the metadata associated with the geometry of a geographic feature aggregation. feature_count (integer) : An integer containing the number of features in the geographic feature aggregation. Default: 0 . geometry_type (string, required) : A string containing the type of features in the geographic feature aggregation. PeriodCoverage (object) : A class used to represent temporal coverage metadata for a resource or aggregation. name (string) : A string containing a name for the time interval. Default: null . start (string, format: date-time, required) : A datetime object containing the instant corresponding to the commencement of the time interval. end (string, format: date-time, required) : A datetime object containing the instant corresponding to the termination of the time interval. PointCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a point location. type (string) : A string containing the type of geographic coverage. Must be one of: [\"point\"] . Must be: \"point\" . Default: \"point\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . east (number, required) : The coordinate of the point location measured in the east direction. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . north (number, required) : The coordinate of the point location measured in the north direction. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . units (string, required) : The units applying to the unlabelled numeric values of north and east. projection (string, required) : The name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. PointSpatialReference (object) : A class used to represent the metadata associated with the spatial reference of a geographic feature or raster aggregation expressed as a point. type (string) : A string containing the type of spatial reference. Must be one of: [\"point\"] . Must be: \"point\" . Default: \"point\" . name (string) : A string containing a name for the place associated with the spatial reference. Default: null . east (number, required) : The coordinate of the point location measured in the east direction. north (number, required) : The coordinate of the point location measured in the north direction. units (string, required) : The units applying to the unlabelled numeric values of north and east. projection (string, required) : A string containing the name of the coordinate system used by the spatial reference. projection_string (string, required) : A string containing an encoding of the coordinate system parameters. projection_string_type (string) : A string containing a description of the type of encoding for the projection string. Default: null . projection_name (string) : A string containing the name of the coordinate system. Default: null . Rights (object) : A class used to represent the rights statement metadata associated with a resource. statement (string, required) : A string containing the text of the license or rights statement. url (string, format: uri, required) : An object containing the URL pointing to a description of the license or rights statement.","title":"Geographic Feature"},{"location":"metadata/GeographicFeatureMetadata/#geographic-feature-aggregation-metadata","text":"","title":"Geographic Feature Aggregation Metadata"},{"location":"metadata/GeographicFeatureMetadata/#properties","text":"title (string) : A string containing a descriptive title for the aggregation. Default: null . subjects (array) : A list of keyword strings expressing the topic of the aggregation. Default: [] . Items (string) language (string) : The 3-character string for the language in which the metadata and content are expressed. Default: \"eng\" . additional_metadata (array) : A dictionary of additional metadata elements expressed as key-value pairs. Items (object) : A key-value pair. Default: [] . key (string) value (string) spatial_coverage : An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point. Default: null . Any of : Refer to #/definitions/PointCoverage . : Refer to #/definitions/BoxCoverage . period_coverage : An object containing the temporal coverage for a aggregation expressed as a date range. Default: null . Any of : Refer to #/definitions/PeriodCoverage . null field_information (array) : A list of objects containing information about the fields in the dataset attribute table. Default: [] . Items : Refer to #/definitions/FieldInformation . geometry_information : An object containing information about the geometry of the features in the dataset. All of : Refer to #/definitions/GeometryInformation . spatial_reference : An object containing spatial reference information for the dataset. Default: null . Any of : Refer to #/definitions/BoxSpatialReference . : Refer to #/definitions/PointSpatialReference . type : A string expressing the aggregation type from the list of HydroShare aggregation types. Default: \"GeoFeature\" . All of : Refer to #/definitions/AggregationType . url (string, format: uri, required) : An object containing the URL of the aggregation. rights : An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared. Default: null . Any of : Refer to #/definitions/Rights . null","title":"Properties"},{"location":"metadata/GeographicFeatureMetadata/#definitions","text":"AggregationType (string) : Must be one of: [\"Generic\", \"FileSet\", \"GeoRaster\", \"NetCDF\", \"GeoFeature\", \"RefTimeseries\", \"TimeSeries\", \"ModelProgram\", \"ModelInstance\", \"CSV\"] . BoxCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a latitude-longitude bounding box. type (string) : A string containing the type of geographic coverage. Must be one of: [\"box\"] . Must be: \"box\" . Default: \"box\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . northlimit (number, required) : A floating point value containing the constant coordinate for the northernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . eastlimit (number, required) : A floating point value containing the constant coordinate for the easternmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . southlimit (number, required) : A floating point value containing the constant coordinate for the southernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . westlimit (number, required) : A floating point value containing the constant coordinate for the westernmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . units (string, required) : A string containing the units applying to the unlabelled numeric values of northlimit, eastlimit, southlimit, and westlimit. projection (string) : A string containing the name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Default: null . BoxSpatialReference (object) : A class used to represent the metadata associated with the spatial reference of a geographic feature or raster aggregation expressed as a bounding box. type (string) : A string containing the type of spatial reference. Must be one of: [\"box\"] . Must be: \"box\" . Default: \"box\" . name (string) : A string containing a name for the place associated with the spatial reference. Default: null . northlimit (number, required) : A floating point value containing the constant coordinate for the northernmost face or edge of the bounding box. eastlimit (number, required) : A floating point value containing the constant coordinate for the easternmost face or edge of the bounding box. southlimit (number, required) : A floating point value containing the constant coordinate for the southernmost face or edge of the bounding box. westlimit (number, required) : A floating point value containing the constant coordinate for the westernmost face or edge of the bounding box. units (string, required) : A string containing the units applying to the unlabelled numeric values of northlimit, eastlimit, southlimit, and westlimit. projection (string) : A string containing the name of the coordinate system used by the spatial reference. Default: null . projection_string (string, required) : A string containing an encoding of the coordinate system parameters. projection_string_type (string) : A string containing a description of the type of encoding for the projection string. Default: null . datum (string) : A string containing the name of the datum used by the coordinate system. Default: null . projection_name (string) : A string containing the name of the coordinate system. Default: null . FieldInformation (object) : A class used to represent the metadata associated with a field in the attribute table for a geographic feature aggregation. field_name (string, required) : A string containing the name of the attribute table field. field_type (string, required) : A string containing the data type of the values in the field. field_type_code : A string value containing a code that indicates the field type. Default: null . Any of string null field_width : An integer value containing the width of the attribute field. Default: null . Any of integer null field_precision : An integer value containing the precision of the attribute field. Default: null . Any of integer null GeometryInformation (object) : A class used to represent the metadata associated with the geometry of a geographic feature aggregation. feature_count (integer) : An integer containing the number of features in the geographic feature aggregation. Default: 0 . geometry_type (string, required) : A string containing the type of features in the geographic feature aggregation. PeriodCoverage (object) : A class used to represent temporal coverage metadata for a resource or aggregation. name (string) : A string containing a name for the time interval. Default: null . start (string, format: date-time, required) : A datetime object containing the instant corresponding to the commencement of the time interval. end (string, format: date-time, required) : A datetime object containing the instant corresponding to the termination of the time interval. PointCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a point location. type (string) : A string containing the type of geographic coverage. Must be one of: [\"point\"] . Must be: \"point\" . Default: \"point\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . east (number, required) : The coordinate of the point location measured in the east direction. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . north (number, required) : The coordinate of the point location measured in the north direction. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . units (string, required) : The units applying to the unlabelled numeric values of north and east. projection (string, required) : The name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. PointSpatialReference (object) : A class used to represent the metadata associated with the spatial reference of a geographic feature or raster aggregation expressed as a point. type (string) : A string containing the type of spatial reference. Must be one of: [\"point\"] . Must be: \"point\" . Default: \"point\" . name (string) : A string containing a name for the place associated with the spatial reference. Default: null . east (number, required) : The coordinate of the point location measured in the east direction. north (number, required) : The coordinate of the point location measured in the north direction. units (string, required) : The units applying to the unlabelled numeric values of north and east. projection (string, required) : A string containing the name of the coordinate system used by the spatial reference. projection_string (string, required) : A string containing an encoding of the coordinate system parameters. projection_string_type (string) : A string containing a description of the type of encoding for the projection string. Default: null . projection_name (string) : A string containing the name of the coordinate system. Default: null . Rights (object) : A class used to represent the rights statement metadata associated with a resource. statement (string, required) : A string containing the text of the license or rights statement. url (string, format: uri, required) : An object containing the URL pointing to a description of the license or rights statement.","title":"Definitions"},{"location":"metadata/GeographicRasterMetadata/","text":"Geographic Raster Aggregation Metadata Properties title (string) : A string containing a descriptive title for the aggregation. Default: null . subjects (array) : A list of keyword strings expressing the topic of the aggregation. Default: [] . Items (string) language (string) : The 3-character string for the language in which the metadata and content are expressed. Default: \"eng\" . additional_metadata (array) : A dictionary of additional metadata elements expressed as key-value pairs. Items (object) : A key-value pair. Default: [] . key (string) value (string) spatial_coverage : An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point. Default: null . Any of : Refer to #/definitions/PointCoverage . : Refer to #/definitions/BoxCoverage . period_coverage : An object containing the temporal coverage for a aggregation expressed as a date range. Default: null . Any of : Refer to #/definitions/PeriodCoverage . null band_information : An object containing information about the bands contained in the raster dataset. All of : Refer to #/definitions/BandInformation . spatial_reference : An object containing spatial reference information for the dataset. Default: null . Any of : Refer to #/definitions/BoxSpatialReference . : Refer to #/definitions/PointSpatialReference . cell_information : An object containing information about the raster grid cells. All of : Refer to #/definitions/CellInformation . type : A string expressing the aggregation type from the list of HydroShare aggregation types. Default: \"GeoRaster\" . All of : Refer to #/definitions/AggregationType . url (string, format: uri, required) : An object containing the URL of the aggregation. rights : An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared. Default: null . Any of : Refer to #/definitions/Rights . null Definitions AggregationType (string) : Must be one of: [\"Generic\", \"FileSet\", \"GeoRaster\", \"NetCDF\", \"GeoFeature\", \"RefTimeseries\", \"TimeSeries\", \"ModelProgram\", \"ModelInstance\", \"CSV\"] . BandInformation (object) : A class used to represent the metadata associated with the raster bands of a geographic raster aggregation. name (string, required) : A string containing the name of the raster band. variable_name : A string containing the name of the variable represented by the raster band. Default: null . Any of string null variable_unit : A string containing the units for the raster band variable. Default: null . Any of string null no_data_value : A string containing the numeric nodata value for the raster band. Default: null . Any of string null maximum_value : A string containing the maximum numeric value for the raster band. Default: null . Any of string null comment : A string containing a comment about the raster band. Default: null . Any of string null method : A string containing a description of the method used to create the raster band data. Default: null . Any of string null minimum_value : A string containing the minimum numerica value for the raster dataset. Default: null . Any of string null BoxCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a latitude-longitude bounding box. type (string) : A string containing the type of geographic coverage. Must be one of: [\"box\"] . Must be: \"box\" . Default: \"box\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . northlimit (number, required) : A floating point value containing the constant coordinate for the northernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . eastlimit (number, required) : A floating point value containing the constant coordinate for the easternmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . southlimit (number, required) : A floating point value containing the constant coordinate for the southernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . westlimit (number, required) : A floating point value containing the constant coordinate for the westernmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . units (string, required) : A string containing the units applying to the unlabelled numeric values of northlimit, eastlimit, southlimit, and westlimit. projection (string) : A string containing the name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Default: null . BoxSpatialReference (object) : A class used to represent the metadata associated with the spatial reference of a geographic feature or raster aggregation expressed as a bounding box. type (string) : A string containing the type of spatial reference. Must be one of: [\"box\"] . Must be: \"box\" . Default: \"box\" . name (string) : A string containing a name for the place associated with the spatial reference. Default: null . northlimit (number, required) : A floating point value containing the constant coordinate for the northernmost face or edge of the bounding box. eastlimit (number, required) : A floating point value containing the constant coordinate for the easternmost face or edge of the bounding box. southlimit (number, required) : A floating point value containing the constant coordinate for the southernmost face or edge of the bounding box. westlimit (number, required) : A floating point value containing the constant coordinate for the westernmost face or edge of the bounding box. units (string, required) : A string containing the units applying to the unlabelled numeric values of northlimit, eastlimit, southlimit, and westlimit. projection (string) : A string containing the name of the coordinate system used by the spatial reference. Default: null . projection_string (string, required) : A string containing an encoding of the coordinate system parameters. projection_string_type (string) : A string containing a description of the type of encoding for the projection string. Default: null . datum (string) : A string containing the name of the datum used by the coordinate system. Default: null . projection_name (string) : A string containing the name of the coordinate system. Default: null . CellInformation (object) : A class used to represent the metadata associated with raster grid cells in geographic raster aggregations. name (string) : Name of the cell information. Default: null . rows (integer) : The integer number of rows in the raster dataset. Default: null . columns (integer) : The integer number of columns in the raster dataset. Default: null . cell_size_x_value (number) : The size of the raster grid cell in the x-direction expressed as a float. Default: null . cell_data_type (string) : The data type of the raster grid cell values. Default: null . cell_size_y_value (number) : The size of the raster grid cell in the y-direction expressed as a float. Default: null . PeriodCoverage (object) : A class used to represent temporal coverage metadata for a resource or aggregation. name (string) : A string containing a name for the time interval. Default: null . start (string, format: date-time, required) : A datetime object containing the instant corresponding to the commencement of the time interval. end (string, format: date-time, required) : A datetime object containing the instant corresponding to the termination of the time interval. PointCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a point location. type (string) : A string containing the type of geographic coverage. Must be one of: [\"point\"] . Must be: \"point\" . Default: \"point\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . east (number, required) : The coordinate of the point location measured in the east direction. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . north (number, required) : The coordinate of the point location measured in the north direction. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . units (string, required) : The units applying to the unlabelled numeric values of north and east. projection (string, required) : The name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. PointSpatialReference (object) : A class used to represent the metadata associated with the spatial reference of a geographic feature or raster aggregation expressed as a point. type (string) : A string containing the type of spatial reference. Must be one of: [\"point\"] . Must be: \"point\" . Default: \"point\" . name (string) : A string containing a name for the place associated with the spatial reference. Default: null . east (number, required) : The coordinate of the point location measured in the east direction. north (number, required) : The coordinate of the point location measured in the north direction. units (string, required) : The units applying to the unlabelled numeric values of north and east. projection (string, required) : A string containing the name of the coordinate system used by the spatial reference. projection_string (string, required) : A string containing an encoding of the coordinate system parameters. projection_string_type (string) : A string containing a description of the type of encoding for the projection string. Default: null . projection_name (string) : A string containing the name of the coordinate system. Default: null . Rights (object) : A class used to represent the rights statement metadata associated with a resource. statement (string, required) : A string containing the text of the license or rights statement. url (string, format: uri, required) : An object containing the URL pointing to a description of the license or rights statement.","title":"Geographic Raster"},{"location":"metadata/GeographicRasterMetadata/#geographic-raster-aggregation-metadata","text":"","title":"Geographic Raster Aggregation Metadata"},{"location":"metadata/GeographicRasterMetadata/#properties","text":"title (string) : A string containing a descriptive title for the aggregation. Default: null . subjects (array) : A list of keyword strings expressing the topic of the aggregation. Default: [] . Items (string) language (string) : The 3-character string for the language in which the metadata and content are expressed. Default: \"eng\" . additional_metadata (array) : A dictionary of additional metadata elements expressed as key-value pairs. Items (object) : A key-value pair. Default: [] . key (string) value (string) spatial_coverage : An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point. Default: null . Any of : Refer to #/definitions/PointCoverage . : Refer to #/definitions/BoxCoverage . period_coverage : An object containing the temporal coverage for a aggregation expressed as a date range. Default: null . Any of : Refer to #/definitions/PeriodCoverage . null band_information : An object containing information about the bands contained in the raster dataset. All of : Refer to #/definitions/BandInformation . spatial_reference : An object containing spatial reference information for the dataset. Default: null . Any of : Refer to #/definitions/BoxSpatialReference . : Refer to #/definitions/PointSpatialReference . cell_information : An object containing information about the raster grid cells. All of : Refer to #/definitions/CellInformation . type : A string expressing the aggregation type from the list of HydroShare aggregation types. Default: \"GeoRaster\" . All of : Refer to #/definitions/AggregationType . url (string, format: uri, required) : An object containing the URL of the aggregation. rights : An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared. Default: null . Any of : Refer to #/definitions/Rights . null","title":"Properties"},{"location":"metadata/GeographicRasterMetadata/#definitions","text":"AggregationType (string) : Must be one of: [\"Generic\", \"FileSet\", \"GeoRaster\", \"NetCDF\", \"GeoFeature\", \"RefTimeseries\", \"TimeSeries\", \"ModelProgram\", \"ModelInstance\", \"CSV\"] . BandInformation (object) : A class used to represent the metadata associated with the raster bands of a geographic raster aggregation. name (string, required) : A string containing the name of the raster band. variable_name : A string containing the name of the variable represented by the raster band. Default: null . Any of string null variable_unit : A string containing the units for the raster band variable. Default: null . Any of string null no_data_value : A string containing the numeric nodata value for the raster band. Default: null . Any of string null maximum_value : A string containing the maximum numeric value for the raster band. Default: null . Any of string null comment : A string containing a comment about the raster band. Default: null . Any of string null method : A string containing a description of the method used to create the raster band data. Default: null . Any of string null minimum_value : A string containing the minimum numerica value for the raster dataset. Default: null . Any of string null BoxCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a latitude-longitude bounding box. type (string) : A string containing the type of geographic coverage. Must be one of: [\"box\"] . Must be: \"box\" . Default: \"box\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . northlimit (number, required) : A floating point value containing the constant coordinate for the northernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . eastlimit (number, required) : A floating point value containing the constant coordinate for the easternmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . southlimit (number, required) : A floating point value containing the constant coordinate for the southernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . westlimit (number, required) : A floating point value containing the constant coordinate for the westernmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . units (string, required) : A string containing the units applying to the unlabelled numeric values of northlimit, eastlimit, southlimit, and westlimit. projection (string) : A string containing the name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Default: null . BoxSpatialReference (object) : A class used to represent the metadata associated with the spatial reference of a geographic feature or raster aggregation expressed as a bounding box. type (string) : A string containing the type of spatial reference. Must be one of: [\"box\"] . Must be: \"box\" . Default: \"box\" . name (string) : A string containing a name for the place associated with the spatial reference. Default: null . northlimit (number, required) : A floating point value containing the constant coordinate for the northernmost face or edge of the bounding box. eastlimit (number, required) : A floating point value containing the constant coordinate for the easternmost face or edge of the bounding box. southlimit (number, required) : A floating point value containing the constant coordinate for the southernmost face or edge of the bounding box. westlimit (number, required) : A floating point value containing the constant coordinate for the westernmost face or edge of the bounding box. units (string, required) : A string containing the units applying to the unlabelled numeric values of northlimit, eastlimit, southlimit, and westlimit. projection (string) : A string containing the name of the coordinate system used by the spatial reference. Default: null . projection_string (string, required) : A string containing an encoding of the coordinate system parameters. projection_string_type (string) : A string containing a description of the type of encoding for the projection string. Default: null . datum (string) : A string containing the name of the datum used by the coordinate system. Default: null . projection_name (string) : A string containing the name of the coordinate system. Default: null . CellInformation (object) : A class used to represent the metadata associated with raster grid cells in geographic raster aggregations. name (string) : Name of the cell information. Default: null . rows (integer) : The integer number of rows in the raster dataset. Default: null . columns (integer) : The integer number of columns in the raster dataset. Default: null . cell_size_x_value (number) : The size of the raster grid cell in the x-direction expressed as a float. Default: null . cell_data_type (string) : The data type of the raster grid cell values. Default: null . cell_size_y_value (number) : The size of the raster grid cell in the y-direction expressed as a float. Default: null . PeriodCoverage (object) : A class used to represent temporal coverage metadata for a resource or aggregation. name (string) : A string containing a name for the time interval. Default: null . start (string, format: date-time, required) : A datetime object containing the instant corresponding to the commencement of the time interval. end (string, format: date-time, required) : A datetime object containing the instant corresponding to the termination of the time interval. PointCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a point location. type (string) : A string containing the type of geographic coverage. Must be one of: [\"point\"] . Must be: \"point\" . Default: \"point\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . east (number, required) : The coordinate of the point location measured in the east direction. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . north (number, required) : The coordinate of the point location measured in the north direction. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . units (string, required) : The units applying to the unlabelled numeric values of north and east. projection (string, required) : The name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. PointSpatialReference (object) : A class used to represent the metadata associated with the spatial reference of a geographic feature or raster aggregation expressed as a point. type (string) : A string containing the type of spatial reference. Must be one of: [\"point\"] . Must be: \"point\" . Default: \"point\" . name (string) : A string containing a name for the place associated with the spatial reference. Default: null . east (number, required) : The coordinate of the point location measured in the east direction. north (number, required) : The coordinate of the point location measured in the north direction. units (string, required) : The units applying to the unlabelled numeric values of north and east. projection (string, required) : A string containing the name of the coordinate system used by the spatial reference. projection_string (string, required) : A string containing an encoding of the coordinate system parameters. projection_string_type (string) : A string containing a description of the type of encoding for the projection string. Default: null . projection_name (string) : A string containing the name of the coordinate system. Default: null . Rights (object) : A class used to represent the rights statement metadata associated with a resource. statement (string, required) : A string containing the text of the license or rights statement. url (string, format: uri, required) : An object containing the URL pointing to a description of the license or rights statement.","title":"Definitions"},{"location":"metadata/ModelInstanceMetadata/","text":"Model Instance Aggregation Metadata Properties title (string) : A string containing a descriptive title for the aggregation. Default: null . subjects (array) : A list of keyword strings expressing the topic of the aggregation. Default: [] . Items (string) language (string) : The 3-character string for the language in which the metadata and content are expressed. Default: \"eng\" . additional_metadata (array) : A dictionary of additional metadata elements expressed as key-value pairs. Items (object) : A key-value pair. Default: [] . key (string) value (string) spatial_coverage : An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point. Default: null . Any of : Refer to #/definitions/PointCoverage . : Refer to #/definitions/BoxCoverage . null period_coverage : An object containing the temporal coverage for a aggregation expressed as a date range. Default: null . Any of : Refer to #/definitions/PeriodCoverage . null includes_model_output (boolean, required) : Indicates whether model output files are included in the aggregation. executed_by : A URL to the Model Program that can be used to execute this model instance. Default: null . Any of string, format: uri null program_schema_json : A URL to the JSON metadata schema for the related model program. Default: null . Any of string, format: uri null program_schema_json_values : A URL to a JSON file containing the metadata values conforming to the JSON metadata schema for the related model program. Default: null . Any of string, format: uri null type : A string expressing the aggregation type from the list of HydroShare aggregation types. Default: \"ModelInstance\" . All of : Refer to #/definitions/AggregationType . url (string, format: uri, required) : An object containing the URL of the aggregation. rights : An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared. Default: null . Any of : Refer to #/definitions/Rights . null Definitions AggregationType (string) : Must be one of: [\"Generic\", \"FileSet\", \"GeoRaster\", \"NetCDF\", \"GeoFeature\", \"RefTimeseries\", \"TimeSeries\", \"ModelProgram\", \"ModelInstance\", \"CSV\"] . BoxCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a latitude-longitude bounding box. type (string) : A string containing the type of geographic coverage. Must be one of: [\"box\"] . Must be: \"box\" . Default: \"box\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . northlimit (number, required) : A floating point value containing the constant coordinate for the northernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . eastlimit (number, required) : A floating point value containing the constant coordinate for the easternmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . southlimit (number, required) : A floating point value containing the constant coordinate for the southernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . westlimit (number, required) : A floating point value containing the constant coordinate for the westernmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . units (string, required) : A string containing the units applying to the unlabelled numeric values of northlimit, eastlimit, southlimit, and westlimit. projection (string) : A string containing the name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Default: null . PeriodCoverage (object) : A class used to represent temporal coverage metadata for a resource or aggregation. name (string) : A string containing a name for the time interval. Default: null . start (string, format: date-time, required) : A datetime object containing the instant corresponding to the commencement of the time interval. end (string, format: date-time, required) : A datetime object containing the instant corresponding to the termination of the time interval. PointCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a point location. type (string) : A string containing the type of geographic coverage. Must be one of: [\"point\"] . Must be: \"point\" . Default: \"point\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . east (number, required) : The coordinate of the point location measured in the east direction. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . north (number, required) : The coordinate of the point location measured in the north direction. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . units (string, required) : The units applying to the unlabelled numeric values of north and east. projection (string, required) : The name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Rights (object) : A class used to represent the rights statement metadata associated with a resource. statement (string, required) : A string containing the text of the license or rights statement. url (string, format: uri, required) : An object containing the URL pointing to a description of the license or rights statement.","title":"Model Instance"},{"location":"metadata/ModelInstanceMetadata/#model-instance-aggregation-metadata","text":"","title":"Model Instance Aggregation Metadata"},{"location":"metadata/ModelInstanceMetadata/#properties","text":"title (string) : A string containing a descriptive title for the aggregation. Default: null . subjects (array) : A list of keyword strings expressing the topic of the aggregation. Default: [] . Items (string) language (string) : The 3-character string for the language in which the metadata and content are expressed. Default: \"eng\" . additional_metadata (array) : A dictionary of additional metadata elements expressed as key-value pairs. Items (object) : A key-value pair. Default: [] . key (string) value (string) spatial_coverage : An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point. Default: null . Any of : Refer to #/definitions/PointCoverage . : Refer to #/definitions/BoxCoverage . null period_coverage : An object containing the temporal coverage for a aggregation expressed as a date range. Default: null . Any of : Refer to #/definitions/PeriodCoverage . null includes_model_output (boolean, required) : Indicates whether model output files are included in the aggregation. executed_by : A URL to the Model Program that can be used to execute this model instance. Default: null . Any of string, format: uri null program_schema_json : A URL to the JSON metadata schema for the related model program. Default: null . Any of string, format: uri null program_schema_json_values : A URL to a JSON file containing the metadata values conforming to the JSON metadata schema for the related model program. Default: null . Any of string, format: uri null type : A string expressing the aggregation type from the list of HydroShare aggregation types. Default: \"ModelInstance\" . All of : Refer to #/definitions/AggregationType . url (string, format: uri, required) : An object containing the URL of the aggregation. rights : An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared. Default: null . Any of : Refer to #/definitions/Rights . null","title":"Properties"},{"location":"metadata/ModelInstanceMetadata/#definitions","text":"AggregationType (string) : Must be one of: [\"Generic\", \"FileSet\", \"GeoRaster\", \"NetCDF\", \"GeoFeature\", \"RefTimeseries\", \"TimeSeries\", \"ModelProgram\", \"ModelInstance\", \"CSV\"] . BoxCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a latitude-longitude bounding box. type (string) : A string containing the type of geographic coverage. Must be one of: [\"box\"] . Must be: \"box\" . Default: \"box\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . northlimit (number, required) : A floating point value containing the constant coordinate for the northernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . eastlimit (number, required) : A floating point value containing the constant coordinate for the easternmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . southlimit (number, required) : A floating point value containing the constant coordinate for the southernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . westlimit (number, required) : A floating point value containing the constant coordinate for the westernmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . units (string, required) : A string containing the units applying to the unlabelled numeric values of northlimit, eastlimit, southlimit, and westlimit. projection (string) : A string containing the name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Default: null . PeriodCoverage (object) : A class used to represent temporal coverage metadata for a resource or aggregation. name (string) : A string containing a name for the time interval. Default: null . start (string, format: date-time, required) : A datetime object containing the instant corresponding to the commencement of the time interval. end (string, format: date-time, required) : A datetime object containing the instant corresponding to the termination of the time interval. PointCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a point location. type (string) : A string containing the type of geographic coverage. Must be one of: [\"point\"] . Must be: \"point\" . Default: \"point\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . east (number, required) : The coordinate of the point location measured in the east direction. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . north (number, required) : The coordinate of the point location measured in the north direction. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . units (string, required) : The units applying to the unlabelled numeric values of north and east. projection (string, required) : The name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Rights (object) : A class used to represent the rights statement metadata associated with a resource. statement (string, required) : A string containing the text of the license or rights statement. url (string, format: uri, required) : An object containing the URL pointing to a description of the license or rights statement.","title":"Definitions"},{"location":"metadata/ModelProgramMetadata/","text":"Model Program Aggregation Metadata Properties title (string) : A string containing a descriptive title for the aggregation. Default: null . subjects (array) : A list of keyword strings expressing the topic of the aggregation. Default: [] . Items (string) language (string) : The 3-character string for the language in which the metadata and content are expressed. Default: \"eng\" . additional_metadata (array) : A dictionary of additional metadata elements expressed as key-value pairs. Items (object) : A key-value pair. Default: [] . key (string) value (string) spatial_coverage : An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point. Default: null . Any of : Refer to #/definitions/PointCoverage . : Refer to #/definitions/BoxCoverage . null period_coverage : An object containing the temporal coverage for a aggregation expressed as a date range. Default: null . Any of : Refer to #/definitions/PeriodCoverage . null version : The software version or build number of the model. Default: null . Any of string null programming_languages (array) : The programming languages that the model is written in. Length must be at most 100. Default: [] . Items (string) operating_systems (array) : Compatible operating systems to setup and run the model. Length must be at most 100. Default: [] . Items (string) release_date : The date that this version of the model was released. Default: null . Any of string, format: date null website : A URL to a website describing the model that is maintained by the model developers. Default: null . Any of string, format: uri null code_repository : A URL to the source code repository for the model code (e.g., git, mercurial, svn, etc.). Default: null . Any of string, format: uri null file_types (array) : File types used by the model program. Default: [] . Items : Refer to #/definitions/ModelProgramFile . program_schema_json : A url to the JSON metadata schema for the model program. Default: null . Any of string, format: uri null type : A string expressing the aggregation type from the list of HydroShare aggregation types. Default: \"ModelProgram\" . All of : Refer to #/definitions/AggregationType . url (string, format: uri, required) : An object containing the URL of the aggregation. rights : An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared. Default: null . Any of : Refer to #/definitions/Rights . null Definitions AggregationType (string) : Must be one of: [\"Generic\", \"FileSet\", \"GeoRaster\", \"NetCDF\", \"GeoFeature\", \"RefTimeseries\", \"TimeSeries\", \"ModelProgram\", \"ModelInstance\", \"CSV\"] . BoxCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a latitude-longitude bounding box. type (string) : A string containing the type of geographic coverage. Must be one of: [\"box\"] . Must be: \"box\" . Default: \"box\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . northlimit (number, required) : A floating point value containing the constant coordinate for the northernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . eastlimit (number, required) : A floating point value containing the constant coordinate for the easternmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . southlimit (number, required) : A floating point value containing the constant coordinate for the southernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . westlimit (number, required) : A floating point value containing the constant coordinate for the westernmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . units (string, required) : A string containing the units applying to the unlabelled numeric values of northlimit, eastlimit, southlimit, and westlimit. projection (string) : A string containing the name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Default: null . ModelProgramFile (object) : A class used to represent the metadata associated with a file used by a model program aggregation. type : The type of the file used by the model program. All of : Refer to #/definitions/ModelProgramFileType . url (string, format: uri, required) : The url of the file used by the model program. ModelProgramFileType (string) : Must be one of: [\"https://www.hydroshare.org/terms/modelReleaseNotes\", \"https://www.hydroshare.org/terms/modelDocumentation\", \"https://www.hydroshare.org/terms/modelSoftware\", \"https://www.hydroshare.org/terms/modelEngine\"] . PeriodCoverage (object) : A class used to represent temporal coverage metadata for a resource or aggregation. name (string) : A string containing a name for the time interval. Default: null . start (string, format: date-time, required) : A datetime object containing the instant corresponding to the commencement of the time interval. end (string, format: date-time, required) : A datetime object containing the instant corresponding to the termination of the time interval. PointCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a point location. type (string) : A string containing the type of geographic coverage. Must be one of: [\"point\"] . Must be: \"point\" . Default: \"point\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . east (number, required) : The coordinate of the point location measured in the east direction. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . north (number, required) : The coordinate of the point location measured in the north direction. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . units (string, required) : The units applying to the unlabelled numeric values of north and east. projection (string, required) : The name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Rights (object) : A class used to represent the rights statement metadata associated with a resource. statement (string, required) : A string containing the text of the license or rights statement. url (string, format: uri, required) : An object containing the URL pointing to a description of the license or rights statement.","title":"Model Program"},{"location":"metadata/ModelProgramMetadata/#model-program-aggregation-metadata","text":"","title":"Model Program Aggregation Metadata"},{"location":"metadata/ModelProgramMetadata/#properties","text":"title (string) : A string containing a descriptive title for the aggregation. Default: null . subjects (array) : A list of keyword strings expressing the topic of the aggregation. Default: [] . Items (string) language (string) : The 3-character string for the language in which the metadata and content are expressed. Default: \"eng\" . additional_metadata (array) : A dictionary of additional metadata elements expressed as key-value pairs. Items (object) : A key-value pair. Default: [] . key (string) value (string) spatial_coverage : An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point. Default: null . Any of : Refer to #/definitions/PointCoverage . : Refer to #/definitions/BoxCoverage . null period_coverage : An object containing the temporal coverage for a aggregation expressed as a date range. Default: null . Any of : Refer to #/definitions/PeriodCoverage . null version : The software version or build number of the model. Default: null . Any of string null programming_languages (array) : The programming languages that the model is written in. Length must be at most 100. Default: [] . Items (string) operating_systems (array) : Compatible operating systems to setup and run the model. Length must be at most 100. Default: [] . Items (string) release_date : The date that this version of the model was released. Default: null . Any of string, format: date null website : A URL to a website describing the model that is maintained by the model developers. Default: null . Any of string, format: uri null code_repository : A URL to the source code repository for the model code (e.g., git, mercurial, svn, etc.). Default: null . Any of string, format: uri null file_types (array) : File types used by the model program. Default: [] . Items : Refer to #/definitions/ModelProgramFile . program_schema_json : A url to the JSON metadata schema for the model program. Default: null . Any of string, format: uri null type : A string expressing the aggregation type from the list of HydroShare aggregation types. Default: \"ModelProgram\" . All of : Refer to #/definitions/AggregationType . url (string, format: uri, required) : An object containing the URL of the aggregation. rights : An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared. Default: null . Any of : Refer to #/definitions/Rights . null","title":"Properties"},{"location":"metadata/ModelProgramMetadata/#definitions","text":"AggregationType (string) : Must be one of: [\"Generic\", \"FileSet\", \"GeoRaster\", \"NetCDF\", \"GeoFeature\", \"RefTimeseries\", \"TimeSeries\", \"ModelProgram\", \"ModelInstance\", \"CSV\"] . BoxCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a latitude-longitude bounding box. type (string) : A string containing the type of geographic coverage. Must be one of: [\"box\"] . Must be: \"box\" . Default: \"box\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . northlimit (number, required) : A floating point value containing the constant coordinate for the northernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . eastlimit (number, required) : A floating point value containing the constant coordinate for the easternmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . southlimit (number, required) : A floating point value containing the constant coordinate for the southernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . westlimit (number, required) : A floating point value containing the constant coordinate for the westernmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . units (string, required) : A string containing the units applying to the unlabelled numeric values of northlimit, eastlimit, southlimit, and westlimit. projection (string) : A string containing the name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Default: null . ModelProgramFile (object) : A class used to represent the metadata associated with a file used by a model program aggregation. type : The type of the file used by the model program. All of : Refer to #/definitions/ModelProgramFileType . url (string, format: uri, required) : The url of the file used by the model program. ModelProgramFileType (string) : Must be one of: [\"https://www.hydroshare.org/terms/modelReleaseNotes\", \"https://www.hydroshare.org/terms/modelDocumentation\", \"https://www.hydroshare.org/terms/modelSoftware\", \"https://www.hydroshare.org/terms/modelEngine\"] . PeriodCoverage (object) : A class used to represent temporal coverage metadata for a resource or aggregation. name (string) : A string containing a name for the time interval. Default: null . start (string, format: date-time, required) : A datetime object containing the instant corresponding to the commencement of the time interval. end (string, format: date-time, required) : A datetime object containing the instant corresponding to the termination of the time interval. PointCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a point location. type (string) : A string containing the type of geographic coverage. Must be one of: [\"point\"] . Must be: \"point\" . Default: \"point\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . east (number, required) : The coordinate of the point location measured in the east direction. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . north (number, required) : The coordinate of the point location measured in the north direction. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . units (string, required) : The units applying to the unlabelled numeric values of north and east. projection (string, required) : The name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Rights (object) : A class used to represent the rights statement metadata associated with a resource. statement (string, required) : A string containing the text of the license or rights statement. url (string, format: uri, required) : An object containing the URL pointing to a description of the license or rights statement.","title":"Definitions"},{"location":"metadata/MultidimensionalMetadata/","text":"Multidimensional Aggregation Metadata Properties title (string) : A string containing a descriptive title for the aggregation. Default: null . subjects (array) : A list of keyword strings expressing the topic of the aggregation. Default: [] . Items (string) language (string) : The 3-character string for the language in which the metadata and content are expressed. Default: \"eng\" . additional_metadata (array) : A dictionary of additional metadata elements expressed as key-value pairs. Items (object) : A key-value pair. Default: [] . key (string) value (string) spatial_coverage : An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point. Default: null . Any of : Refer to #/definitions/PointCoverage . : Refer to #/definitions/BoxCoverage . period_coverage : An object containing the temporal coverage for a aggregation expressed as a date range. Default: null . All of : Refer to #/definitions/PeriodCoverage . variables (array) : A list containing information about the variables for which data are stored in the dataset. Default: [] . Items : Refer to #/definitions/Variable . spatial_reference : An object containing spatial reference information for the dataset. Default: null . All of : Refer to #/definitions/MultidimensionalBoxSpatialReference . type : A string expressing the aggregation type from the list of HydroShare aggregation types. Default: \"NetCDF\" . All of : Refer to #/definitions/AggregationType . url (string, format: uri, required) : An object containing the URL of the aggregation. rights : An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared. Default: null . Any of : Refer to #/definitions/Rights . null Definitions AggregationType (string) : Must be one of: [\"Generic\", \"FileSet\", \"GeoRaster\", \"NetCDF\", \"GeoFeature\", \"RefTimeseries\", \"TimeSeries\", \"ModelProgram\", \"ModelInstance\", \"CSV\"] . BoxCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a latitude-longitude bounding box. type (string) : A string containing the type of geographic coverage. Must be one of: [\"box\"] . Must be: \"box\" . Default: \"box\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . northlimit (number, required) : A floating point value containing the constant coordinate for the northernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . eastlimit (number, required) : A floating point value containing the constant coordinate for the easternmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . southlimit (number, required) : A floating point value containing the constant coordinate for the southernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . westlimit (number, required) : A floating point value containing the constant coordinate for the westernmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . units (string, required) : A string containing the units applying to the unlabelled numeric values of northlimit, eastlimit, southlimit, and westlimit. projection (string) : A string containing the name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Default: null . MultidimensionalBoxSpatialReference (object) : A class used to represent the metadata associated with the spatial reference of a multidimensional aggregation expressed as a bounding box. type (string) : A string containing the type of spatial reference. Must be one of: [\"box\"] . Must be: \"box\" . Default: \"box\" . name (string) : A string containing a name for the place associated with the spatial reference. Default: null . northlimit (number, required) : A floating point value containing the constant coordinate for the northernmost face or edge of the bounding box. eastlimit (number, required) : A floating point value containing the constant coordinate for the easternmost face or edge of the bounding box. southlimit (number, required) : A floating point value containing the constant coordinate for the southernmost face or edge of the bounding box. westlimit (number, required) : A floating point value containing the constant coordinate for the westernmost face or edge of the bounding box. units (string, required) : A string containing the units applying to the unlabelled numeric values of northlimit, eastlimit, southlimit, and westlimit. projection (string) : A string containing the name of the coordinate system used by the spatial reference. Default: null . projection_string (string, required) : A string containing an encoding of the coordinate system parameters. projection_string_type (string) : A string containing a description of the type of encoding for the projection string. Default: null . datum (string) : A string containing the name of the datum used by the coordinate system. Default: null . projection_name (string) : A string containing the name of the coordinate system. Default: null . PeriodCoverage (object) : A class used to represent temporal coverage metadata for a resource or aggregation. name (string) : A string containing a name for the time interval. Default: null . start (string, format: date-time, required) : A datetime object containing the instant corresponding to the commencement of the time interval. end (string, format: date-time, required) : A datetime object containing the instant corresponding to the termination of the time interval. PointCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a point location. type (string) : A string containing the type of geographic coverage. Must be one of: [\"point\"] . Must be: \"point\" . Default: \"point\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . east (number, required) : The coordinate of the point location measured in the east direction. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . north (number, required) : The coordinate of the point location measured in the north direction. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . units (string, required) : The units applying to the unlabelled numeric values of north and east. projection (string, required) : The name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Rights (object) : A class used to represent the rights statement metadata associated with a resource. statement (string, required) : A string containing the text of the license or rights statement. url (string, format: uri, required) : An object containing the URL pointing to a description of the license or rights statement. Variable (object) : A class used to represent the metadata associated with a variable contained within a multidimensional aggregation. name (string, required) : A string containing the name of the variable. unit (string, required) : A string containing the units in which the values for the variable are expressed. type : The data type of the values for the variable. All of : Refer to #/definitions/VariableType . shape (string, required) : A string containing the shape of the variable expressed as a list of dimensions. descriptive_name : A string containing a descriptive name for the variable. Default: null . Any of string null method : A string containing a description of the method used to create the values for the variable. Default: null . Any of string null missing_value : A string containing the value used to indicate missing values for the variable. Default: null . Any of string null VariableType (string) : Must be one of: [\"Char\", \"Byte\", \"Short\", \"Int\", \"Float\", \"Double\", \"Int64\", \"Unsigned Byte\", \"Unsigned Short\", \"Unsigned Int\", \"Unsigned Int64\", \"String\", \"User Defined Type\", \"Unknown\"] .","title":"Multidimensional"},{"location":"metadata/MultidimensionalMetadata/#multidimensional-aggregation-metadata","text":"","title":"Multidimensional Aggregation Metadata"},{"location":"metadata/MultidimensionalMetadata/#properties","text":"title (string) : A string containing a descriptive title for the aggregation. Default: null . subjects (array) : A list of keyword strings expressing the topic of the aggregation. Default: [] . Items (string) language (string) : The 3-character string for the language in which the metadata and content are expressed. Default: \"eng\" . additional_metadata (array) : A dictionary of additional metadata elements expressed as key-value pairs. Items (object) : A key-value pair. Default: [] . key (string) value (string) spatial_coverage : An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point. Default: null . Any of : Refer to #/definitions/PointCoverage . : Refer to #/definitions/BoxCoverage . period_coverage : An object containing the temporal coverage for a aggregation expressed as a date range. Default: null . All of : Refer to #/definitions/PeriodCoverage . variables (array) : A list containing information about the variables for which data are stored in the dataset. Default: [] . Items : Refer to #/definitions/Variable . spatial_reference : An object containing spatial reference information for the dataset. Default: null . All of : Refer to #/definitions/MultidimensionalBoxSpatialReference . type : A string expressing the aggregation type from the list of HydroShare aggregation types. Default: \"NetCDF\" . All of : Refer to #/definitions/AggregationType . url (string, format: uri, required) : An object containing the URL of the aggregation. rights : An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared. Default: null . Any of : Refer to #/definitions/Rights . null","title":"Properties"},{"location":"metadata/MultidimensionalMetadata/#definitions","text":"AggregationType (string) : Must be one of: [\"Generic\", \"FileSet\", \"GeoRaster\", \"NetCDF\", \"GeoFeature\", \"RefTimeseries\", \"TimeSeries\", \"ModelProgram\", \"ModelInstance\", \"CSV\"] . BoxCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a latitude-longitude bounding box. type (string) : A string containing the type of geographic coverage. Must be one of: [\"box\"] . Must be: \"box\" . Default: \"box\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . northlimit (number, required) : A floating point value containing the constant coordinate for the northernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . eastlimit (number, required) : A floating point value containing the constant coordinate for the easternmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . southlimit (number, required) : A floating point value containing the constant coordinate for the southernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . westlimit (number, required) : A floating point value containing the constant coordinate for the westernmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . units (string, required) : A string containing the units applying to the unlabelled numeric values of northlimit, eastlimit, southlimit, and westlimit. projection (string) : A string containing the name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Default: null . MultidimensionalBoxSpatialReference (object) : A class used to represent the metadata associated with the spatial reference of a multidimensional aggregation expressed as a bounding box. type (string) : A string containing the type of spatial reference. Must be one of: [\"box\"] . Must be: \"box\" . Default: \"box\" . name (string) : A string containing a name for the place associated with the spatial reference. Default: null . northlimit (number, required) : A floating point value containing the constant coordinate for the northernmost face or edge of the bounding box. eastlimit (number, required) : A floating point value containing the constant coordinate for the easternmost face or edge of the bounding box. southlimit (number, required) : A floating point value containing the constant coordinate for the southernmost face or edge of the bounding box. westlimit (number, required) : A floating point value containing the constant coordinate for the westernmost face or edge of the bounding box. units (string, required) : A string containing the units applying to the unlabelled numeric values of northlimit, eastlimit, southlimit, and westlimit. projection (string) : A string containing the name of the coordinate system used by the spatial reference. Default: null . projection_string (string, required) : A string containing an encoding of the coordinate system parameters. projection_string_type (string) : A string containing a description of the type of encoding for the projection string. Default: null . datum (string) : A string containing the name of the datum used by the coordinate system. Default: null . projection_name (string) : A string containing the name of the coordinate system. Default: null . PeriodCoverage (object) : A class used to represent temporal coverage metadata for a resource or aggregation. name (string) : A string containing a name for the time interval. Default: null . start (string, format: date-time, required) : A datetime object containing the instant corresponding to the commencement of the time interval. end (string, format: date-time, required) : A datetime object containing the instant corresponding to the termination of the time interval. PointCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a point location. type (string) : A string containing the type of geographic coverage. Must be one of: [\"point\"] . Must be: \"point\" . Default: \"point\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . east (number, required) : The coordinate of the point location measured in the east direction. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . north (number, required) : The coordinate of the point location measured in the north direction. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . units (string, required) : The units applying to the unlabelled numeric values of north and east. projection (string, required) : The name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Rights (object) : A class used to represent the rights statement metadata associated with a resource. statement (string, required) : A string containing the text of the license or rights statement. url (string, format: uri, required) : An object containing the URL pointing to a description of the license or rights statement. Variable (object) : A class used to represent the metadata associated with a variable contained within a multidimensional aggregation. name (string, required) : A string containing the name of the variable. unit (string, required) : A string containing the units in which the values for the variable are expressed. type : The data type of the values for the variable. All of : Refer to #/definitions/VariableType . shape (string, required) : A string containing the shape of the variable expressed as a list of dimensions. descriptive_name : A string containing a descriptive name for the variable. Default: null . Any of string null method : A string containing a description of the method used to create the values for the variable. Default: null . Any of string null missing_value : A string containing the value used to indicate missing values for the variable. Default: null . Any of string null VariableType (string) : Must be one of: [\"Char\", \"Byte\", \"Short\", \"Int\", \"Float\", \"Double\", \"Int64\", \"Unsigned Byte\", \"Unsigned Short\", \"Unsigned Int\", \"Unsigned Int64\", \"String\", \"User Defined Type\", \"Unknown\"] .","title":"Definitions"},{"location":"metadata/ReferencedTimeSeriesMetadata/","text":"Referenced Time Series Aggregation Metadata Properties title (string) : A string containing a descriptive title for the aggregation. Default: null . subjects (array) : A list of keyword strings expressing the topic of the aggregation. Default: [] . Items (string) language (string) : The 3-character string for the language in which the metadata and content are expressed. Default: \"eng\" . additional_metadata (array) : A dictionary of additional metadata elements expressed as key-value pairs. Items (object) : A key-value pair. Default: [] . key (string) value (string) spatial_coverage : An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point. Default: null . Any of : Refer to #/definitions/PointCoverage . : Refer to #/definitions/BoxCoverage . null period_coverage : An object containing the temporal coverage for a aggregation expressed as a date range. Default: null . Any of : Refer to #/definitions/PeriodCoverage . null type : A string expressing the aggregation type from the list of HydroShare aggregation types. Default: \"RefTimeseries\" . All of : Refer to #/definitions/AggregationType . url (string, format: uri, required) : An object containing the URL of the aggregation. rights : An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared. Default: null . Any of : Refer to #/definitions/Rights . null Definitions AggregationType (string) : Must be one of: [\"Generic\", \"FileSet\", \"GeoRaster\", \"NetCDF\", \"GeoFeature\", \"RefTimeseries\", \"TimeSeries\", \"ModelProgram\", \"ModelInstance\", \"CSV\"] . BoxCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a latitude-longitude bounding box. type (string) : A string containing the type of geographic coverage. Must be one of: [\"box\"] . Must be: \"box\" . Default: \"box\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . northlimit (number, required) : A floating point value containing the constant coordinate for the northernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . eastlimit (number, required) : A floating point value containing the constant coordinate for the easternmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . southlimit (number, required) : A floating point value containing the constant coordinate for the southernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . westlimit (number, required) : A floating point value containing the constant coordinate for the westernmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . units (string, required) : A string containing the units applying to the unlabelled numeric values of northlimit, eastlimit, southlimit, and westlimit. projection (string) : A string containing the name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Default: null . PeriodCoverage (object) : A class used to represent temporal coverage metadata for a resource or aggregation. name (string) : A string containing a name for the time interval. Default: null . start (string, format: date-time, required) : A datetime object containing the instant corresponding to the commencement of the time interval. end (string, format: date-time, required) : A datetime object containing the instant corresponding to the termination of the time interval. PointCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a point location. type (string) : A string containing the type of geographic coverage. Must be one of: [\"point\"] . Must be: \"point\" . Default: \"point\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . east (number, required) : The coordinate of the point location measured in the east direction. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . north (number, required) : The coordinate of the point location measured in the north direction. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . units (string, required) : The units applying to the unlabelled numeric values of north and east. projection (string, required) : The name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Rights (object) : A class used to represent the rights statement metadata associated with a resource. statement (string, required) : A string containing the text of the license or rights statement. url (string, format: uri, required) : An object containing the URL pointing to a description of the license or rights statement.","title":"Referenced Time Series"},{"location":"metadata/ReferencedTimeSeriesMetadata/#referenced-time-series-aggregation-metadata","text":"","title":"Referenced Time Series Aggregation Metadata"},{"location":"metadata/ReferencedTimeSeriesMetadata/#properties","text":"title (string) : A string containing a descriptive title for the aggregation. Default: null . subjects (array) : A list of keyword strings expressing the topic of the aggregation. Default: [] . Items (string) language (string) : The 3-character string for the language in which the metadata and content are expressed. Default: \"eng\" . additional_metadata (array) : A dictionary of additional metadata elements expressed as key-value pairs. Items (object) : A key-value pair. Default: [] . key (string) value (string) spatial_coverage : An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point. Default: null . Any of : Refer to #/definitions/PointCoverage . : Refer to #/definitions/BoxCoverage . null period_coverage : An object containing the temporal coverage for a aggregation expressed as a date range. Default: null . Any of : Refer to #/definitions/PeriodCoverage . null type : A string expressing the aggregation type from the list of HydroShare aggregation types. Default: \"RefTimeseries\" . All of : Refer to #/definitions/AggregationType . url (string, format: uri, required) : An object containing the URL of the aggregation. rights : An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared. Default: null . Any of : Refer to #/definitions/Rights . null","title":"Properties"},{"location":"metadata/ReferencedTimeSeriesMetadata/#definitions","text":"AggregationType (string) : Must be one of: [\"Generic\", \"FileSet\", \"GeoRaster\", \"NetCDF\", \"GeoFeature\", \"RefTimeseries\", \"TimeSeries\", \"ModelProgram\", \"ModelInstance\", \"CSV\"] . BoxCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a latitude-longitude bounding box. type (string) : A string containing the type of geographic coverage. Must be one of: [\"box\"] . Must be: \"box\" . Default: \"box\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . northlimit (number, required) : A floating point value containing the constant coordinate for the northernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . eastlimit (number, required) : A floating point value containing the constant coordinate for the easternmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . southlimit (number, required) : A floating point value containing the constant coordinate for the southernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . westlimit (number, required) : A floating point value containing the constant coordinate for the westernmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . units (string, required) : A string containing the units applying to the unlabelled numeric values of northlimit, eastlimit, southlimit, and westlimit. projection (string) : A string containing the name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Default: null . PeriodCoverage (object) : A class used to represent temporal coverage metadata for a resource or aggregation. name (string) : A string containing a name for the time interval. Default: null . start (string, format: date-time, required) : A datetime object containing the instant corresponding to the commencement of the time interval. end (string, format: date-time, required) : A datetime object containing the instant corresponding to the termination of the time interval. PointCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a point location. type (string) : A string containing the type of geographic coverage. Must be one of: [\"point\"] . Must be: \"point\" . Default: \"point\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . east (number, required) : The coordinate of the point location measured in the east direction. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . north (number, required) : The coordinate of the point location measured in the north direction. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . units (string, required) : The units applying to the unlabelled numeric values of north and east. projection (string, required) : The name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Rights (object) : A class used to represent the rights statement metadata associated with a resource. statement (string, required) : A string containing the text of the license or rights statement. url (string, format: uri, required) : An object containing the URL pointing to a description of the license or rights statement.","title":"Definitions"},{"location":"metadata/ResourceMetadata/","text":"Resource Metadata Properties title (string, required) : A string containing the name given to a resource. abstract (string) : A string containing a summary of a resource. Default: null . language (string) : A 3-character string for the language in which the metadata and content of a resource are expressed. Default: \"eng\" . subjects (array) : A list of keyword strings expressing the topic of a resource. Default: [] . Items (string) creators (array) : A list of Creator objects indicating the entities responsible for creating a resource. Default: [] . Items : Refer to #/definitions/Creator . contributors (array) : A list of Contributor objects indicating the entities that contributed to a resource. Default: [] . Items : Refer to #/definitions/Contributor . relations (array) : A list of Relation objects representing resources related to a described resource. Default: [] . Items : Refer to #/definitions/Relation . additional_metadata (array) : A dictionary containing key-value pair metadata associated with a resource. Items (object) : A key-value pair. Default: [] . key (string) value (string) rights : An object containing information about rights held in an over a resource. All of : Refer to #/definitions/Rights . awards (array) : A list of objects containing information about the funding agencies and awards associated with a resource. Default: [] . Items : Refer to #/definitions/AwardInfo . spatial_coverage : An object containing information about the spatial topic of a resource, the spatial applicability of a resource, or jurisdiction under with a resource is relevant. Default: null . Any of : Refer to #/definitions/PointCoverage . : Refer to #/definitions/BoxCoverage . null period_coverage : An object containing information about the temporal topic or applicability of a resource. Default: null . Any of : Refer to #/definitions/PeriodCoverage . null publisher : An object containing information about the publisher of a resource. Default: null . All of : Refer to #/definitions/Publisher . citation (string) : A string containing the biblilographic citation for a resource. Default: null . url (string, format: uri, required) : An object containing the URL for a resource. identifier (string, format: uri, required) : An object containing the URL-encoded unique identifier for a resource. created (string, format: date-time) : A datetime object containing the instant associated with when a resource was created. modified (string, format: date-time) : A datetime object containing the instant associated with when a resource was last modified. review_started (string, format: date-time) : A datetime object containing the instant associated with when metadata review started on a resource. Default: null . published (string, format: date-time) : A datetime object containing the instant associated with when a resource was published. Default: null . type (string) : An object containing a URL that points to the HydroShare resource type selected from the hsterms namespace. Must be one of: [\"CompositeResource\"] . Must be: \"CompositeResource\" . Default: \"CompositeResource\" . Definitions AwardInfo (object) : A class used to represent the metadata associated with funding agency credits for a resource. funding_agency_name (string, required) : A string containing the name of the funding agency or organization. title : A string containing the title of the project or award. Default: null . Any of string null number : A string containing the award number or other identifier. Default: null . Any of string null funding_agency_url : An object containing a URL pointing to a website describing the funding award. Default: null . Any of string, format: uri null BoxCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a latitude-longitude bounding box. type (string) : A string containing the type of geographic coverage. Must be one of: [\"box\"] . Must be: \"box\" . Default: \"box\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . northlimit (number, required) : A floating point value containing the constant coordinate for the northernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . eastlimit (number, required) : A floating point value containing the constant coordinate for the easternmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . southlimit (number, required) : A floating point value containing the constant coordinate for the southernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . westlimit (number, required) : A floating point value containing the constant coordinate for the westernmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . units (string, required) : A string containing the units applying to the unlabelled numeric values of northlimit, eastlimit, southlimit, and westlimit. projection (string) : A string containing the name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Default: null . Contributor (object) : A class used to represent the metadata associated with a contributor to a resource. name (string) : A string containing the name of the contributor. Default: null . phone : A string containing a phone number for the contributor. Default: null . Any of string null address : A string containing an address for the contributor. Default: null . Any of string null organization : A string containing the name of the organization with which the contributor is affiliated. Default: null . Any of string null email : A string containing an email address for the contributor. Default: null . Any of string, format: email null homepage : An object containing the URL for website associated with the contributor. Default: null . Any of string, format: uri null hydroshare_user_id : An integer containing the Hydroshare user ID. Default: null . Any of integer null identifiers (object) : A dictionary containing identifier types and URL links to alternative identiers for the contributor. Can contain additional properties. Default: {} . Additional properties (string, format: uri) Creator (object) : A class used to represent the metadata associated with a creator of a resource. name (string) : A string containing the name of the creator. Default: null . phone : A string containing a phone number for the creator. Default: null . Any of string null address : A string containing an address for the creator. Default: null . Any of string null organization : A string containing the name of the organization with which the creator is affiliated. Default: null . Any of string null email : A string containing an email address for the creator. Default: null . Any of string, format: email null homepage : An object containing the URL for website associated with the creator. Default: null . Any of string, format: uri null creator_order : An integer to order creators. Default: null . Any of integer null hydroshare_user_id : An integer containing the Hydroshare user ID. Default: null . Any of integer null identifiers (object) : A dictionary containing identifier types and URL links to alternative identifiers for the creator. Can contain additional properties. Default: {} . Additional properties (string, format: uri) PeriodCoverage (object) : A class used to represent temporal coverage metadata for a resource or aggregation. name (string) : A string containing a name for the time interval. Default: null . start (string, format: date-time, required) : A datetime object containing the instant corresponding to the commencement of the time interval. end (string, format: date-time, required) : A datetime object containing the instant corresponding to the termination of the time interval. PointCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a point location. type (string) : A string containing the type of geographic coverage. Must be one of: [\"point\"] . Must be: \"point\" . Default: \"point\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . east (number, required) : The coordinate of the point location measured in the east direction. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . north (number, required) : The coordinate of the point location measured in the north direction. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . units (string, required) : The units applying to the unlabelled numeric values of north and east. projection (string, required) : The name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Publisher (object) : A class used to represent the metadata associated with the publisher of a resource. name (string, required) : A string containing the name of the publisher. url (string, format: uri, required) : An object containing a URL that points to the publisher website. Relation (object) : A class used to represent the metadata associated with a resource related to the resource being described. type : The type of relationship with the related resource. All of : Refer to #/definitions/RelationType . value (string, required) : String expressing the Full text citation, URL link for, or description of the related resource. RelationType (string) : Must be one of: [\"The content of this resource is part of\", \"This resource includes\", \"The content of this resource can be executed by\", \"The content of this resource was created by a related App or software program\", \"This resource updates and replaces a previous version\", \"This resource has been replaced by a newer version\", \"This resource is described by\", \"This resource conforms to established standard described by\", \"This resource has a related resource in another format\", \"This resource is a different format of\", \"This resource is required by\", \"This resource requires\", \"This resource is referenced by\", \"The content of this resource references\", \"This resource replaces\", \"The content of this resource is derived from\", \"The content of this resource is similar to\"] . Rights (object) : A class used to represent the rights statement metadata associated with a resource. statement (string, required) : A string containing the text of the license or rights statement. url (string, format: uri, required) : An object containing the URL pointing to a description of the license or rights statement.","title":"Resource"},{"location":"metadata/ResourceMetadata/#resource-metadata","text":"","title":"Resource Metadata"},{"location":"metadata/ResourceMetadata/#properties","text":"title (string, required) : A string containing the name given to a resource. abstract (string) : A string containing a summary of a resource. Default: null . language (string) : A 3-character string for the language in which the metadata and content of a resource are expressed. Default: \"eng\" . subjects (array) : A list of keyword strings expressing the topic of a resource. Default: [] . Items (string) creators (array) : A list of Creator objects indicating the entities responsible for creating a resource. Default: [] . Items : Refer to #/definitions/Creator . contributors (array) : A list of Contributor objects indicating the entities that contributed to a resource. Default: [] . Items : Refer to #/definitions/Contributor . relations (array) : A list of Relation objects representing resources related to a described resource. Default: [] . Items : Refer to #/definitions/Relation . additional_metadata (array) : A dictionary containing key-value pair metadata associated with a resource. Items (object) : A key-value pair. Default: [] . key (string) value (string) rights : An object containing information about rights held in an over a resource. All of : Refer to #/definitions/Rights . awards (array) : A list of objects containing information about the funding agencies and awards associated with a resource. Default: [] . Items : Refer to #/definitions/AwardInfo . spatial_coverage : An object containing information about the spatial topic of a resource, the spatial applicability of a resource, or jurisdiction under with a resource is relevant. Default: null . Any of : Refer to #/definitions/PointCoverage . : Refer to #/definitions/BoxCoverage . null period_coverage : An object containing information about the temporal topic or applicability of a resource. Default: null . Any of : Refer to #/definitions/PeriodCoverage . null publisher : An object containing information about the publisher of a resource. Default: null . All of : Refer to #/definitions/Publisher . citation (string) : A string containing the biblilographic citation for a resource. Default: null . url (string, format: uri, required) : An object containing the URL for a resource. identifier (string, format: uri, required) : An object containing the URL-encoded unique identifier for a resource. created (string, format: date-time) : A datetime object containing the instant associated with when a resource was created. modified (string, format: date-time) : A datetime object containing the instant associated with when a resource was last modified. review_started (string, format: date-time) : A datetime object containing the instant associated with when metadata review started on a resource. Default: null . published (string, format: date-time) : A datetime object containing the instant associated with when a resource was published. Default: null . type (string) : An object containing a URL that points to the HydroShare resource type selected from the hsterms namespace. Must be one of: [\"CompositeResource\"] . Must be: \"CompositeResource\" . Default: \"CompositeResource\" .","title":"Properties"},{"location":"metadata/ResourceMetadata/#definitions","text":"AwardInfo (object) : A class used to represent the metadata associated with funding agency credits for a resource. funding_agency_name (string, required) : A string containing the name of the funding agency or organization. title : A string containing the title of the project or award. Default: null . Any of string null number : A string containing the award number or other identifier. Default: null . Any of string null funding_agency_url : An object containing a URL pointing to a website describing the funding award. Default: null . Any of string, format: uri null BoxCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a latitude-longitude bounding box. type (string) : A string containing the type of geographic coverage. Must be one of: [\"box\"] . Must be: \"box\" . Default: \"box\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . northlimit (number, required) : A floating point value containing the constant coordinate for the northernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . eastlimit (number, required) : A floating point value containing the constant coordinate for the easternmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . southlimit (number, required) : A floating point value containing the constant coordinate for the southernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . westlimit (number, required) : A floating point value containing the constant coordinate for the westernmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . units (string, required) : A string containing the units applying to the unlabelled numeric values of northlimit, eastlimit, southlimit, and westlimit. projection (string) : A string containing the name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Default: null . Contributor (object) : A class used to represent the metadata associated with a contributor to a resource. name (string) : A string containing the name of the contributor. Default: null . phone : A string containing a phone number for the contributor. Default: null . Any of string null address : A string containing an address for the contributor. Default: null . Any of string null organization : A string containing the name of the organization with which the contributor is affiliated. Default: null . Any of string null email : A string containing an email address for the contributor. Default: null . Any of string, format: email null homepage : An object containing the URL for website associated with the contributor. Default: null . Any of string, format: uri null hydroshare_user_id : An integer containing the Hydroshare user ID. Default: null . Any of integer null identifiers (object) : A dictionary containing identifier types and URL links to alternative identiers for the contributor. Can contain additional properties. Default: {} . Additional properties (string, format: uri) Creator (object) : A class used to represent the metadata associated with a creator of a resource. name (string) : A string containing the name of the creator. Default: null . phone : A string containing a phone number for the creator. Default: null . Any of string null address : A string containing an address for the creator. Default: null . Any of string null organization : A string containing the name of the organization with which the creator is affiliated. Default: null . Any of string null email : A string containing an email address for the creator. Default: null . Any of string, format: email null homepage : An object containing the URL for website associated with the creator. Default: null . Any of string, format: uri null creator_order : An integer to order creators. Default: null . Any of integer null hydroshare_user_id : An integer containing the Hydroshare user ID. Default: null . Any of integer null identifiers (object) : A dictionary containing identifier types and URL links to alternative identifiers for the creator. Can contain additional properties. Default: {} . Additional properties (string, format: uri) PeriodCoverage (object) : A class used to represent temporal coverage metadata for a resource or aggregation. name (string) : A string containing a name for the time interval. Default: null . start (string, format: date-time, required) : A datetime object containing the instant corresponding to the commencement of the time interval. end (string, format: date-time, required) : A datetime object containing the instant corresponding to the termination of the time interval. PointCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a point location. type (string) : A string containing the type of geographic coverage. Must be one of: [\"point\"] . Must be: \"point\" . Default: \"point\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . east (number, required) : The coordinate of the point location measured in the east direction. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . north (number, required) : The coordinate of the point location measured in the north direction. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . units (string, required) : The units applying to the unlabelled numeric values of north and east. projection (string, required) : The name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Publisher (object) : A class used to represent the metadata associated with the publisher of a resource. name (string, required) : A string containing the name of the publisher. url (string, format: uri, required) : An object containing a URL that points to the publisher website. Relation (object) : A class used to represent the metadata associated with a resource related to the resource being described. type : The type of relationship with the related resource. All of : Refer to #/definitions/RelationType . value (string, required) : String expressing the Full text citation, URL link for, or description of the related resource. RelationType (string) : Must be one of: [\"The content of this resource is part of\", \"This resource includes\", \"The content of this resource can be executed by\", \"The content of this resource was created by a related App or software program\", \"This resource updates and replaces a previous version\", \"This resource has been replaced by a newer version\", \"This resource is described by\", \"This resource conforms to established standard described by\", \"This resource has a related resource in another format\", \"This resource is a different format of\", \"This resource is required by\", \"This resource requires\", \"This resource is referenced by\", \"The content of this resource references\", \"This resource replaces\", \"The content of this resource is derived from\", \"The content of this resource is similar to\"] . Rights (object) : A class used to represent the rights statement metadata associated with a resource. statement (string, required) : A string containing the text of the license or rights statement. url (string, format: uri, required) : An object containing the URL pointing to a description of the license or rights statement.","title":"Definitions"},{"location":"metadata/SingleFileMetadata/","text":"Single File Aggregation Metadata Properties title (string) : A string containing a descriptive title for the aggregation. Default: null . subjects (array) : A list of keyword strings expressing the topic of the aggregation. Default: [] . Items (string) language (string) : The 3-character string for the language in which the metadata and content are expressed. Default: \"eng\" . additional_metadata (array) : A dictionary of additional metadata elements expressed as key-value pairs. Items (object) : A key-value pair. Default: [] . key (string) value (string) spatial_coverage : An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point. Default: null . Any of : Refer to #/definitions/PointCoverage . : Refer to #/definitions/BoxCoverage . null period_coverage : An object containing the temporal coverage for a aggregation expressed as a date range. Default: null . Any of : Refer to #/definitions/PeriodCoverage . null type : A string expressing the aggregation type from the list of HydroShare aggregation types. Default: \"Generic\" . All of : Refer to #/definitions/AggregationType . url (string, format: uri, required) : An object containing the URL of the aggregation. rights : An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared. Default: null . Any of : Refer to #/definitions/Rights . null Definitions AggregationType (string) : Must be one of: [\"Generic\", \"FileSet\", \"GeoRaster\", \"NetCDF\", \"GeoFeature\", \"RefTimeseries\", \"TimeSeries\", \"ModelProgram\", \"ModelInstance\", \"CSV\"] . BoxCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a latitude-longitude bounding box. type (string) : A string containing the type of geographic coverage. Must be one of: [\"box\"] . Must be: \"box\" . Default: \"box\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . northlimit (number, required) : A floating point value containing the constant coordinate for the northernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . eastlimit (number, required) : A floating point value containing the constant coordinate for the easternmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . southlimit (number, required) : A floating point value containing the constant coordinate for the southernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . westlimit (number, required) : A floating point value containing the constant coordinate for the westernmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . units (string, required) : A string containing the units applying to the unlabelled numeric values of northlimit, eastlimit, southlimit, and westlimit. projection (string) : A string containing the name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Default: null . PeriodCoverage (object) : A class used to represent temporal coverage metadata for a resource or aggregation. name (string) : A string containing a name for the time interval. Default: null . start (string, format: date-time, required) : A datetime object containing the instant corresponding to the commencement of the time interval. end (string, format: date-time, required) : A datetime object containing the instant corresponding to the termination of the time interval. PointCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a point location. type (string) : A string containing the type of geographic coverage. Must be one of: [\"point\"] . Must be: \"point\" . Default: \"point\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . east (number, required) : The coordinate of the point location measured in the east direction. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . north (number, required) : The coordinate of the point location measured in the north direction. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . units (string, required) : The units applying to the unlabelled numeric values of north and east. projection (string, required) : The name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Rights (object) : A class used to represent the rights statement metadata associated with a resource. statement (string, required) : A string containing the text of the license or rights statement. url (string, format: uri, required) : An object containing the URL pointing to a description of the license or rights statement.","title":"Single File"},{"location":"metadata/SingleFileMetadata/#single-file-aggregation-metadata","text":"","title":"Single File Aggregation Metadata"},{"location":"metadata/SingleFileMetadata/#properties","text":"title (string) : A string containing a descriptive title for the aggregation. Default: null . subjects (array) : A list of keyword strings expressing the topic of the aggregation. Default: [] . Items (string) language (string) : The 3-character string for the language in which the metadata and content are expressed. Default: \"eng\" . additional_metadata (array) : A dictionary of additional metadata elements expressed as key-value pairs. Items (object) : A key-value pair. Default: [] . key (string) value (string) spatial_coverage : An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point. Default: null . Any of : Refer to #/definitions/PointCoverage . : Refer to #/definitions/BoxCoverage . null period_coverage : An object containing the temporal coverage for a aggregation expressed as a date range. Default: null . Any of : Refer to #/definitions/PeriodCoverage . null type : A string expressing the aggregation type from the list of HydroShare aggregation types. Default: \"Generic\" . All of : Refer to #/definitions/AggregationType . url (string, format: uri, required) : An object containing the URL of the aggregation. rights : An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared. Default: null . Any of : Refer to #/definitions/Rights . null","title":"Properties"},{"location":"metadata/SingleFileMetadata/#definitions","text":"AggregationType (string) : Must be one of: [\"Generic\", \"FileSet\", \"GeoRaster\", \"NetCDF\", \"GeoFeature\", \"RefTimeseries\", \"TimeSeries\", \"ModelProgram\", \"ModelInstance\", \"CSV\"] . BoxCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a latitude-longitude bounding box. type (string) : A string containing the type of geographic coverage. Must be one of: [\"box\"] . Must be: \"box\" . Default: \"box\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . northlimit (number, required) : A floating point value containing the constant coordinate for the northernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . eastlimit (number, required) : A floating point value containing the constant coordinate for the easternmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . southlimit (number, required) : A floating point value containing the constant coordinate for the southernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . westlimit (number, required) : A floating point value containing the constant coordinate for the westernmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . units (string, required) : A string containing the units applying to the unlabelled numeric values of northlimit, eastlimit, southlimit, and westlimit. projection (string) : A string containing the name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Default: null . PeriodCoverage (object) : A class used to represent temporal coverage metadata for a resource or aggregation. name (string) : A string containing a name for the time interval. Default: null . start (string, format: date-time, required) : A datetime object containing the instant corresponding to the commencement of the time interval. end (string, format: date-time, required) : A datetime object containing the instant corresponding to the termination of the time interval. PointCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a point location. type (string) : A string containing the type of geographic coverage. Must be one of: [\"point\"] . Must be: \"point\" . Default: \"point\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . east (number, required) : The coordinate of the point location measured in the east direction. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . north (number, required) : The coordinate of the point location measured in the north direction. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . units (string, required) : The units applying to the unlabelled numeric values of north and east. projection (string, required) : The name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Rights (object) : A class used to represent the rights statement metadata associated with a resource. statement (string, required) : A string containing the text of the license or rights statement. url (string, format: uri, required) : An object containing the URL pointing to a description of the license or rights statement.","title":"Definitions"},{"location":"metadata/TimeSeriesMetadata/","text":"Time Series Aggregation Metadata Properties title (string) : A string containing a descriptive title for the aggregation. Default: null . subjects (array) : A list of keyword strings expressing the topic of the aggregation. Default: [] . Items (string) language (string) : The 3-character string for the language in which the metadata and content are expressed. Default: \"eng\" . additional_metadata (array) : A dictionary of additional metadata elements expressed as key-value pairs. Items (object) : A key-value pair. Default: [] . key (string) value (string) spatial_coverage : An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point. Default: null . Any of : Refer to #/definitions/PointCoverage . : Refer to #/definitions/BoxCoverage . period_coverage : An object containing the temporal coverage for a aggregation expressed as a date range. Default: null . All of : Refer to #/definitions/PeriodCoverage . time_series_results (array) : A list of time series results contained within the time series aggregation. Default: [] . Items : Refer to #/definitions/TimeSeriesResult . abstract : A string containing a summary of a aggregation. Default: null . Any of string null type : A string expressing the aggregation type from the list of HydroShare aggregation types. Default: \"TimeSeries\" . All of : Refer to #/definitions/AggregationType . url (string, format: uri, required) : An object containing the URL of the aggregation. rights : An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared. Default: null . Any of : Refer to #/definitions/Rights . null Definitions AggregationType (string) : Must be one of: [\"Generic\", \"FileSet\", \"GeoRaster\", \"NetCDF\", \"GeoFeature\", \"RefTimeseries\", \"TimeSeries\", \"ModelProgram\", \"ModelInstance\", \"CSV\"] . BoxCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a latitude-longitude bounding box. type (string) : A string containing the type of geographic coverage. Must be one of: [\"box\"] . Must be: \"box\" . Default: \"box\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . northlimit (number, required) : A floating point value containing the constant coordinate for the northernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . eastlimit (number, required) : A floating point value containing the constant coordinate for the easternmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . southlimit (number, required) : A floating point value containing the constant coordinate for the southernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . westlimit (number, required) : A floating point value containing the constant coordinate for the westernmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . units (string, required) : A string containing the units applying to the unlabelled numeric values of northlimit, eastlimit, southlimit, and westlimit. projection (string) : A string containing the name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Default: null . PeriodCoverage (object) : A class used to represent temporal coverage metadata for a resource or aggregation. name (string) : A string containing a name for the time interval. Default: null . start (string, format: date-time, required) : A datetime object containing the instant corresponding to the commencement of the time interval. end (string, format: date-time, required) : A datetime object containing the instant corresponding to the termination of the time interval. PointCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a point location. type (string) : A string containing the type of geographic coverage. Must be one of: [\"point\"] . Must be: \"point\" . Default: \"point\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . east (number, required) : The coordinate of the point location measured in the east direction. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . north (number, required) : The coordinate of the point location measured in the north direction. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . units (string, required) : The units applying to the unlabelled numeric values of north and east. projection (string, required) : The name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. ProcessingLevel (object) : A class used to represent the metadata associated with a processing level contained within a time series aggregation. processing_level_code (string, required) : A string containing a short but meaningful code identifying the processing level. definition : A string containing a description of the processing level. Default: null . Any of string null explanation : A string containing a more extensive explanation of the meaning of the processing level. Default: null . Any of string null Rights (object) : A class used to represent the rights statement metadata associated with a resource. statement (string, required) : A string containing the text of the license or rights statement. url (string, format: uri, required) : An object containing the URL pointing to a description of the license or rights statement. TimeSeriesMethod (object) : A class used to represent the metadata associated with a method contained within a time series aggregation. method_code (string, required) : A string containing a short but meaningful code identifying the method. method_name (string, required) : A string containing the name of the method. method_type (string, required) : A string containing the method type from the ODM2 Method Type controlled vocabulary. method_description : A string containing a detailed description of the method. Default: null . Any of string null method_link : An object containing a URL that points to a website having a detailed description of the method. Default: null . Any of string, format: uri null TimeSeriesResult (object) : A class used to represent the metadata associated with a time series result within a time series aggregation. series_id (string, required) : A string containing a unique identifier for the time series result. unit : An object containing the units in which the values of the time series are expressed. Default: null . All of : Refer to #/definitions/Unit . status : A string containing the status of the time series result chosen from the ODM2 Status controlled vocabulary. Default: null . Any of string null sample_medium (string, required) : A string containing the sample medium in which the time series result was measured chosen from the ODM2 Medium controlled vocabulary. value_count (integer, required) : An integer value containing the number of data values contained within the time series result. aggregation_statistic (string, required) : A string containing the aggregation statistic associated with the values of the time series result chosen from the ODM2 Aggregation Statistic controlled vocabulary. series_label (string) : A string containing a label for the time series result. Default: null . site : An object containing metadata about the site at which the time series result was created. All of : Refer to #/definitions/TimeSeriesSite . variable : An object containing metadata about the observed variable associated with the time series result values. All of : Refer to #/definitions/TimeSeriesVariable . method : An object containing metadata about the method used to produce the time series result values. All of : Refer to #/definitions/TimeSeriesMethod . processing_level : An object containing metadata about the processing level or level of quality control to which the time series result values have been subjected. All of : Refer to #/definitions/ProcessingLevel . utc_offset : A floating point value that represents the time offset from UTC time in hours associated with the time series result value timestamps. Default: null . Any of number null TimeSeriesSite (object) : A class used to represent the metadata associated with a site contained within a time series aggregation. site_code (string, required) : A string containing a short but meaningful code identifying the site. site_name : A string containing the name of the site. Default: null . Any of string null elevation_m : A floating point number expressing the elevation of the site in meters. Default: null . Any of number null elevation_datum : A string expressing the elevation datum used from the ODM2 Elevation Datum controlled vocabulary. Default: null . Any of string null site_type : A string containing the type of site from the ODM2 Sampling Feature Type controlled vocabulary . Default: null . Any of string null latitude : A floating point value expressing the latitude coordinate of the site. Default: null . Any of number null longitude : A floating point value expressing the longitude coordinate of the site. Default: null . Any of number null TimeSeriesVariable (object) : A class used to represent the metadata associated with a variable contained within a time series aggregation. variable_code (string, required) : A string containing a short but meaningful code that identifies a variable. variable_name (string, required) : A string containing the name of the variable. variable_type (string, required) : A string containing the type of variable from the ODM2 VariableType controlled vocabulary. no_data_value (integer, required) : The NoData value for the variable. variable_definition : A string containing a detailed description of the variable. Default: null . Any of string null speciation : A string containing the speciation for the variable from the ODM2 Speciation control vocabulary. Default: null . Any of string null Unit (object) : A class used to represent the metadata associated with a dimensional unit within a time series aggregation. type (string, required) : A string containing the type of unit from the ODM2 Units Type controlled vocabulary. name (string, required) : A string containing the name of the unit from the ODM2 units list. abbreviation (string, required) : A string containing an abbreviation for the unit from the ODM2 units list.","title":"Time Series"},{"location":"metadata/TimeSeriesMetadata/#time-series-aggregation-metadata","text":"","title":"Time Series Aggregation Metadata"},{"location":"metadata/TimeSeriesMetadata/#properties","text":"title (string) : A string containing a descriptive title for the aggregation. Default: null . subjects (array) : A list of keyword strings expressing the topic of the aggregation. Default: [] . Items (string) language (string) : The 3-character string for the language in which the metadata and content are expressed. Default: \"eng\" . additional_metadata (array) : A dictionary of additional metadata elements expressed as key-value pairs. Items (object) : A key-value pair. Default: [] . key (string) value (string) spatial_coverage : An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point. Default: null . Any of : Refer to #/definitions/PointCoverage . : Refer to #/definitions/BoxCoverage . period_coverage : An object containing the temporal coverage for a aggregation expressed as a date range. Default: null . All of : Refer to #/definitions/PeriodCoverage . time_series_results (array) : A list of time series results contained within the time series aggregation. Default: [] . Items : Refer to #/definitions/TimeSeriesResult . abstract : A string containing a summary of a aggregation. Default: null . Any of string null type : A string expressing the aggregation type from the list of HydroShare aggregation types. Default: \"TimeSeries\" . All of : Refer to #/definitions/AggregationType . url (string, format: uri, required) : An object containing the URL of the aggregation. rights : An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared. Default: null . Any of : Refer to #/definitions/Rights . null","title":"Properties"},{"location":"metadata/TimeSeriesMetadata/#definitions","text":"AggregationType (string) : Must be one of: [\"Generic\", \"FileSet\", \"GeoRaster\", \"NetCDF\", \"GeoFeature\", \"RefTimeseries\", \"TimeSeries\", \"ModelProgram\", \"ModelInstance\", \"CSV\"] . BoxCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a latitude-longitude bounding box. type (string) : A string containing the type of geographic coverage. Must be one of: [\"box\"] . Must be: \"box\" . Default: \"box\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . northlimit (number, required) : A floating point value containing the constant coordinate for the northernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . eastlimit (number, required) : A floating point value containing the constant coordinate for the easternmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . southlimit (number, required) : A floating point value containing the constant coordinate for the southernmost face or edge of the bounding box. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . westlimit (number, required) : A floating point value containing the constant coordinate for the westernmost face or edge of the bounding box. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . units (string, required) : A string containing the units applying to the unlabelled numeric values of northlimit, eastlimit, southlimit, and westlimit. projection (string) : A string containing the name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. Default: null . PeriodCoverage (object) : A class used to represent temporal coverage metadata for a resource or aggregation. name (string) : A string containing a name for the time interval. Default: null . start (string, format: date-time, required) : A datetime object containing the instant corresponding to the commencement of the time interval. end (string, format: date-time, required) : A datetime object containing the instant corresponding to the termination of the time interval. PointCoverage (object) : A class used to represent geographic coverage metadata for a resource or aggregation expressed as a point location. type (string) : A string containing the type of geographic coverage. Must be one of: [\"point\"] . Must be: \"point\" . Default: \"point\" . name (string) : A string containing a name for the place associated with the geographic coverage. Default: null . east (number, required) : The coordinate of the point location measured in the east direction. Exclusive minimum: -180.0 . Exclusive maximum: 180.0 . north (number, required) : The coordinate of the point location measured in the north direction. Exclusive minimum: -90.0 . Exclusive maximum: 90.0 . units (string, required) : The units applying to the unlabelled numeric values of north and east. projection (string, required) : The name of the projection used with any parameters required, such as ellipsoid parameters, datum, standard parallels and meridians, zone, etc. ProcessingLevel (object) : A class used to represent the metadata associated with a processing level contained within a time series aggregation. processing_level_code (string, required) : A string containing a short but meaningful code identifying the processing level. definition : A string containing a description of the processing level. Default: null . Any of string null explanation : A string containing a more extensive explanation of the meaning of the processing level. Default: null . Any of string null Rights (object) : A class used to represent the rights statement metadata associated with a resource. statement (string, required) : A string containing the text of the license or rights statement. url (string, format: uri, required) : An object containing the URL pointing to a description of the license or rights statement. TimeSeriesMethod (object) : A class used to represent the metadata associated with a method contained within a time series aggregation. method_code (string, required) : A string containing a short but meaningful code identifying the method. method_name (string, required) : A string containing the name of the method. method_type (string, required) : A string containing the method type from the ODM2 Method Type controlled vocabulary. method_description : A string containing a detailed description of the method. Default: null . Any of string null method_link : An object containing a URL that points to a website having a detailed description of the method. Default: null . Any of string, format: uri null TimeSeriesResult (object) : A class used to represent the metadata associated with a time series result within a time series aggregation. series_id (string, required) : A string containing a unique identifier for the time series result. unit : An object containing the units in which the values of the time series are expressed. Default: null . All of : Refer to #/definitions/Unit . status : A string containing the status of the time series result chosen from the ODM2 Status controlled vocabulary. Default: null . Any of string null sample_medium (string, required) : A string containing the sample medium in which the time series result was measured chosen from the ODM2 Medium controlled vocabulary. value_count (integer, required) : An integer value containing the number of data values contained within the time series result. aggregation_statistic (string, required) : A string containing the aggregation statistic associated with the values of the time series result chosen from the ODM2 Aggregation Statistic controlled vocabulary. series_label (string) : A string containing a label for the time series result. Default: null . site : An object containing metadata about the site at which the time series result was created. All of : Refer to #/definitions/TimeSeriesSite . variable : An object containing metadata about the observed variable associated with the time series result values. All of : Refer to #/definitions/TimeSeriesVariable . method : An object containing metadata about the method used to produce the time series result values. All of : Refer to #/definitions/TimeSeriesMethod . processing_level : An object containing metadata about the processing level or level of quality control to which the time series result values have been subjected. All of : Refer to #/definitions/ProcessingLevel . utc_offset : A floating point value that represents the time offset from UTC time in hours associated with the time series result value timestamps. Default: null . Any of number null TimeSeriesSite (object) : A class used to represent the metadata associated with a site contained within a time series aggregation. site_code (string, required) : A string containing a short but meaningful code identifying the site. site_name : A string containing the name of the site. Default: null . Any of string null elevation_m : A floating point number expressing the elevation of the site in meters. Default: null . Any of number null elevation_datum : A string expressing the elevation datum used from the ODM2 Elevation Datum controlled vocabulary. Default: null . Any of string null site_type : A string containing the type of site from the ODM2 Sampling Feature Type controlled vocabulary . Default: null . Any of string null latitude : A floating point value expressing the latitude coordinate of the site. Default: null . Any of number null longitude : A floating point value expressing the longitude coordinate of the site. Default: null . Any of number null TimeSeriesVariable (object) : A class used to represent the metadata associated with a variable contained within a time series aggregation. variable_code (string, required) : A string containing a short but meaningful code that identifies a variable. variable_name (string, required) : A string containing the name of the variable. variable_type (string, required) : A string containing the type of variable from the ODM2 VariableType controlled vocabulary. no_data_value (integer, required) : The NoData value for the variable. variable_definition : A string containing a detailed description of the variable. Default: null . Any of string null speciation : A string containing the speciation for the variable from the ODM2 Speciation control vocabulary. Default: null . Any of string null Unit (object) : A class used to represent the metadata associated with a dimensional unit within a time series aggregation. type (string, required) : A string containing the type of unit from the ODM2 Units Type controlled vocabulary. name (string, required) : A string containing the name of the unit from the ODM2 units list. abbreviation (string, required) : A string containing an abbreviation for the unit from the ODM2 units list.","title":"Definitions"}]}